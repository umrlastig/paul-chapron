[["univariee.html", "Chapitre 2 Analyse Univariée 2.1 Le concept de distribution 2.2 Exemples de distributions de lois connues 2.3 Histogramme d’une distribution réelle", " Chapitre 2 Analyse Univariée 2.1 Le concept de distribution L’analyse univariée a pour but de décrire et mesurer la répartition des valeurs que peut prendre une variable. On appelle la répartition des valeurs d’un variable sa distribution , que l’on peut approximativement voir comme son «histogramme en continu». Voilà une distribution d’une variable réelle (courbe noire), superposée à son histogramme : Vous pouvez voir avec cet exemple, que la courbe suit les variations de hauteur des colonnes de l’histogramme, tout en lissant les aspérités. C’est de cette courbe que l’on parle lorsqu’on évoque la distribution de la variable. Plus formellement, pour une population donnée, la distribution d’une variable \\(V\\) est définie comme une fonction qui donne la probabilité qu’un individu \\(x\\) pris au hasard dans la population ait la valeur \\(V_x\\) pour la variable \\(V\\) : \\[distribution(V) \\equiv P(V=V_x), \\forall V_x \\in \\Omega_V\\] avec \\(\\Omega_V\\) l’ensemble des valeurs que peut prendre \\(V\\) : l’univers de \\(V\\). Lorsque la variable prend des valeurs réelles, on parle de densité de probabilité, c’est pourquoi on retrouve ce terme “density” sur les axes des ordonnées dans les graphiques de distribution. La forme d’une distribution donne beaucoup d’informations sur les valeurs d’une variable dans une population : valeurs les plus représentées dans la population : les “pics” présence de valeurs extrêmes : la courbe de la distribution est tirées à gauche ou à droite du graphique caractéristiques de sa forme : symétrie, aplatissement etc… Dans notre exemple de distribution de longueur de nageoires en millimètres, on observe deux pics assez doux : l’un aux alentours de 190mm, l’autre de 215mm. On peut l’interpréter ainsi : «la valeurs la plus représentée dans les longueurs de nageoires de cette population de pingouins est de 190mm, suivie de 215mm» 2.1.1 Interpréter la courbe de densité L’histogramme représente l’effectif de la population en fonction de la valeur d’une variable, son interprétation est directe et aisée puisque ce graphique donne une représentation du nombre d’individus par intervalles de valeurs. La représentation d’une distribution est légèrement plus délicate à comprendre mathématiquement. En première approximation , vous pouvez l’interpréter comme un histogramme dont les barres seraient infiniement fines, et dont l’axe des \\(y\\) représenteraient une probabilité au lieu d’un effectif. La densité de probabilité comme son nom l’indique, représente des probabilités: celles d’obtenir, pour un individu dans la population, une certaine valeur de la variable. Le point délicat est qu’une variable continue (i.e. définie sur un intervalle de \\(\\mathbb{R}\\)), peut prendre une infinité de valeurs possibles, et que la probabilité d’obtenir exactement, c’est à dire avec une précision infinie, une valeur est infinitésimale, en fait carrément nulle. Il faut alors considérer la probabilité d’obtenir une valeur, non pas de façon exacte , mais dans un intervalle de valeur. Par exemple, dans le graphique ci-dessous, de s’intérroger sur la probabilité , pour un individu tiré au hasard dans la population , d’avoir une valeur de Variable 1 dans l’intervalle [25;30]. Cela pourrait s’écrire \\(P( 25 \\leq V_1 \\leq 30)\\) et serait égal à l’intégrale de la fonction de densité notée \\(f_{V_1}\\) entre les bornes 25 et 30 de l’intervalle de \\(V_1\\) : \\[P( 25 \\leq V_1 \\leq 30) = \\int_{25}^{30} f_{V_1}(x)dx\\] En pratique , le graphique d’une densité s’interprète en observant la quantité d’aire sous la courbe L’aire totale sous la courbe vaut 1 (cela revient à considérer la somme de toutes les probabilités d’avoir une valeur particulière \\(X\\) dans l’intervalle de valeur de \\(V_1\\)) et par approximation , la valeur de la probabilité d’obtenir une certaine valeur se lit comme la proportion d’aire sous la courbe comprise entre deux bornes proche de la valeur. ## [1] 3.735817 ici , la valeur de \\(P( 25 \\leq V_1 \\leq 30)\\) vaut XXX 2.2 Exemples de distributions de lois connues Parfois certaines distributions ressemblent à des distributions bien connues : on appelle ces distributions des lois. Ce sont des distributions de probabilités que l’on peut formaliser par une équation et dont les statisticiens ont pu dériver des caractéristiques par le calcul. 2.2.1 Loi Gaussienne La plus connue est la distribution Gaussienne, on dit aussi distribution normale du nom de la loi de probabilité qu’elle suit : la loi dite normale. Cette loi a deux paramètres : \\(\\mu\\) la moyenne, i.e. la valeur moyenne qu’auront les valeurs tirées de cette distribution \\(\\sigma\\) l’écart type, qui représente leur écartement par rapport à cette moyenne Nous reviendrons plus loin sur ces deux caractéristiques Voici la distribution d’une population dont la variable \\(V1\\) suit une loi normale de moyenne 0 et d’écart-type 1, qu’on note \\(\\mathscr{N}(0,1)\\) xx &lt;- data.frame(value=rnorm(8000)) plot1 &lt;- ggplot(xx)+ geom_density(aes(x = value), color=&quot;#aaaaaa&quot;, fill=&quot;#44DD99&quot; )+ theme_light()+ labs(title = &quot;Loi Normale&quot;, x=&quot;Valeur de la variable V1 &quot;, y=&quot;densité&quot;) plot1 Voici un histogramme de la même population plot1 &lt;- ggplot(xx)+ geom_histogram(aes(x = value),bins = 50, color=&quot;#aaaaaa&quot;, fill=&quot;#44DD99&quot; )+ theme_light()+ labs(title = &quot;Loi Normale&quot;, x=&quot;Valeur de la variable V1&quot;, y=&quot;Effectif&quot;) plot1 2.2.2 Loi uniforme Comme son nom l’indique, la loi uniforme vaut partout la même valeur entre deux bornes \\(a\\) et \\(b\\), autrement dit , la probabilité d’obtenir une certaine valeur \\(v\\in[a;b]\\) est constante. La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois, la distribution, qui devrait être plate, est courbée aux extrémités. La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout sur \\([a;b]\\) mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois comme ici, la distribution, qui devrait être plate, est courbée aux extrémités. Cela est dû à la façon dont R estime la densité numériquement, biaisée aux extrémités de l’intervalle 2.2.3 Loi log-normale La loi log-normale est comme son nom l’indique, le résultat d’un logarithme appliqué à une variable suivant une loi normale. Notez comme la distribution est «tirée vers la droite». On parle de «queue de distribution». Cette longue queue (“fat tail” in english) indique une grande inégalité dans la population: quelques individus, peu nombreux mais aux valeurs de variable très élevées, et une vaste majorité d’individus dont la valeur de la variable est faible qui constitue le pic de la distribution. Cette loi modélise par exemple l’effet d’un «grand nombre de petits facteurs considérés comme indépendants». Wikipedia nous apprend qu’elle modélise des phénomènes réels tels que la répartition de 97% des salaires du monde, celle de la la longueur et le poids de spécimen d’animaux, la durée des parties d’échecs, etc. 2.3 Histogramme d’une distribution réelle Les distribution de données empiriques ont rarement des formes aussi régulière et identifiable que celles des lois. Voici par exemple l’histogramme de la hauteur des arbres à Paris, selon les données disponibles sur [https://opendata.paris.fr/] Cet histogramme n’est pas très informatif en l’état : si on le lit naïvement, il semblerait que tous les arbres aient une valeur nulle ou quasi-nulle pour leur hauteur en mètres et la circonférences de leur tronc en centimètres. Pourquoi ? Parce que le logiciel qui trace l’histogramme (R) fait du mieux qu’il peut pour tracer les colonnes de l’histogramme correspondant aux valeurs : il ne doit pas en oublier, la hauteur des colonnes doit correspondre à l’effectif (le nombre) d’individus (ici des arbres) par valeur de la variable l’échelle de l’axes \\(x\\) doit «faire tenir» l’étendue des valeurs (\\(x_{max} - x_{min}\\)),sur une quantité de pixels limitée. Ce qui se produit ici est que certains individus ont des hauteurs ou des circonférences renseignées à des valeurs totalement irréalistes, comme nous l’indique les bornes du dernier décile (i.e. les 10% des valeurs les plus élevées ) : ## 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% ## 0 0 4 5 6 8 10 11 15 16 881818 10% des arbres ont une hauteur comprise entre 12 et 881818 mètres: il y a donc quelques arbres, au moins un, dont la hauteur est clairement defectueuse, on peut supposer qu’il s’agit d’une erreur de saisie ou d’ encodage des données (les plus hauts arbres font autour de 120m). On constate aussi qu’au moins 10% des données ont une hauteur nulle. En affichant l’histogramme de cette variable, R a donc du afficher une colonne aux alentours de la valeur 881818, dont la hauteur est vraisemblablement très faible (1 ou 2 individus), en tout cas si faible qu’on ne la distingue pas : son épaisseur est dans le trait de l’axe des \\(x\\) Nous allons donc filtrer les données, pour ne conserver que les arbres dont la hauteur est comprise entre 1 et 60 mètres, ce qui me semble correct comme intervalle pour des hauteurs d’arbres parisiens, mais qui pourrait être discuté. De même , on écarte les arbres dont le tronc excède 2500 cm : On voit ici comme la représentation graphique des variables nous renseigne à deux niveaux : elle nous indique la présence de valeurs aberrantes lors de son affichage “brut”, et une fois filtrée, elle nous montre comment la population varie dans les valeurs de ses variables. Nous allons maintenant voir comment décrire la forme de la répartition de ces valeurs avec des mesures statistiques. "],["tendance.html", "Chapitre 3 Statistique descriptive univariée : la tendance 3.1 Moyenne 3.2 Mode 3.3 Médiane 3.4 Quelle mesure de tendance choisir ? 3.5 Distribution unimodale symétrique 3.6 Histogramme et distribution en R 3.7 Histogramme et distribution en R", " Chapitre 3 Statistique descriptive univariée : la tendance Les distributions de variables dans les données du monde réel sont rarement constantes ou uniformes. Elles exhibent ce qu’on appelle une tendance, c’est-à-dire une valeur autour de laquelle se retrouvent la majorité des individus. Si la forme de la distribution est suffisamment régulière, cette tendance peut servir de résumé statistique de la variable de la population. Les indicateurs de tendance centrale de la distribution d’une variable sont la moyenne et ses variantes, la médiane et le mode. 3.1 Moyenne La moyenne d’une variable \\(x\\) , notée \\(\\bar{x}\\) , s’écrit : \\[ \\bar{x} = \\frac{1}{n}\\sum_{i=0}^{n} x_i \\] 3.1.1 Moyenne pondérée Lorsque des poids \\(p_i\\) sont affectés aux individus, la moyenne pondérée s’écrit : \\[ \\bar{x} = \\frac{1}{\\sum_{i=0}^n pi}\\sum_{i=0}^{n} p_i x_i \\] 3.1.2 Avantages et inconvénients de la moyenne Avantage : chaque valeur compte dans le calcul. Inconvénients : sensibilité aux valeurs extrêmes pas de signification directe sur les variables quantitatives discrètes (e.g. «2.5 enfants/femme» ) Pour y remédier : exclure les outliers, ou restreindre les valeurs considérées par filtrage utiliser un autre estimateur, par exemple la médiane étudier la distribution des valeurs et en cas de multi-modalités, opérer une classification 3.1.3 Autres Moyennes 3.1.3.1 Moyenne geométrique: Elle s’écrit ainsi : \\[ \\bar{x} = \\sqrt[n]{\\prod _{i=0}^{n} x_i}\\] Elle a l’avantage d’être moins sensible à la présence de valeurs extrêmes que la moyenne algébrique. 3.1.3.2 Moyenne quadratique (RMS) Elle s’écrit : \\[\\bar{x} = \\sqrt{\\frac{1}{n}\\sum _{i=0}^{n} x_i^2} \\] 3.1.3.3 Hors sujet : Moyenne glissante Ce n’est pas une moyenne comme les autres, au sens où elle ne résume pas toute une série de valeurs Dans le cas de séries temporelles (i.e. valeurs successives de la même variable), la moyenne glissante est calculée sur une «fenêtre» de \\(n\\) valeurs consécutives. La fenêtre est centrée sur l’instant auquel on calcule la valeur de la moyenne. Par exemple, pour une moyenne glissante sur une fenêtre de taille 10, la valeur en chaque points \\(x_i\\) à la position \\(i\\) dans la série temporelle (on suppose que \\(i&gt;5\\)) vaut la moyenne des de \\(x_i\\) et des 10 valeurs environnantes, 5 en avant , 5 en arrière : \\[\\bar{x} = \\frac{1}{11}\\sum _{j=i-5}^{j=i+5} x_j\\] 3.2 Mode Le mode d’une variable est la valeur la plus fréquente ( d’effectif maximum) d’une variable. Si la variable est quantitative et continue, il faut découper l’étendue de la variable (la différence entre la valeur maximum et minimum) en intervalle égaux , puis réaliser une classification des individus dans ces intervalles et un comptage des effectifs de chaque classe. Dans ce cas, le mode est la moyenne des valeurs min et max des bornes de la classe de plus grand effectif. C’est exactement ce que fait un histogramme graphiquement ! 3.2.1 Avantages et inconvénients du mode Avantages : Peu sensible aux valeurs extrêmes (moins sensible que la moyenne) il s’interprète facilement : c’est la situation la plus fréquente dans la population Inconvénients : le mode ne dépends pas de toutes les observations : la modification d’une seule valeur n’entraîne pas une modification du mode. Cet inconvénient explique sa robustesse aux valeurs extrêmes 3.3 Médiane La médiane est la valeur qui partage une série de valeurs en deux sous-ensembles d’égal effectif Comme en géométrie, la médiane est la valeur de la variable qui est la plus proche de toutes les autres. 3.3.1 Étapes de calcul Déterminer la médiane d’un ensemble de valeurs est très simple : Ordonner les \\(n\\) valeurs de \\(V\\) selon un ordre croissant Calculer le rang \\(rg=\\frac{n+1}{2}\\) si \\(n\\) impair, la valeur médiane est \\(V[rg]\\). Si \\(n\\) est pair, la valeur médiane est entre deux valeurs et est égale à la moyenne de \\(V[\\frac{n}{2}]\\) et \\(V[\\frac{n}{2}-1]\\) Dans cet algo , on suppose qu’on compte les cellules d’un tableau à partir de 0, comme en python. En R, où on compte les cellules à partir de 1 , il faudrait ajouter 1 à tous les indices. 3.3.2 Avantages et inconvénients de la médiane Avantages : Souvent plus pertinente que la moyenne Peu sensible aux valeurs extrêmes: quelques valeurs très fortes ou très faibles ne modifie pas sa valeur elle s’interprète facilement : comme elle divise en deux la distribution, un individu sur deux a une valeur inférieure (respectivement supérieure) à la médiane. Inconvénient : Comme le mode, la médiane ne dépend pas de toutes les observations : la modification d’une seule valeur n’entraine pas une modification de la médiane. Notons que la robustesse de la médiane est bien utile dans le cas de distribution particulièrement asymétriques, où la moyenne est dégradée par les valeurs extrêmes, à droite (valeurs très élevées) ou à gauche (valeurs très faibles). Par exemple , pour les revenus mensuels en équivalent temps plein en France en 2016 : le revenu mensuel net moyen est de 2 238 €, le revenu mensuel net médian est de 1 789 € : selon l’[https://www.insee.fr/fr/statistiques/4277680?sommaire=4318291] Supposons qu’on cherche à évaluer si un salaire mensuel net équivalent temps plein de 2000€ est un bon salaire en France, sans définir trop rigoureusement ce qui signifie «bon». 2000€ est inférieur à la moyenne du pays, on peut le considérer comme trop bas pour être «bon». 2000€ est supérieur au salaire médian, il est supérieur à (au moins) la moitié des salaires du pays, et on peut le considérer comme un «bon» salaire. Cette double interprétation est due au fait que certains salaires très élevés, mais d’effectifs peu nombreux, tirent la distribution du salaire vers la droite, et avec eux, la moyenne. 3.4 Quelle mesure de tendance choisir ? Tout dépend de la distribution ! (cette réponse est malheureusement quasiment universelle, d’où l’importance de toujours représenter visuellement les variables pour décider en connaissance de cause ) Si la distribution n’a pas de longue queue (on dit aussi traîne) , la moyenne et la médiane sont adaptées. Si la distribution exhibe plusieurs modes , il faut réaliser une classification puis calculer médiane et moyenne pour chaque classe. Le mode est privilégié pour les variables nominales c’est-à-dire des variables qualitatives dont les modalités ne sont pas ordonnées, et si on désire considérer «le cas le plus fréquent» 3.4.1 Cas délicat : Distribution bimodale Que choisir : moyenne ou médiane ? 3.5 Distribution unimodale symétrique xx &lt;- data.frame(value=rnorm(2900,mean = 5, sd = 1)) plot1 &lt;- ggplot(xx)+ geom_line(aes(x = value),stat = &quot;density&quot;, color=&quot;#44DD99&quot;, lwd= 1.3)+ geom_vline(xintercept = mean(xx$value), color=&quot;red&quot;)+ geom_vline(xintercept = median(xx$value) + 0.02,color=&quot;blue&quot;)+ annotate(&quot;text&quot;, x=c(4.5,5.5), y=c(0.2,0.2), colour=c(&quot;red&quot;,&quot;blue&quot;),label=c(&quot;mean&quot;, &quot;median&quot;))+ theme_light() plot1 3.6 Histogramme et distribution en R la fonction hist affiche un histogramme d’un vecteur numerique: x &lt;- rnorm(2500) #init hist(x) 3.7 Histogramme et distribution en R un histogramme n’a pas de sens pour une variable qualitative. On peut utiliser barplot,⚠ mais ce n’est plus une distribution ! x &lt;- sample(month.name, 2500, replace=T) tx &lt;- table(x) barplot(tx , las=2) "],["statistique-descriptive-univariée-la-dispersion.html", "Chapitre 4 Statistique descriptive univariée : la dispersion 4.1 La dispersion statistique 4.2 Variance et Écart-type 4.3 Variance et Écart-type 4.4 Précaution 4.5 Lorsque \\(X\\sim \\mathscr{N}(\\mu,\\sigma)\\) 4.6 Quantiles 4.7 Déciles 4.8 Ecarts inter-quartiles et inter-déciles 4.9 Les boîtes à moustaches (boxplots) 4.10 Interprétation des boxplots 4.11 Avantages et inconvénient des quantiles 4.12 Le coefficient de variation 4.13 Comparaison de dispersion de deux distributions de valeurs. 4.14 (Mauvaise) Comparaison visuelle de deux distributions 4.15 Comparaison visuelle de dispersion de deux distributions", " Chapitre 4 Statistique descriptive univariée : la dispersion Variance, écart-type, Coeff. de variation. 4.1 La dispersion statistique Tendance des valeurs d’une variable à se disperser autour des valeurs des tendances centrales. mydataset &lt;- data.frame(X=rnorm(900), Y=rnorm(900)) plot1 &lt;- ggplot(mydataset)+ geom_point(aes(x=X, y=Y), fill=&quot;#44DD99&quot;, color=&quot;#666666&quot;, shape=21)+ coord_equal()+theme_light() plot1 4.2 Variance et Écart-type La variance est la somme des écarts carrés à la moyenne rapporté à l’effectif \\(\\displaystyle var_X= \\frac{1}{n}\\sum_{i=1}^{n}(x_i -\\bar{x})^2\\) Avec : * \\(X\\) une variable * \\(x_i\\) les valeurs de la variables * \\(\\bar{x}\\) la moyenne de \\(X\\) * \\(n\\) l’effectif \\(\\sigma_X = \\sqrt{var_X}\\) : l’écart type est la racine carrée de la variance 4.3 Variance et Écart-type Variance et écart-type rendent compte de la dispersion de la variable autour de sa moyenne. Ils sont sensibles aux valeurs extrèmes et toujours positifs. Si \\(var_X = 0\\) ou \\(\\sigma_X = 0\\) , alors \\(X\\) est constante. Un écart-type faible indique que les valeurs sont réparties de façon homogène autour de la moyenne. 4.4 Précaution ⚠Variance et écart type n’ont d’intérêt que pour qualifier des distributions unimodales, et (à peu près) symétriques (i.e. proche de la Gaussienne) 4.5 Lorsque \\(X\\sim \\mathscr{N}(\\mu,\\sigma)\\) \\([-\\sigma;\\sigma] \\approx \\frac{2}{3}\\) de l’effectif \\([-2\\sigma;2\\sigma] \\approx\\) 95% de l’effectif 4.6 Quantiles La médiane sépare une population en deux classes d’égal effectif selon la valeur d’une variable (quantitative). Les quantiles séparent une population en \\(n\\) classes d’égal effectif Les quartiles d’une population selon une variable \\(X\\) sont trois valeurs, \\(Q_1,Q_2,Q_3\\) qui séparent la population en quatre classes d’égal effectif. 25% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_1\\) 50% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_2\\) (médiane) 75% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_3\\) 4.7 Déciles Les déciles sont les 9 quantiles \\(Q_1,Q_2,\\dots,Q_9\\) qui séparent une population selon la valeur d’une variable quantitative en 10 classes d’égal effectif. 4.8 Ecarts inter-quartiles et inter-déciles Deux mesures de la dispersion d’une distribution : Écart inter-quartile: \\(Q_3-Q_1\\) , capture 50% des valeurs de la population les plus proches de la médiane Écart inter-déciile: \\(Q_9-Q_1\\) , capture 80% des valeurs de la population les plus proches de la médiane 4.9 Les boîtes à moustaches (boxplots) représentation courante de la dispersion d’une variable à l’aide de quartiles plot1 &lt;- ggplot(iris)+ geom_boxplot(aes(y=Sepal.Width,x= Species) ) + coord_flip() plot1 4.10 Interprétation des boxplots La marque centrale de la boîte est la médiane Les bords de la boîte sont les quartiles \\(Q_1\\) et \\(Q_3\\) Les extrémités des moustaches vont jusqu’à la plus grande (resp. la plus petite ) valeur inférieure (resp. supérieure) à 1.5 fois l’écart interquartile Les valeurs qui dépassent les moustaches sont affichées sous formes de points 4.11 Avantages et inconvénient des quantiles 4.11.1 Avantages Peu sensibles aux distributions aplaties et aux valeurs extrèmes L’écart inter-quantile est plus robuste que l’écart-type 4.11.2 Inconvénients Parfois délicat pour les variables quantitatives discrètes Les écarts inter-quantiles négligent l’influence des valeurs extrèmes sur la distribution 4.12 Le coefficient de variation Le coefficient de variation (\\(CV\\)) est une autre mesure de dispersion. C’est le ratio entre l’écart-type \\(\\sigma_x\\) et la moyenne \\(\\bar{x}\\) d’une variable quantitative \\(X\\). \\(\\displaystyle CV(X)=\\frac{\\sigma_x}{\\bar{x}}\\) Plus il est important , plus la dispersion est grande. Plus il est proche de 0, plus les données sont homogènes. Il souffre des mêmes inconvénients que la moyenne et l’écart-type : sensibilité aux valeurs extrèmes. 4.13 Comparaison de dispersion de deux distributions de valeurs. Exemple : deux communes versent des aides aux entreprises locales. Commune A : moyenne = 390 euros, \\(\\sigma\\) = 30 euros Commune B : moyenne = 152 euros, \\(\\sigma\\) = 8 euros Pour quelle commune les aides sont les plus homogènes? On pourrait aussi comparer des distribution de valeurs exprimées dans des unités différentes ! 4.14 (Mauvaise) Comparaison visuelle de deux distributions Pour échantilloner dans une loi normale : fonction rnorm A &lt;- rnorm(n = 10000, mean = 390, sd = 30) B &lt;- rnorm(n = 10000, mean = 152, sd = 8) par(mfrow=c(1, 2)) #2 graphes en colonnes hist(A, probability = T) lines(density(A), col=&quot;red&quot;) hist(B, probability = T) lines(density(B), col=&quot;red&quot;) Qu’est ce qui ne va pas ? 4.15 Comparaison visuelle de dispersion de deux distributions Il faut une échelle commune ! A &lt;- rnorm(n = 10000, mean = 390, sd = 30) B &lt;- rnorm(n = 10000, mean = 152, sd = 8) par(mfrow=c(1, 2)) hist(A, probability = T, xlim = c(50,600), ylim = c(0,0.05)) lines(density(A), col=&quot;red&quot;) hist(B, probability = T,xlim = c(50,600), ylim = c(0,0.05)) lines(density(B), col=&quot;red&quot;) "],["statistique-descriptive-univariée-la-forme.html", "Chapitre 5 Statistique descriptive univariée : la forme 5.1 Asymétrie des distributions. 5.2 les Coefficients de Pearson 5.3 Interprétation des coefficients d’asymétrie 5.4 Le coefficient de Fischer 5.5 L’aplatissement des distributions (kurtosis) 5.6 Coefficient d’applatissement : kurtosis", " Chapitre 5 Statistique descriptive univariée : la forme Symétrie , applatissement 5.1 Asymétrie des distributions. 5.2 les Coefficients de Pearson Deux moyens simples d’estimer l’asymétrie \\(\\displaystyle C_1 = \\frac{\\bar{x} - mode(X)}{\\sigma_x}\\) \\(\\displaystyle C_2 = \\frac{3(\\bar{x} - mediane(X))}{\\sigma_x}\\) 5.3 Interprétation des coefficients d’asymétrie si le coefficient nul, la distribution est symétrique si le coefficient est négatif, la distribution est déformée à gauche de la médiane (sur-représentation de valeurs faibles, à gauche) si le coefficient est positif, la distribution est déformée à droite de la médiane (sur-représentation de valeurs fortes, à droite) 5.4 Le coefficient de Fischer Ce coefficient est le moment d’ordre 3 de la variable \\(X\\) ( de moyenne \\(\\mu\\) et d’écart-type \\(\\sigma\\)) centrée réduite \\(\\displaystyle skewness&#39;=\\mathbb{E}\\bigg[\\bigg(\\frac{X-\\mu}{\\sigma}\\bigg)^3\\bigg]=\\frac{\\sum_{i=0}^{n} (x_i - \\bar{x})^3}{n\\sigma^3}\\) 5.5 L’aplatissement des distributions (kurtosis) Courbe piquée: Peu de variation, distribution relativement homogène, beaucoup de valeurs égales ou proches de la moyenne. Courbe applatie: Variations importantes, distribution relativement hétérogène, beaucoup de valeurs s’éloignent de la moyenne. 5.6 Coefficient d’applatissement : kurtosis Coefficient non normalisé : \\(\\displaystyle K=\\frac{\\sum_{i=1}^{n}(x_i -\\bar{x})^4}{n\\sigma^4}\\) Si la distribution est normale , \\(K= 3\\) Si \\(K&gt;3\\), la distribution est plus applatie Si \\(K&lt;3\\), la distribution est moins applatie On normalise parfois en considérant \\(K&#39;=K-3\\) (excès d’applatissement) "],["représentation-dune-distribution-et-échelle-de-couleurs.html", "Chapitre 6 Représentation d’une distribution et Échelle de couleurs 6.1 Distribution et Échelle de couleurs 6.2 Distribution et Échelle de couleurs 6.3 Exemple avec la surface des quartiers de Paris 6.4 Allure de la distribution 6.5 Affichage par défaut : 6.6 Jenks à 5 , 7 et 9 classes 6.7 Jenks à 5 , 7 et 9 classes 6.8 Effectifs égaux 6.9 Intervalles égaux (7) 6.10 Ecart types 6.11 Guides de choix de la méthode de classification 6.12 Autres classifications 6.13 Transformations des données 6.14 Variables centrées-réduites", " Chapitre 6 Représentation d’une distribution et Échelle de couleurs 6.1 Distribution et Échelle de couleurs Pour une variable quanti. continue qu’on souhaite colorer, il n’est pas toujours possible de graduer une échelle de couleur continue. Il faut (souvent) classer les valeurs en catégories. Le nombre de classes et les méthodes de classification varient. En général 5,7 ou 9 classes : \\(&lt;5\\) trop peu de détails \\(&gt;9\\) difficile de distinguer les classes proches 6.2 Distribution et Échelle de couleurs Méthodes de classifications de Qgis Ruptures Naturelles (Jenks) : Minimisation des variances intra-classe et maximisation des variances inter-classe Effectifs égaux (quantiles) Intervalles égaux Ecart-type : intervales de 1 ou 0.5 \\(\\sigma\\) Jolies ruptures : intervalle égaux “décalés” pour faire joli : nombre ronds, puissances de 10, … 6.3 Exemple avec la surface des quartiers de Paris quartiers &lt;- st_read(&quot;data/quartier_paris.shp&quot;) plot(quartiers$geometry) 6.4 Allure de la distribution hist(quartiers$surface,breaks = 15) 6.5 Affichage par défaut : par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;]) par defaut la fonction plot de sf utilise la méthode “pretty” avec 10 ruptures (\\(9\\pm1\\) classes) =&gt; ce sont des intervalles égaux. 6.6 Jenks à 5 , 7 et 9 classes 6.7 Jenks à 5 , 7 et 9 classes Code R correspondant : par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 5, main = &quot;5 breaks&quot;) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 7, main=&quot;7 breaks&quot;) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 9, main= &quot;9 breaks&quot;) 6.8 Effectifs égaux 6.9 Intervalles égaux (7) par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;equal&quot;, nbreaks = 7, main = &quot;Intervalles égaux&quot;) 6.10 Ecart types par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;sd&quot;,main = &quot;Écart-type&quot;) \\(\\approx\\) méthode des jolies ruptures sur variable centrée réduite 6.11 Guides de choix de la méthode de classification Pour les classification manuelles : les classes doivent contenir toutes les valeurs, être sans recouvrement, contigües et distinctes. Procéder par essai-erreur attention aux décimales et aux extrémités si distribution uniforme \\(\\rightarrow\\) Intervalles égaux si distribution asymétrique \\(\\rightarrow\\) Effectifs égaux, Jenks , progression géométrique (rare). si distribution symétrique \\(\\rightarrow\\) Écart-type, intervalle égaux 6.12 Autres classifications consultez la doc de la fonction classInt du package du même nom 6.13 Transformations des données \\(x \\mapsto log(x)\\) pour une distribution asymétrique à droite ou \\(x \\mapsto \\sqrt x\\) si moins asymétrique \\(x \\mapsto x^2\\) pour une distribution asymétrique à gauche ou \\(x \\mapsto x^3\\) si très asymétrique (⚠ toujours vérifier l’allure de la distribution transformée) 6.14 Variables centrées-réduites ⚠ En principe, uniquement lorsque la distribution d’une variable est proche d’une gaussienne ⚠ Centrer : soustraire la moyenne Réduire : diviser par l’écart-type une variable centrée réduite est exprimée en «écarts-types à la moyenne» \\(\\rightarrow\\) permet de repérer les valeurs extrèmes (\\(&lt;2\\sigma\\) ou \\(&gt;2\\sigma\\)) \\(\\rightarrow\\) utile pour comparer des individus selon un grand nombre de variables (tableaux de synthèse) "],["visualiser-une-distribution.html", "Chapitre 7 Visualiser une distribution 7.1 Histogramme : Code R + ggplot 7.2 Distribution : Code R + ggplot 7.3 BoxPlot : Code R + ggplot 7.4 Violin plot 7.5 Violin plot et Boxplot : Code R + ggplot 2 7.6 Pyramides (histogrammes juxtaposés) 7.7 Polygones de fréquences 7.8 Distribution cumulée , Fonction de répartition , CDF 7.9 Distribution cumulée , Fonction de répartition , CDF 7.10 Distribution cumulée simple : Code R + ggplot 7.11 Distribution cumulée par groupe : Code R + ggplot 7.12 Dot Strip Plot", " Chapitre 7 Visualiser une distribution Histogramme Distribution BoxPlot Violin plot Pyramides (histogrammes jusxtaposés) Polygones de fréquences Distribution cumulée , Fonction de répartition , CDF Dot strip plot 7.1 Histogramme : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins histo_mass &lt;- ggplot(mydata)+ geom_histogram(aes(x=body_mass_g), fill=&quot;darkorchid4&quot;, color=&quot;darkgray&quot;, bins=50)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Histogram&quot;)+ ylab(&quot;Count&quot;)+theme_light() histo_mass 7.2 Distribution : Code R + ggplot ⚠ ce n’est pas exactement une probabilité, mais une densité de probabilité. Pour obtenir la probabilité , il faut intégrer sur un petit \\(dx\\). library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins distrib_mass &lt;- ggplot(mydata)+ geom_density(aes(x=body_mass_g), fill=&quot;darkorchid4&quot;, color=&quot;darkgray&quot;)+ geom_vline(aes(xintercept=mean(body_mass_g, na.rm = T)), color=&quot;black&quot;, size=0.4, linetype=&quot;dashed&quot; )+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Probability density and mean&quot;)+ ylab(&quot;Count&quot;)+theme_light() distrib_mass 7.3 BoxPlot : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins boxplot_mass &lt;- ggplot(mydata)+ geom_boxplot(aes(x=body_mass_g, y=species, color=species))+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;BoxPlot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() boxplot_mass 7.4 Violin plot Dsitribution+miroir Utile pour des distributions complexes, e.g. mal résumées par la moyenne et la dispersion. library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins violin_mass &lt;- ggplot(mydata)+ geom_violin(aes(y=body_mass_g, x=species, fill=species), color=&quot;gray&quot;, trim=F)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;ViolinPlot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() violin_mass 7.5 Violin plot et Boxplot : Code R + ggplot 2 library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins violin_mass &lt;- ggplot(mydata)+ geom_violin(aes(y=body_mass_g, x=species, fill=species), color=&quot;lightgray&quot;, trim=F)+ geom_boxplot(aes(y=body_mass_g, x=species, fill=species), color=&quot;black&quot;, fill=&quot;#eeeeee&quot; ,width=0.1)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;ViolinPlot and Boxplot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() violin_mass 7.6 Pyramides (histogrammes juxtaposés) lorsqu’une des variables est qualitatives à deux modalités : library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins pyramide_mass &lt;- ggplot(mydata, aes(fill = sex)) + geom_bar(data = subset(mydata, sex == &quot;female&quot;), stat = &quot;bin&quot;, aes(x=body_mass_g, y=..count..*(-1)), color=&quot;grey&quot;) + geom_bar(data = subset(mydata, sex == &quot;male&quot;), stat = &quot;bin&quot;, aes(x=body_mass_g), color=&quot;grey&quot;) + scale_y_continuous(labels = paste0(as.character(c(seq(20, 0, -10), seq(10, 20, 10))))) + ylab(&quot;count&quot;)+ coord_flip()+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Pyramid Plot by sex&quot;)+ theme_light() pyramide_mass 7.7 Polygones de fréquences “Histogramme en courbe” Utile pour comparer plusieurs distributions library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins freqpoly_mass &lt;- ggplot(mydata)+ geom_freqpoly(aes(x=body_mass_g, color=species), bins=50)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Frequence Polygons&quot;)+ ylab(&quot;Count&quot;)+theme_light() freqpoly_mass 7.8 Distribution cumulée , Fonction de répartition , CDF Courbe \\(x,y\\), en \\(x\\) la valeur de la variable \\(V\\), en \\(y\\) la probabilité empririque d’avoir dans la population, un individu pour lequel \\(V\\leq x\\) i.e. c’est la fonction \\(F_{V}(x)=\\mathbb {P} (V\\leq x)\\) 7.9 Distribution cumulée , Fonction de répartition , CDF Permet de superposer les CDF de sous groupes de la population. ici : la race des penguins 7.10 Distribution cumulée simple : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins plot_mass &lt;- ggplot(mydata)+ stat_ecdf(aes(x= body_mass_g),color=&quot;darkorchid4&quot;)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Cumulative Distribution Function&quot;)+ ylab(&quot;Probability&quot;)+theme_light() plot_mass 7.11 Distribution cumulée par groupe : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins plot_mass &lt;- ggplot(mydata)+ stat_ecdf(aes(x= body_mass_g,color=species))+ #on affecte la couleur à la variable modale labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Cumulative Distribution Function&quot;)+ ylab(&quot;Probability&quot;)+theme_light() plot_mass 7.12 Dot Strip Plot "],["bonus.html", "Chapitre 8 Bonus 8.1 Fat-tail distributions 8.2 Distribution rang-taille des villes de france 8.3 Transformation logarithmique 8.4 Distribution rang-log(taille)", " Chapitre 8 Bonus 8.1 Fat-tail distributions Les distributions très asymétriques et très étendues sont délicates à résumer. Les indicateurs traditionnels sont plus efficaces lorsque la variabilité des valeurs est moindre, et leur distribution plus symétrique. e.g. Considérer la population moyenne des villes de France a-t’elle du sens ? 8.2 Distribution rang-taille des villes de france Pour mieux voir la distribution et les écarts, on trace la taille des villes en fonction de leur rang 8.3 Transformation logarithmique Appliquer une transformation monotone, bijective et inversible qui “applatisse” la distribution. réduit les écarts entre les valeurs resserre l’essentiel des valeurs \\(\\implies\\) mesure de façon plus robuste tendance, dispersion et forme Ici : le logarithme décimal 8.4 Distribution rang-log(taille) "]]
