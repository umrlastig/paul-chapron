[["index.html", "Analyse Statistique M2 IGAST Préambule Programme du cours et Contenu Reférences Ressources pour l’apprentissage du langage R", " Analyse Statistique M2 IGAST PC 2021-01-13 Préambule Ce document s’adresse en priorité aux étudiants du Master 2 IGAST de l’ENSG, dans le cadre du Module intitulé “Analyse Statistique”, dirigé par Ana-Maria Olteanu-Raimond. Programme du cours et Contenu Ce cours comporte une introduction générale pour situer les statistiques qui y sont abordées. Dans cette introduction, on parle beaucoup d’analyse spatiale, parce que c’est dans ce contexte que les rudiments de statistiques exposés ici vont etre utilisés par les étudiant.e.s du M2 IGAST, mais aucune technique purement spatiale n’est abordée ici. Le programme stricto-sensu est le suivant : Analyse Univariée: Vocabulaire Description de distribution : indicateurs de tendance centrale, quantiles, dispersion , symétrie , applatissement Analyse Bivariée: regression linéaire : R2, p-value corrélation : r de Pearson , rho de Spearman, hypothèse nulle Test du Chi 2 : Construction du tableau d’effectif théorique, calcul du Chi 2 , hypothèse nulle Le reste, c’est du bonus ! Reférences Pour constituer ce cours, j’ai utilisé les références suivantes: Cours M2 IGAST 2018 d’Ana-Maria Olteanu-Raimond Cours M2 IGAST 2017 d’Élodie Buard Probabilités, analyse de données et statistiques , Gilbert Saporta, Editions TECHNIP, 2011 l’excellent cours de Hadrien Commenges https://gitlab.huma-num.fr/hcommenges/cours_statcomplet/-/raw/master/cours_statcomplet.pdf Nombreuses ressources en ligne, parmi lesquelles : http://www.foad-mooc.auf.org/IMG/pdf/424B_-Application_des_methodes_statistiques_d_analyse.pdf http://www.itse.be/statistique2010/co/Module_statistique_FSP.html J’ai également fait un usage immodéré de Wikipedia, Google, et StackOverflow Pour les principes de la visualisation, j’essaye de suivre quelques uns des conseils prodigués par Claus O. Wilke dans son ouvrage Fundamentals of Data Visualization Ressources pour l’apprentissage du langage R R est un langage qui s’apprend «au fil de l’eau», en trouvant des exemples de manipulations et des réponses à des questions sur des forums et sites spécialisé (Stackoverflow principalement). Cependant, l’étudiant.e IGAST désireuse d’aller droit au but et de manipuler des données spatiales avec R pourra se référer en priorité à : R et espace https://framabook.org/r-et-espace/ l’excellente formation à R du Ministère de la Transition Écologique et Solidaire : https://mtes-mct.github.io/parcours-r/ notamment le module 7 : « Analyse spatiale » la présentation du package sf sur https://r-spatial.github.io/sf/articles/sf1.html le livre https://rcarto.github.io/carto_avec_r/ très complet pour la cartographie. "],["intro.html", "Chapitre 1 Introduction générale 1.1 Analyse spatiale : définition 1.2 Analyse spatiale &amp; Analyse Statistique 1.3 Deux approches en analyse spatiale 1.4 Deux familles statistiques 1.5 Vocabulaire", " Chapitre 1 Introduction générale Commençons par le plus important : En présence de données, la première chose à faire est de les visualiser, avant d’entreprendre tout calcul. Cette exploration visuelle permet: d’identifier les intervalles de valeurs des variables, ou leur modalités de se faire une idée de la répartition des valeurs des variables à l’intérieur de leurs intervalles d’identifier des valeurs aberrantes d’observer pour les variables spatialisées , leur répartition dans l’espace en R, pour tracer directement tout un dataframe (=jeu de données) , on utilise la commande plot library(palmerpenguins) #charge un jeu de données nommé &#39;penguins&#39; plot(penguins) #affiche une matrice de graphique Avec un peu d’expérience, on identifie rapidement des caractéristiques utiles : les deux premières variables sont des variables qualitatives à trois modalités les variables suivantes sont quantitatives, les deux dernières semblent corrélées positivement les deux dernières variables sont qualitatives, à deux et trois modalités Ce cours a pour but de vous donner le vocabulaire et les outils nécessaires à préciser le sens de ces caractéristiques, et d’en chiffrer certaines propriétés. L’analyse statistique ne se confond pas avec l’analyse spatiale, bien qu’elles soient parfois cousines. Nous allons commencer par préciser ce qu’on entend par analyse spatiale et statistique, sachant que ce support de cours se concentre sur les prémices de l’analyse statistique : l’analyse univariée 3 et l’analyse bivariée 10 1.1 Analyse spatiale : définition L’analyse spatiale étudie la répartition et l’organisation d’objets localisés L’objectif est de : «déceler en quoi la localisation apporte un élément utile à la connaissances des objets étudiés et peut en expliquer les caractéristiques» — [Pumain, Saint-Julien 97] 1.2 Analyse spatiale &amp; Analyse Statistique L’analyse statistique peut être vue comme l’utilisation de méthodes de calcul pour résumer et généraliser des observations. Ces observations constituent les données. En analyse statistique : On suppose a priori que les unités d’analyse sont des éléments indépendants, et on examine avec des outils statistiques, si les variables qui les décrivent sont elles-aussi indépendantes. On ne s’intéresse pas à la localisation de ces unités d’observation, ni à leur interactions spatiales. En analyse spatiale statistique, au contraire : Les unités d’analyse sont localisables On s’intéresse à leur propriétés y compris et surtout leur localisation et l’effet de celle-ci : on fait l’hypothèse que la localisation des unités peut influencer les valeurs des variables des unités observées. Prenons des exemples volontairement simplistes: En statistiques «normales», on peut examiner le lien entre revenu mensuel et la pointure d’une population: ce lien existe-t-il ? Si oui, quelle est son intensité ? En statistiques spatiales, on peut examiner la répartition des personnes de pointure supérieur à 42 dans les zones littorales : cette répartition a-t-elle une répartition particulière ou au contraire aléatoire ? Quelles régularités peut-on observer dans cette répartition ? , etc. 1.3 Deux approches en analyse spatiale L’analyse spatiale peut désigner deux sortes d’analyse : l’analyse géométrique et l’analyse de données spatiales. L’ analyse géométrique se concentre sur la géométrie (i.e. la forme) des représentations numériques qui décrivent les objets du monde réel : analyse de forme : aire , périmètre, compacité, etc. analyse de réseaux : densité, centralité des nœuds, indice de Shimbel, (voir par exemple https://groupefmr.hypotheses.org/3740) calculs de proximité (distance euclidienne, grands cercles, distance sur réseau, isochrones) Par extension l’analyse géométrique concerne également la création d’objets géométriques : buffers , intersections , unions, etc. L’analyse de données (spatiales) , elle , s’attache à découvrir des relations (des groupes, des lois, des régularités) dans des données spatiales pour aider l’étude de certains phénomènes. En guise d’exemple, on pourra se référer à ce qui est peut être la toute première analyse spatiale par cartographie : l’ étude de la propagation du choléra par John Snow (#fig:img_john_snow)Original map made by John Snow in 1854. Cholera cases are highlighted in black Dans ce cours, nous n’aborderons ni l’une ni l’autre. Nous donnerons des bases d’analyse statistique (donc a-spatiale), dont pourra dépendre une partie de l’analyse de données spatiales 1.4 Deux familles statistiques On peut distinguer dans les statistique les statistiques inférentielles et les statistiques descriptives . 1.4.1 Statistiques inférentielles Les statistiques inférentielles cherchent à caractériser une population (=ensemble d’unités) à partir des caractéristiques d’un échantillon pour lequel on a recueilli des données : par des mesures, des observations, des enquêtes. Les statistiques inférentielles cherchent à répondre de façon mathématiquement rigoureuse à la question suivante : « A partir d’un échantillon , que peut-on attendre (=inférer) de la population ? » Cette famille de statistiques emploie des modèles et des estimateurs pour réaliser des régressions, des estimations, des extrapolations, voire des prévisions. Ce sont les statistiques qui sont utilisées lors des sondages, des recensements, mais aussi dans l’analyse de résultats expérimentaux (par ex. efficacité d’un médicament). La plupart du temps quand on emploie le terme «statistiques» dans le langage courant, c’est de statistiques inférentielles qu’il s’agit. 1.4.2 Statistiques inférentielles : l’exemple des pingouins Penguins data were collected and made available by Dr. Kristen Gorman and the Palmer Station, Antarctica LTER, a member of the Long Term Ecological Research Network. [https://github.com/allisonhorst/palmerpenguins] Dans cet exemple, une régression linaire a été réalisée entre deux variables : la masse du corps de pingouins et la longueur de leurs nageoires. Pour autant que cette régression linaire soit de bonne qualité (cf la section dédiée dans le chapitre 10, la droite de régression, ici en bleu, est un modèle linéaire qui permet , à partir de la valeur d’une des deux variables, de déduire la valeur de l’autre. Par exemple, si on était en présence d’un pingouin avec une règle graduée , mais sans balance, et qu’on mesurait sa nageoire à 197mm, on peut se servir de la droite de régression pour postuler que ce pingouin pèse 4000g. C’est ce calcul qui est appelé parfois prédiction : le modèle linéaire, s’il est bien ajusté au nuage de points , permet de prédire la valeur de la masse du pingouin. 1.4.3 Statistiques descriptives Les statistiques descriptives ont pour but de décrire, résumer, synthétiser les propriétés d’une population, potentiellement très nombreuse, à partir des variables qui décrivent ses individus. Ce résumé peut prendre plusieurs formes : Graphiques : nuages de points , histogrammes, distributions, camemberts… Mesures agrégées : moyenne , médiane, fréquences, caractéristiques des distributions, par exemple leur symétrie, leur aplatissement … calculées à partir des valeurs des variables Liaisons statistiques entre variables : corrélation, covariance, qui sont des mesures de l’intensité du lien qui peut exister entre deux variables Forme et structure des données, par exemple des regroupements, détectées par classification , Analyse en Composantes Principale,… Voici des exemples de graphiques habituels : Le nuage de points est la représentation la plus courrante pour observer deux variables d’une population. L’histogramme est utilisé pour observer la répartition des valeurs d’une variable. Il est recommandé de faire varier le nombre ou l’épaisseur des barres qui le constituent pour ne pas «manquer» des phénomènes dans la distribution de valeurs (par ex. plusieurs modalités fondues en une seule du fait d’une résolution trop grossière) la densité d’une distribution est un autre moyen de représenter la répartition des valeurs d’une variable quantitative? Pour l’interprétation d’un tel graphique, reportez-vous à la section dédiée @ref{interpret_dens} du chapitre @ref{univariee} Ce type de représentation est très populaire malgré des défauts certains (voir par exemple ; https://www.data-to-viz.com/caveat/pie.html) , il est à utiliser avec parcimonie! Dans ce module, nous ferons majoritairement de la statistique descriptive, notamment dans le chapitre d’Analyse Univariée 3. Dans le chapitre d’Analyse Bivariée 10, nous verrons la régression linéaire, qui, lorsque qu’elle est «utile» – c’est à dire que les deux variables présentent effectivement une dépendance suffisamment linéaire pour être bien décrite par une droite– peut être considérée comme une technique de statistique inférentielle , et utilisée pour «prédire» des valeurs, même si nous préférerons parler d’explication plutôt que de prédiction. 1.4.4 Les formats de données wide et long Les données sont la plupart du temps tabulaires, et peuvent apparaître sous deux formats : le format dit long, où chaque observation d’un même individu occupe une ligne le format dit wide, où chaque observation d’un même individu occupe une colonne Exemple de données au format wide: ## subject_ID sex mass measure_t1 measure_t2 ## 1 1 M 7.9 12.3 10.7 ## 2 2 F 6.3 10.6 11.1 ## 3 3 F 9.5 13.1 13.8 ## 4 4 M 11.5 13.4 12.9 Exemple des mêmes données au format long ## subject_ID sex measure value ## 1 1 M pct 7.9 ## 2 2 F pct 6.3 ## 3 3 F pct 9.5 ## 4 4 M pct 11.5 ## 5 1 M measure_t1 12.3 ## 6 2 F measure_t1 10.6 ## 7 3 F measure_t1 13.1 ## 8 4 M measure_t1 13.4 ## 9 1 M measure_t2 10.7 ## 10 2 F measure_t2 11.1 ## 11 3 F measure_t2 13.8 ## 12 4 M measure_t2 12.9 1.5 Vocabulaire Population : Ensemble d’individus. Le nombre d’individus d’une population est appelé l’effectif. On parle aussi de “données”, “corpus”, “échantillon”, “data”, “dataset” . Individus : l’individu est l’unité statistique élémentaire. On parle parfois d’observations, en particuliers lorsqu’on mesure une évolution de quelque chose dans le temps. Très souvent, les individus sont les lignes du tableau des données Variables : les variables sont les caractéristiques d’un individu. On obtient les valeurs des variables par des mesures, des enquêtes, des observations… Très souvent, les variables sont les colonnes du tableau des données. On distingues deux types de variables : les variables quantitatives et les variables qualitatives 1.5.1 Variables quantitatives Ce sont des variables qui représentent une quantité, une grandeur. Ce sont des nombres , et ils sont parfois accompagnés d’une unité. Par exemple : la taille, la masse, le revenu mensuel, la surface, les points de vie,etc. Les variables quantitatives peuvent être continues : \\(var \\in \\mathbb{R}\\) , ou discrètes : \\(var \\in \\mathbb{N}\\) . 1.5.2 Variables qualitatives appelées aussi facteurs ou variables catégorielles. Ce sont des variables dont les valeurs ne sont pas en général des nombres, mais des catégories, qu’on appelle modalités. Par exemple : la couleur des yeux , le genre, la catégorie socio-professionnelle, le type de pokemon, etc. Une variable qualitative ne peut prendre qu’un nombre fini de modalités, qui sont définies par extension (i.e. on donne la liste des valeurs possibles) Il peut arriver qu’une variable qualitative soit codée avec des valeurs numériques, par exemple le niveau d’une alerte ou le code postal d’un département. 1.5.2.1 variables qualitatives nominales Les modalités ne sont pas ordonnées explicitement e.g. situation matrimoniale \\(\\in\\) {marié·e, célibataire, veuf·ve} 1.5.2.2 variables qualitatives ordinales Les modalités sont ordonnées selon un ordre total et non-ambigu. e.g. Echelle de Likert (5 ou 7 valeurs, dont une neutre) satisfaction \\(\\in\\) {Très satisfait, Satisfait, Ni satisfait ni insatisfait, Peu satisfait, Pas du tout satisfait} 1.5.3 Valeur et Nature des variables Les données étant stockées sous la forme de caractères dans des fichiers par exemple CSV, un même caractère ou suite de caractères pourra être interprété de différentes façons à la lecture de ce fichier. Ce n’est pas le cas dans d’autres systèmes comme les bases de données, où les colonnes sont typées à la création. Ainsi la valeur «trois» peut être exprimée dans des variables de nature différentes. Cela peut-être : la valeur numérique ‘3’ , d’une variable quantitative, par exemple une hauteur en mètres. la valeur caractère ‘3’, d’une variable qualitative, par exemple l’arrondissement de paris où se trouve une adresse. Un logiciel ne peut pas trancher seul entre ces deux alternatives, on doit lui indiquer la nature des variables, en l’occurence pour un logiciel de statistiques , indiquer si la variable est quantitative (de type numeric ou integer en R) ou qualitative (de type character ou factor en R). Également, les valeurs manquantes d’un dataset sont parfois exprimées avec les caractères NA (qui signifie “non attribué”), parfois avec NULL , parfois avec rien. Il revient à la personne qui traite les données d’identifier ces valeurs manquantes et de les traiter de façon adéquate. 1.5.4 Types de variables et représentations La représentation des données doit être adaptées au type de variables. La table suivante indique les choix de représentations conventionnels. Type Échelle/Axes quantitative continue continue quantitative discrète discrète qualitative/modale non ordonnée discrète qualitative/modale ordonnée discrète dates continue ou discrète texte aucune ou discrète tiré de Fundamentals of Data Visualization Claus O. Wilke [https://serialmentor.com/dataviz/] "],["difficultés-de-la-statistique.html", "Chapitre 2 Difficultés de la statistique 2.1 Plusieurs discours sont possibles 2.2 Taille et représentativité de l’échantillon 2.3 Le paradoxe de Simpsons 2.4 Échelle individuelle vs. Échelle agrégée 2.5 À quelle échelle observer ? le MAUP 2.6 Rappel: La première “chose à faire”", " Chapitre 2 Difficultés de la statistique Nous donnons ci-dessous quelques exemples de difficultés inhérentes à l’analyse statistique. 2.1 Plusieurs discours sont possibles Les statistiques sont délicates parce qu’un.e statisticien.ne ne peut pas se limiter à des calculs et à la représentation graphique de ses données, mais doit également les décrire et les interpréter. Cette interprétation est elle-même difficile car des discours différents peuvent être produits sur la base de chiffres identiques. Considérons cet exemple, tiré du cours d’Ana-Maria Olteanu-Raimond : Voici les chiffres du bilan d’une entreprise en 2013 et 2014 Ouvriers Cadres 2013 effectif : 500 effectif : 100 salaire : 1300 salaire :2200 2014 effectif : 200 effectif : 400 salaire :1170 salaire : 1980 Mme. AAA : «tous les salaires ont baissé de 10%» Mme. BBB : «le salaire moyen a augmenté d’environ 18%» Ces deux phrases sont justes, et il n’y a pas lieu d’en choisir une plus que l’autre. Un.e analyste consciencieux.se se devrait de mentionner les deux à la fois ! 2.2 Taille et représentativité de l’échantillon Les données ne sont jamais exhaustives: elles sont le résultats de mesures, d’enquête et ne captent qu’une partie, un échantillon de l’ensemble des objets qu’elles décrivent. La taille et la représentativité de cet échantillon sont critiques, et il est évident qu’on ne dit pas les mêmes choses à partir d’un petit échantillon partial qu’à partir d’un vaste échantillon représentatif. Quand on en a la possibilité, il faut toujours privilégier les données les plus nombreuses et les plus représentatives du phénomène étudié. Prenons un exemple avec des données “réelles” , on va calculer la hauteur moyenne des arbres de paris , dont le jeu de données est disponible ici Après filtrage des données pour ne considérer que les arbres entre 1 et 40 mètres de hauteur, on va calculer la hauteur moyennes des arbres du dataset: library(geojsonsf) library(sf) arbres &lt;- geojson_sf(&quot;./data/les-arbres.geojson&quot;) arbres &lt;- filter(arbres, hauteurenm &lt; 40 &amp; hauteurenm &gt; 1 ) mean(arbres$hauteurenm) ## [1] 10.28588 On va maintenant opérer une selection sur les données et ne considérer que les arbres étiquettés comme “jeunes” (variable statdedeveloppement), et calculer leur hauteur moyenne : arbresJeunes &lt;- arbres %&gt;% filter( stadedeveloppement ==&quot;J&quot;) mean(arbresJeunes$hauteurenm) ## [1] 5.691254 Évidemment , la hauteur moyenne des jeunes arbres n’est pas la même que la hauteur moyenne des arbres en général! Observons maintenant l’effet que peut avoir la taille de l’échantillon sur un calcul de moyenne : On va prendre des échantillons du dataset des arbres de Paris de plus en plus petits (on divise par deux la taille de l’échantillons à chaque fois) et on va observer la variation de la hauteur moyenne des arbres de cet échantillon en fonction de la taille de l’échantillon. Pour chaque taille d’échantillon , on réalise plusieurs tirages et on observe les valeurs moyennes de la hauteur en mètres sur ces échantillons nbSpls &lt;- nrow(arbres) spls &lt;- c() while(nbSpls &gt; 1){ nbSpls &lt;- floor(nbSpls/2) spls &lt;- c(spls, nbSpls) } myfunc&lt;- function(taille,data){ return(sample(data,taille,replace = F)) } # tirage simple samples_hauteur &lt;- sapply(spls, myfunc, arbres$hauteurenm) valeurs_moyennes &lt;- sapply(samples_hauteur, mean) names(valeurs_moyennes) &lt;- spls %&gt;% as.character() #on répète fois le tirage spls_sizes &lt;- rep(spls, 50) spl_h &lt;- sapply(spls_sizes, myfunc, arbres$hauteurenm ) spl_moy &lt;- sapply(spl_h, mean) # constitution du dataframe dfhmoy &lt;- data.frame(spl_moy, spls_sizes) dfhmoy$spls_sizes &lt;- factor(dfhmoy$spls_sizes, levels=spls) names(dfhmoy) &lt;- c(&quot;h_moy&quot;, &quot;spl_size&quot;) #graphique ggplot(dfhmoy ,aes(h_moy, spl_size))+ geom_boxplot()+ coord_flip()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ labs(x=&quot;hauteur moyenne en mètre&quot;, y=&quot;taille de l&#39;échantillon&quot;, title=&quot;Sensibilité de la moyenne à la taille de l&#39;échantillon&quot;, subtitle = &quot;chaque échantillon est tiré 50 fois dans la population&quot;) Ce graphique présente sous la forme d’un boxplot (ou boîte à moustaches), la distribution de la valeur des moyennes des hauteurs, calculées sur des échantillons dont la taille varie de 84508 individus, soit la moitié du dataset des arbres filtrés, à 1 individu. Pour chaque taille d’échantillon, on réalise 50 tirages de cette même taille, pour éviter les “coups de chance”, et on calcule pour la moyenne pour chaque taille. On a donc calculé 50 valeurs de moyenne , pour chaque taille d’échantillon. Pour voir comment la valeurs des 50 moyennes varie, on représente la distributions des valeurs de moyenne obtenues sous la forme d’un boxplot. Le boxplot montre l’étendue de la variation d’une variable quantitative . Plus la boîte est grande (étirée), plus les valeurs de la variable qu’il représente varient. Le trait noir au milieu représente la médiance des valeurs. Sur notre graphique, on constate que la médiane des moyenne est très stable et est toujours proche de 10, mais que les tailles des boxplot sont très petites pour les grandes tailles d’échantillons (indiquant que la moyenne des hauteurs varie peu), et qu’au contraire , pour des tailles d’échantillons faibles (moins de 100 individus), la moyenne des hauteurs varie plus fortement. Nous aborderons l’interprétation des boxplots dans le chapitre @ref(univariée) de façon plus précise. Pour finir de se convaincre de ces variations, voici la représentation des valeurs moyennes en fonction de la taille des échantillons sous la forme d’un nuage de point: ggplot(dfhmoy ,aes(h_moy, spl_size))+ geom_point(col=&quot;orange&quot;, size=0.5)+ coord_flip()+ theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))+ labs(x=&quot;hauteur moyenne en mètre&quot;, y=&quot;taille de l&#39;échantillon&quot;, title=&quot;Hauteur moyenne en fonction de la taille d&#39;échantillon&quot;, subtitle = &quot;chaque échantillon est tiré 50 fois dans la population&quot;) 2.3 Le paradoxe de Simpsons Le paradoxe de Simpsons apparaît lorsqu’une population est structurée en groupes et que deux hypothèses contradictoires peuvent être formulées, suivant qu’on prenne en compte les appartenances des individus à ces groupes ou non. source: wikipedia Par exemple, le nuage de points animés ci-dessus, illustre comment on peut formuler deux hypothèses contradictoire concernant la même population : \\(H_A\\) : la variable \\(x\\) est corrélée négativement avec la variable \\(y\\) \\(H_B\\) : la variable \\(x\\) est corrélée positivement avec la variable \\(y\\) \\(H_A\\) est valable si l’on considère les valeurs de la population dans son ensemble et sans tenir compte des groupes qui la structurent. À l’intérieur de chaque groupe, \\(H_B\\) est valable et contredit \\(H_A\\). 2.4 Échelle individuelle vs. Échelle agrégée Lorsqu’on manipule des données spatiales, le territoire sur lequel les données sont disponibles peut être découpé de plusieurs façons. Par exemple, la France se découpe en régions, elles-mêmes décomposées en départements, eux-mêmes décomposés en commune. Un jeu de données spatial est défini à un certain niveau de découpage spatial. Par exemple, on peut disposer du revenu mensuel moyen des foyers par commune, mais on ne dispose pas des données “brutes” qui y ont conduit: les revenus des personnes qui composent les foyer des communes. Si on désire considérer la même variable à un niveau de découpage plus grossier (ici, les régions) ou plus fin (ici, les communes), on devra agréger ou désagréger les données. L’agrégation est relativement directe , la désagrégation l’est beaucoup moins Agrégation On parle d’agrégation lorsqu’on désirer regrouper des données disponibles à un niveau de découpage donné Inférer des caractéristiques concernant les unités agrégées d’après les caractéristiques individuelles Désagrégation ou Ventilation On parle de désagrégation ou de ventilation de données lorsqu’à partir de données disponibles à un niveau de découpage donné, on cherche à simuler une répartition de données à un niveau de découpage plus fin, tout en restant cohérent avec la répartition des données au niveau de découpage originel. Solution triviale donc sans intérêt: Pour une variable de stock \\(V_s\\) (on dit aussi variable d’effectif) , i.e. mesurant une quantité d’objets, et en l’absence de toute autre données ou contraintes, on peut affecter aux \\(n\\) communes du département un nombre constant valant \\(\\frac{V_s}{n}\\). Pour une variable de ratio \\(V_r\\), on peut affecter le même ratio \\(V_r\\) à toutes les mailles qui composent la maille à désagréger. Si on écarte la solution triviale, la désagrégation de données est une opération complexe, pour lesquels il existe cependant plusieurs méthodes de génération de population synthétique respectant certaines contraintes, comme l’Iterative Proportional Fitting Les choses se compliquent encore si les découpages ne sont pas imbriqués les uns dans les autres. Généralement, on agrège les valeurs par des sommes pondérées par la surface des entités spatiales concernées. Un bon aperçu des méthodes d’allocation spatiale est donné dans ce document 2.5 À quelle échelle observer ? le MAUP Puisqu’une même zone peut être découpée de différentes façons, avec des mailles de taille variable, susceptibles d’évoluer dans le temps (par exemple les limites adminsitratives des communes en France), toute question d’analyse spatiale (et donc d’analyse spatiale statistique) comporte une question spécifique à l’échelle d’observation : À quelle échelle observer nos données ? Cette question peut se décomposer en deux sous-questions, liées : quel maillage utiliser ? Par exemple: une maille régulière carrée ou hexagonale, les contours adminsitratifs, les mailles IRIS ? quelle taille de maille choisir ? Il est très difficile de répondre à ces questions dans l’absolu, c’est même un problème «insoluble» appelé le MAUP (Modifiable Areal Unit Problem). Les raisons de cette impossibilité de déterminer le découpage idéal pour observer une donnée spatialisée sont nombreuses. En voici quelques unes, qui je pense sont les principales: La plupart des phénomènes d’intérêts sont multi-scalaires, c’est-à-dire qu’ils peuvent se produire et/ou s’observer à plusieurs niveaux d’échelle. L’agrégation peut faire disparaitre certains détails, certaines spécificités dans la cartographie des données. Des effets de la géométrie du découpage (appelés effets de zonage) modifie la représentation cartographique des données Voici quelques exemples qui montrent ces difficultés. 2.5.1 Effet de zonage Cette image tiré de la page wikipedia gerrymanding, illustre bien comment un découpage d’une même zone peut amener à des résultats de vote différents. (#fig:img_gerryManding)Différentes manières de découper des circonscriptions électorales. 2.5.2 MAUP : exemples Ces exemples sont tirés du rapport ESPON : https://www.espon.eu/sites/default/files/attachments/espon343_maup_final_version2_nov_2006.pdf Vous pouvez noter comme les zones du Sud en découpage NUTS 2 , sont représentées uniformément rose (valeur max du GDP/hab) alors qu’avec un découpage plus fin (NUTS 3), la situation du sud est loin d’être aussi uniforme : on note par exemple que la moitié Est des mailles du Sud-Est a des teintes plus mélangées dans le découpage NUTS3, avec un mélanges de mailles jaunes et bleues, que dans le découpage NUTS2 . De même, les zones frontalières du Luxembourg et de la Belgique apparaissent plus pauvres (teintes jaunes et bleues) dans le découpage NUTS 3 que dans le découpage NUTS2. De manière générale : l’agrégation va “lisser” les aspérités des données, certains contrastes ne «survivent pas» à l’agrégation spatiale. Dans ce deuxième exemple, on voit la forme et la taille des mailles changer. Là aussi, un effet de lissage, indissociable de l’agrégation, fait apparaitre certaines régions comme uniformes et cachent certains singularités: par exemple le fait que les zones les plus lointaines du littoral sont pauvres (teintes oranges à l’arrière du pays, Nord et Nord-Ouest) dans le découpage en mailles carrées de 30km n’apparait pas dans le découpage administratif(les deux vignettes de gauche), tout en longueur. 2.6 Rappel: La première “chose à faire” Représenter/Tracer/Cartographier les variables de la population. Cette exploration visuelle permet: d’identifier les intervalles de valeurs des variables, ou leur modalités de se faire une idée de la répartition des valeurs des variables à l’intérieur de leurs intervalles d’identifier des valeurs aberrantes d’observer pour les variables spatialisées , leur répartition dans l’espace D’autre part, comme le montre l’exemple ci-dessous, les valeurs de statistiques peuvent être trompeuses, et discriminent beaucoup moins bien des situations qualitativement très différentes que notre œil : Les valeurs chiffrées affichées sont la moyenne, l’écart-type et la corrélation des deux séries qui forment le nuage de points. Le chapitre suivant introduira ces notions. "],["univariee.html", "Chapitre 3 Analyse Univariée 3.1 Le concept de distribution 3.2 Exemples de distributions de lois connues 3.3 Histogramme d’une distribution réelle", " Chapitre 3 Analyse Univariée 3.1 Le concept de distribution L’analyse univariée a pour but de décrire et mesurer la répartition des valeurs que peut prendre une variable. On appelle la répartition des valeurs d’un variable sa distribution , que l’on peut approximativement voir comme son «histogramme en continu». Voilà une distribution d’une variable réelle (courbe noire), superposée à son histogramme : Vous pouvez voir avec cet exemple, que la courbe suit les variations de hauteur des colonnes de l’histogramme, tout en lissant les aspérités. C’est de cette courbe que l’on parle lorsqu’on évoque la distribution de la variable. Plus formellement, pour une population donnée, la distribution d’une variable \\(V\\) est définie comme une fonction qui donne la probabilité qu’un individu \\(x\\) pris au hasard dans la population ait la valeur \\(V_x\\) pour la variable \\(V\\) : \\[distribution(V) \\equiv P(V=V_x), \\forall V_x \\in \\Omega_V\\] avec \\(\\Omega_V\\) l’ensemble des valeurs que peut prendre \\(V\\) : l’univers de \\(V\\). Lorsque la variable prend des valeurs réelles, on parle de densité de probabilité, c’est pourquoi on retrouve ce terme “density” sur les axes des ordonnées dans les graphiques de distribution. La forme d’une distribution donne beaucoup d’informations sur les valeurs d’une variable dans une population : valeurs les plus représentées dans la population : les “pics” présence de valeurs extrêmes : la courbe de la distribution est tirées à gauche ou à droite du graphique caractéristiques de sa forme : symétrie, aplatissement etc… Dans notre exemple de distribution de longueur de nageoires en millimètres, on observe deux pics assez doux : l’un aux alentours de 190mm, l’autre de 215mm. On peut l’interpréter ainsi : «la valeurs la plus représentée dans les longueurs de nageoires de cette population de pingouins est de 190mm, suivie de 215mm» 3.1.1 Interpréter la courbe de densité L’histogramme représente l’effectif de la population en fonction de la valeur d’une variable, son interprétation est directe et aisée puisque ce graphique donne une représentation du nombre d’individus par intervalles de valeurs. La représentation d’une distribution est légèrement plus délicate à comprendre mathématiquement. En première approximation , vous pouvez l’interpréter comme un histogramme dont les barres seraient infiniement fines, et dont l’axe des \\(y\\) représenteraient une probabilité au lieu d’un effectif. La densité de probabilité comme son nom l’indique, représente des probabilités: celles d’obtenir, pour un individu dans la population, une certaine valeur de la variable. Le point délicat est qu’une variable continue (i.e. définie sur un intervalle de \\(\\mathbb{R}\\)), peut prendre une infinité de valeurs possibles, et que la probabilité d’obtenir exactement, c’est à dire avec une précision infinie, une valeur est infinitésimale, en fait carrément nulle. Il faut alors considérer la probabilité d’obtenir une valeur, non pas de façon exacte , mais dans un intervalle de valeur. Par exemple, dans le graphique ci-dessous, de s’intérroger sur la probabilité , pour un individu tiré au hasard dans la population , d’avoir une valeur de Variable 1 dans l’intervalle [25;30]. Cela pourrait s’écrire \\(P( 25 \\leq V_1 \\leq 30)\\) et serait égal à l’intégrale de la fonction de densité notée \\(f_{V_1}\\) entre les bornes 25 et 30 de l’intervalle de \\(V_1\\) : \\[P( 25 \\leq V_1 \\leq 30) = \\int_{25}^{30} f_{V_1}(x)dx\\] En pratique , le graphique d’une densité s’interprète en observant la quantité d’aire sous la courbe L’aire totale sous la courbe vaut 1 (cela revient à considérer la somme de toutes les probabilités d’avoir une valeur particulière \\(X\\) dans l’intervalle de valeur de \\(V_1\\)) et par approximation , la valeur de la probabilité d’obtenir une certaine valeur se lit comme la proportion d’aire sous la courbe comprise entre deux bornes proche de la valeur. ## [1] 3.735817 ici , la valeur de \\(P( 25 \\leq V_1 \\leq 30)\\) vaut XXX 3.2 Exemples de distributions de lois connues Parfois certaines distributions ressemblent à des distributions bien connues : on appelle ces distributions des lois. Ce sont des distributions de probabilités que l’on peut formaliser par une équation et dont les statisticiens ont pu dériver des caractéristiques par le calcul. 3.2.1 Loi Gaussienne La plus connue est la distribution Gaussienne, on dit aussi distribution normale du nom de la loi de probabilité qu’elle suit : la loi dite normale. Cette loi a deux paramètres : \\(\\mu\\) la moyenne, i.e. la valeur moyenne qu’auront les valeurs tirées de cette distribution \\(\\sigma\\) l’écart type, qui représente leur écartement par rapport à cette moyenne Nous reviendrons plus loin sur ces deux caractéristiques Voici la distribution d’une population dont la variable \\(V1\\) suit une loi normale de moyenne 0 et d’écart-type 1, qu’on note \\(\\mathscr{N}(0,1)\\) xx &lt;- data.frame(value=rnorm(8000)) plot1 &lt;- ggplot(xx)+ geom_density(aes(x = value), color=&quot;#aaaaaa&quot;, fill=&quot;#44DD99&quot; )+ theme_light()+ labs(title = &quot;Loi Normale&quot;, x=&quot;Valeur de la variable V1 &quot;, y=&quot;densité&quot;) plot1 Voici un histogramme de la même population plot1 &lt;- ggplot(xx)+ geom_histogram(aes(x = value),bins = 50, color=&quot;#aaaaaa&quot;, fill=&quot;#44DD99&quot; )+ theme_light()+ labs(title = &quot;Loi Normale&quot;, x=&quot;Valeur de la variable V1&quot;, y=&quot;Effectif&quot;) plot1 3.2.2 Loi uniforme Comme son nom l’indique, la loi uniforme vaut partout la même valeur entre deux bornes \\(a\\) et \\(b\\), autrement dit , la probabilité d’obtenir une certaine valeur \\(v\\in[a;b]\\) est constante. La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois, la distribution, qui devrait être plate, est courbée aux extrémités. La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout sur \\([a;b]\\) mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois comme ici, la distribution, qui devrait être plate, est courbée aux extrémités. Cela est dû à la façon dont R estime la densité numériquement, biaisée aux extrémités de l’intervalle 3.2.3 Loi log-normale La loi log-normale est comme son nom l’indique, le résultat d’un logarithme appliqué à une variable suivant une loi normale. Notez comme la distribution est «tirée vers la droite». On parle de «queue de distribution». Cette longue queue (“fat tail” in english) indique une grande inégalité dans la population: quelques individus, peu nombreux mais aux valeurs de variable très élevées, et une vaste majorité d’individus dont la valeur de la variable est faible qui constitue le pic de la distribution. Cette loi modélise par exemple l’effet d’un «grand nombre de petits facteurs considérés comme indépendants». Wikipedia nous apprend qu’elle modélise des phénomènes réels tels que la répartition de 97% des salaires du monde, celle de la la longueur et le poids de spécimen d’animaux, la durée des parties d’échecs, etc. 3.3 Histogramme d’une distribution réelle Les distribution de données empiriques ont rarement des formes aussi régulière et identifiable que celles des lois. Voici par exemple l’histogramme de la hauteur des arbres à Paris, selon les données disponibles sur [https://opendata.paris.fr/] Cet histogramme n’est pas très informatif en l’état : si on le lit naïvement, il semblerait que tous les arbres aient une valeur nulle ou quasi-nulle pour leur hauteur en mètres et la circonférences de leur tronc en centimètres. Pourquoi ? Parce que le logiciel qui trace l’histogramme (R) fait du mieux qu’il peut pour tracer les colonnes de l’histogramme correspondant aux valeurs : il ne doit pas en oublier, la hauteur des colonnes doit correspondre à l’effectif (le nombre) d’individus (ici des arbres) par valeur de la variable l’échelle de l’axes \\(x\\) doit «faire tenir» l’étendue des valeurs (\\(x_{max} - x_{min}\\)),sur une quantité de pixels limitée. Ce qui se produit ici est que certains individus ont des hauteurs ou des circonférences renseignées à des valeurs totalement irréalistes, comme nous l’indique les bornes du dernier décile (i.e. les 10% des valeurs les plus élevées ) : ## 0% 10% 20% 30% 40% 50% 60% 70% 80% 90% 100% ## 0 0 4 5 6 8 10 11 15 16 881818 10% des arbres ont une hauteur comprise entre 12 et 881818 mètres: il y a donc quelques arbres, au moins un, dont la hauteur est clairement defectueuse, on peut supposer qu’il s’agit d’une erreur de saisie ou d’ encodage des données (les plus hauts arbres font autour de 120m). On constate aussi qu’au moins 10% des données ont une hauteur nulle. En affichant l’histogramme de cette variable, R a donc du afficher une colonne aux alentours de la valeur 881818, dont la hauteur est vraisemblablement très faible (1 ou 2 individus), en tout cas si faible qu’on ne la distingue pas : son épaisseur est dans le trait de l’axe des \\(x\\) Nous allons donc filtrer les données, pour ne conserver que les arbres dont la hauteur est comprise entre 1 et 60 mètres, ce qui me semble correct comme intervalle pour des hauteurs d’arbres parisiens, mais qui pourrait être discuté. De même , on écarte les arbres dont le tronc excède 2500 cm : On voit ici comme la représentation graphique des variables nous renseigne à deux niveaux : elle nous indique la présence de valeurs aberrantes lors de son affichage “brut”, et une fois filtrée, elle nous montre comment la population varie dans les valeurs de ses variables. Nous allons maintenant voir comment décrire la forme de la répartition de ces valeurs avec des mesures statistiques. "],["tendance.html", "Chapitre 4 Statistique descriptive univariée : la tendance 4.1 Moyenne 4.2 Mode 4.3 Médiane 4.4 Quelle mesure de tendance choisir ? 4.5 Distribution unimodale symétrique 4.6 Histogramme et distribution en R 4.7 Histogramme et distribution en R", " Chapitre 4 Statistique descriptive univariée : la tendance Les distributions de variables dans les données du monde réel sont rarement constantes ou uniformes. Elles exhibent ce qu’on appelle une tendance, c’est-à-dire une valeur autour de laquelle se retrouvent la majorité des individus. Si la forme de la distribution est suffisamment régulière, cette tendance peut servir de résumé statistique de la variable de la population. Les indicateurs de tendance centrale de la distribution d’une variable sont la moyenne et ses variantes, la médiane et le mode. 4.1 Moyenne La moyenne d’une variable \\(x\\) , notée \\(\\bar{x}\\) , s’écrit : \\[ \\bar{x} = \\frac{1}{n}\\sum_{i=0}^{n} x_i \\] 4.1.1 Moyenne pondérée Lorsque des poids \\(p_i\\) sont affectés aux individus, la moyenne pondérée s’écrit : \\[ \\bar{x} = \\frac{1}{\\sum_{i=0}^n pi}\\sum_{i=0}^{n} p_i x_i \\] 4.1.2 Avantages et inconvénients de la moyenne Avantage : chaque valeur compte dans le calcul. Inconvénients : sensibilité aux valeurs extrêmes pas de signification directe sur les variables quantitatives discrètes (e.g. «2.5 enfants/femme» ) Pour y remédier : exclure les outliers, ou restreindre les valeurs considérées par filtrage utiliser un autre estimateur, par exemple la médiane étudier la distribution des valeurs et en cas de multi-modalités, opérer une classification 4.1.3 Autres Moyennes 4.1.3.1 Moyenne geométrique: Elle s’écrit ainsi : \\[ \\bar{x} = \\sqrt[n]{\\prod _{i=0}^{n} x_i}\\] Elle a l’avantage d’être moins sensible à la présence de valeurs extrêmes que la moyenne algébrique. 4.1.3.2 Moyenne quadratique (RMS) Elle s’écrit : \\[\\bar{x} = \\sqrt{\\frac{1}{n}\\sum _{i=0}^{n} x_i^2} \\] 4.1.3.3 Hors sujet : Moyenne glissante Ce n’est pas une moyenne comme les autres, au sens où elle ne résume pas toute une série de valeurs Dans le cas de séries temporelles (i.e. valeurs successives de la même variable), la moyenne glissante est calculée sur une «fenêtre» de \\(n\\) valeurs consécutives. La fenêtre est centrée sur l’instant auquel on calcule la valeur de la moyenne. Par exemple, pour une moyenne glissante sur une fenêtre de taille 10, la valeur en chaque points \\(x_i\\) à la position \\(i\\) dans la série temporelle (on suppose que \\(i&gt;5\\)) vaut la moyenne des de \\(x_i\\) et des 10 valeurs environnantes, 5 en avant , 5 en arrière : \\[\\bar{x} = \\frac{1}{11}\\sum _{j=i-5}^{j=i+5} x_j\\] 4.2 Mode Le mode d’une variable est la valeur la plus fréquente ( d’effectif maximum) d’une variable. Si la variable est quantitative et continue, il faut découper l’étendue de la variable (la différence entre la valeur maximum et minimum) en intervalle égaux , puis réaliser une classification des individus dans ces intervalles et un comptage des effectifs de chaque classe. Dans ce cas, le mode est la moyenne des valeurs min et max des bornes de la classe de plus grand effectif. C’est exactement ce que fait un histogramme graphiquement ! 4.2.1 Avantages et inconvénients du mode Avantages : Peu sensible aux valeurs extrêmes (moins sensible que la moyenne) il s’interprète facilement : c’est la situation la plus fréquente dans la population Inconvénients : le mode ne dépends pas de toutes les observations : la modification d’une seule valeur n’entraîne pas une modification du mode. Cet inconvénient explique sa robustesse aux valeurs extrêmes 4.3 Médiane La médiane est la valeur qui partage une série de valeurs en deux sous-ensembles d’égal effectif Comme en géométrie, la médiane est la valeur de la variable qui est la plus proche de toutes les autres. 4.3.1 Étapes de calcul Déterminer la médiane d’un ensemble de valeurs est très simple : Ordonner les \\(n\\) valeurs de \\(V\\) selon un ordre croissant Calculer le rang \\(rg=\\frac{n+1}{2}\\) si \\(n\\) impair, la valeur médiane est \\(V[rg]\\). Si \\(n\\) est pair, la valeur médiane est entre deux valeurs et est égale à la moyenne de \\(V[\\frac{n}{2}]\\) et \\(V[\\frac{n}{2}-1]\\) Dans cet algo , on suppose qu’on compte les cellules d’un tableau à partir de 0, comme en python. En R, où on compte les cellules à partir de 1 , il faudrait ajouter 1 à tous les indices. 4.3.2 Avantages et inconvénients de la médiane Avantages : Souvent plus pertinente que la moyenne Peu sensible aux valeurs extrêmes: quelques valeurs très fortes ou très faibles ne modifie pas sa valeur elle s’interprète facilement : comme elle divise en deux la distribution, un individu sur deux a une valeur inférieure (respectivement supérieure) à la médiane. Inconvénient : Comme le mode, la médiane ne dépend pas de toutes les observations : la modification d’une seule valeur n’entraine pas une modification de la médiane. Notons que la robustesse de la médiane est bien utile dans le cas de distribution particulièrement asymétriques, où la moyenne est dégradée par les valeurs extrêmes, à droite (valeurs très élevées) ou à gauche (valeurs très faibles). Par exemple , pour les revenus mensuels en équivalent temps plein en France en 2016 : le revenu mensuel net moyen est de 2 238 €, le revenu mensuel net médian est de 1 789 € : selon l’[https://www.insee.fr/fr/statistiques/4277680?sommaire=4318291] Supposons qu’on cherche à évaluer si un salaire mensuel net équivalent temps plein de 2000€ est un bon salaire en France, sans définir trop rigoureusement ce qui signifie «bon». 2000€ est inférieur à la moyenne du pays, on peut le considérer comme trop bas pour être «bon». 2000€ est supérieur au salaire médian, il est supérieur à (au moins) la moitié des salaires du pays, et on peut le considérer comme un «bon» salaire. Cette double interprétation est due au fait que certains salaires très élevés, mais d’effectifs peu nombreux, tirent la distribution du salaire vers la droite, et avec eux, la moyenne. 4.4 Quelle mesure de tendance choisir ? Tout dépend de la distribution ! (cette réponse est malheureusement quasiment universelle, d’où l’importance de toujours représenter visuellement les variables pour décider en connaissance de cause ) Si la distribution n’a pas de longue queue (on dit aussi traîne) , la moyenne et la médiane sont adaptées. Si la distribution exhibe plusieurs modes , il faut réaliser une classification puis calculer médiane et moyenne pour chaque classe. Le mode est privilégié pour les variables nominales c’est-à-dire des variables qualitatives dont les modalités ne sont pas ordonnées, et si on désire considérer «le cas le plus fréquent» 4.4.1 Cas délicat : Distribution bimodale Parfois une variable peut être bimodale, c’est à dire avoir deux intervalles de valeurs majoritaires Que choisir dans un tel cas : moyenne ou médiane ? 4.5 Distribution unimodale symétrique xx &lt;- data.frame(value=rnorm(2900,mean = 5, sd = 1)) plot1 &lt;- ggplot(xx)+ geom_line(aes(x = value),stat = &quot;density&quot;, color=&quot;#44DD99&quot;, lwd= 1.3)+ geom_vline(xintercept = mean(xx$value), color=&quot;red&quot;)+ geom_vline(xintercept = median(xx$value) + 0.02,color=&quot;blue&quot;)+ annotate(&quot;text&quot;, x=c(4.5,5.5), y=c(0.2,0.2), colour=c(&quot;red&quot;,&quot;blue&quot;),label=c(&quot;mean&quot;, &quot;median&quot;))+ theme_light() plot1 4.6 Histogramme et distribution en R la fonction hist affiche un histogramme d’un vecteur numerique: x &lt;- rnorm(2500) #init hist(x) 4.7 Histogramme et distribution en R un histogramme n’a pas de sens pour une variable qualitative. On peut utiliser barplot,⚠ mais ce n’est plus une distribution ! x &lt;- sample(month.name, 2500, replace=T) tx &lt;- table(x) barplot(tx , las=2) "],["statistique-descriptive-univariée-la-dispersion.html", "Chapitre 5 Statistique descriptive univariée : la dispersion 5.1 La dispersion statistique 5.2 Variance et Écart-type 5.3 Variance et Écart-type 5.4 Précaution 5.5 Lorsque \\(X\\sim \\mathscr{N}(\\mu,\\sigma)\\) 5.6 Quantiles 5.7 Déciles 5.8 Ecarts inter-quartiles et inter-déciles 5.9 Les boîtes à moustaches (boxplots) 5.10 Interprétation des boxplots 5.11 Avantages et inconvénient des quantiles 5.12 Le coefficient de variation 5.13 Comparaison de dispersion de deux distributions de valeurs. 5.14 (Mauvaise) Comparaison visuelle de deux distributions 5.15 Comparaison visuelle de dispersion de deux distributions", " Chapitre 5 Statistique descriptive univariée : la dispersion Variance, écart-type, Coeff. de variation. 5.1 La dispersion statistique Tendance des valeurs d’une variable à se disperser autour des valeurs des tendances centrales. mydataset &lt;- data.frame(X=rnorm(900), Y=rnorm(900)) plot1 &lt;- ggplot(mydataset)+ geom_point(aes(x=X, y=Y), fill=&quot;#44DD99&quot;, color=&quot;#666666&quot;, shape=21)+ coord_equal()+theme_light() plot1 5.2 Variance et Écart-type La variance est la somme des écarts carrés à la moyenne rapporté à l’effectif \\(\\displaystyle var_X= \\frac{1}{n}\\sum_{i=1}^{n}(x_i -\\bar{x})^2\\) Avec : * \\(X\\) une variable * \\(x_i\\) les valeurs de la variables * \\(\\bar{x}\\) la moyenne de \\(X\\) * \\(n\\) l’effectif \\(\\sigma_X = \\sqrt{var_X}\\) : l’écart type est la racine carrée de la variance 5.3 Variance et Écart-type Variance et écart-type rendent compte de la dispersion de la variable autour de sa moyenne. Ils sont sensibles aux valeurs extrèmes et toujours positifs. Si \\(var_X = 0\\) ou \\(\\sigma_X = 0\\) , alors \\(X\\) est constante. Un écart-type faible indique que les valeurs sont réparties de façon homogène autour de la moyenne. 5.4 Précaution ⚠Variance et écart type n’ont d’intérêt que pour qualifier des distributions unimodales, et (à peu près) symétriques (i.e. proche de la Gaussienne) 5.5 Lorsque \\(X\\sim \\mathscr{N}(\\mu,\\sigma)\\) \\([-\\sigma;\\sigma] \\approx \\frac{2}{3}\\) de l’effectif \\([-2\\sigma;2\\sigma] \\approx\\) 95% de l’effectif 5.6 Quantiles La médiane sépare une population en deux classes d’égal effectif selon la valeur d’une variable (quantitative). Les quantiles séparent une population en \\(n\\) classes d’égal effectif Les quartiles d’une population selon une variable \\(X\\) sont trois valeurs, \\(Q_1,Q_2,Q_3\\) qui séparent la population en quatre classes d’égal effectif. 25% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_1\\) 50% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_2\\) (médiane) 75% des valeurs de \\(X\\) sont strictement inférieures à \\(Q_3\\) 5.7 Déciles Les déciles sont les 9 quantiles \\(Q_1,Q_2,\\dots,Q_9\\) qui séparent une population selon la valeur d’une variable quantitative en 10 classes d’égal effectif. 5.8 Ecarts inter-quartiles et inter-déciles Deux mesures de la dispersion d’une distribution : Écart inter-quartile: \\(Q_3-Q_1\\) , capture 50% des valeurs de la population les plus proches de la médiane Écart inter-déciile: \\(Q_9-Q_1\\) , capture 80% des valeurs de la population les plus proches de la médiane 5.9 Les boîtes à moustaches (boxplots) représentation courante de la dispersion d’une variable à l’aide de quartiles plot1 &lt;- ggplot(iris)+ geom_boxplot(aes(y=Sepal.Width,x= Species) ) + coord_flip() plot1 5.10 Interprétation des boxplots La marque centrale de la boîte est la médiane Les bords de la boîte sont les quartiles \\(Q_1\\) et \\(Q_3\\) Les extrémités des moustaches vont jusqu’à la plus grande (resp. la plus petite ) valeur inférieure (resp. supérieure) à 1.5 fois l’écart interquartile Les valeurs qui dépassent les moustaches sont affichées sous formes de points 5.11 Avantages et inconvénient des quantiles 5.11.1 Avantages Peu sensibles aux distributions aplaties et aux valeurs extrèmes L’écart inter-quantile est plus robuste que l’écart-type 5.11.2 Inconvénients Parfois délicat pour les variables quantitatives discrètes Les écarts inter-quantiles négligent l’influence des valeurs extrèmes sur la distribution 5.12 Le coefficient de variation Le coefficient de variation (\\(CV\\)) est une autre mesure de dispersion. C’est le ratio entre l’écart-type \\(\\sigma_x\\) et la moyenne \\(\\bar{x}\\) d’une variable quantitative \\(X\\). \\(\\displaystyle CV(X)=\\frac{\\sigma_x}{\\bar{x}}\\) Plus il est important , plus la dispersion est grande. Plus il est proche de 0, plus les données sont homogènes. Il souffre des mêmes inconvénients que la moyenne et l’écart-type : sensibilité aux valeurs extrèmes. 5.13 Comparaison de dispersion de deux distributions de valeurs. Exemple : deux communes versent des aides aux entreprises locales. Commune A : moyenne = 390 euros, \\(\\sigma\\) = 30 euros Commune B : moyenne = 152 euros, \\(\\sigma\\) = 8 euros Pour quelle commune les aides sont les plus homogènes? On pourrait aussi comparer des distribution de valeurs exprimées dans des unités différentes ! 5.14 (Mauvaise) Comparaison visuelle de deux distributions Pour échantilloner dans une loi normale : fonction rnorm A &lt;- rnorm(n = 10000, mean = 390, sd = 30) B &lt;- rnorm(n = 10000, mean = 152, sd = 8) par(mfrow=c(1, 2)) #2 graphes en colonnes hist(A, probability = T) lines(density(A), col=&quot;red&quot;) hist(B, probability = T) lines(density(B), col=&quot;red&quot;) Qu’est ce qui ne va pas ? 5.15 Comparaison visuelle de dispersion de deux distributions Il faut une échelle commune ! A &lt;- rnorm(n = 10000, mean = 390, sd = 30) B &lt;- rnorm(n = 10000, mean = 152, sd = 8) par(mfrow=c(1, 2)) hist(A, probability = T, xlim = c(50,600), ylim = c(0,0.05)) lines(density(A), col=&quot;red&quot;) hist(B, probability = T,xlim = c(50,600), ylim = c(0,0.05)) lines(density(B), col=&quot;red&quot;) "],["statistique-descriptive-univariée-la-forme.html", "Chapitre 6 Statistique descriptive univariée : la forme 6.1 Asymétrie des distributions. 6.2 les Coefficients de Pearson 6.3 Interprétation des coefficients d’asymétrie 6.4 Le coefficient de Fischer 6.5 L’aplatissement des distributions (kurtosis) 6.6 Coefficient d’applatissement : kurtosis", " Chapitre 6 Statistique descriptive univariée : la forme Symétrie , applatissement 6.1 Asymétrie des distributions. 6.2 les Coefficients de Pearson Deux moyens simples d’estimer l’asymétrie \\(\\displaystyle C_1 = \\frac{\\bar{x} - mode(X)}{\\sigma_x}\\) \\(\\displaystyle C_2 = \\frac{3(\\bar{x} - mediane(X))}{\\sigma_x}\\) 6.3 Interprétation des coefficients d’asymétrie si le coefficient nul, la distribution est symétrique si le coefficient est négatif, la distribution est déformée à gauche de la médiane (sur-représentation de valeurs faibles, à gauche) si le coefficient est positif, la distribution est déformée à droite de la médiane (sur-représentation de valeurs fortes, à droite) 6.4 Le coefficient de Fischer Ce coefficient est le moment d’ordre 3 de la variable \\(X\\) ( de moyenne \\(\\mu\\) et d’écart-type \\(\\sigma\\)) centrée réduite \\(\\displaystyle skewness&#39;=\\mathbb{E}\\bigg[\\bigg(\\frac{X-\\mu}{\\sigma}\\bigg)^3\\bigg]=\\frac{\\sum_{i=0}^{n} (x_i - \\bar{x})^3}{n\\sigma^3}\\) 6.5 L’aplatissement des distributions (kurtosis) Courbe piquée: Peu de variation, distribution relativement homogène, beaucoup de valeurs égales ou proches de la moyenne. Courbe applatie: Variations importantes, distribution relativement hétérogène, beaucoup de valeurs s’éloignent de la moyenne. 6.6 Coefficient d’applatissement : kurtosis Coefficient non normalisé : \\(\\displaystyle K=\\frac{\\sum_{i=1}^{n}(x_i -\\bar{x})^4}{n\\sigma^4}\\) Si la distribution est normale , \\(K= 3\\) Si \\(K&gt;3\\), la distribution est plus applatie Si \\(K&lt;3\\), la distribution est moins applatie On normalise parfois en considérant \\(K&#39;=K-3\\) (excès d’applatissement) "],["représentation-dune-distribution-et-échelle-de-couleurs.html", "Chapitre 7 Représentation d’une distribution et Échelle de couleurs 7.1 Distribution et Échelle de couleurs 7.2 Distribution et Échelle de couleurs 7.3 Exemple avec la surface des quartiers de Paris 7.4 Allure de la distribution 7.5 Affichage par défaut : 7.6 Jenks à 5 , 7 et 9 classes 7.7 Jenks à 5 , 7 et 9 classes 7.8 Effectifs égaux 7.9 Intervalles égaux (7) 7.10 Ecart types 7.11 Guides de choix de la méthode de classification 7.12 Autres classifications 7.13 Transformations des données 7.14 Variables centrées-réduites", " Chapitre 7 Représentation d’une distribution et Échelle de couleurs 7.1 Distribution et Échelle de couleurs Pour une variable quanti. continue qu’on souhaite colorer, il n’est pas toujours possible de graduer une échelle de couleur continue. Il faut (souvent) classer les valeurs en catégories. Le nombre de classes et les méthodes de classification varient. En général 5,7 ou 9 classes : \\(&lt;5\\) trop peu de détails \\(&gt;9\\) difficile de distinguer les classes proches 7.2 Distribution et Échelle de couleurs Méthodes de classifications de Qgis Ruptures Naturelles (Jenks) : Minimisation des variances intra-classe et maximisation des variances inter-classe Effectifs égaux (quantiles) Intervalles égaux Ecart-type : intervales de 1 ou 0.5 \\(\\sigma\\) Jolies ruptures : intervalle égaux “décalés” pour faire joli : nombre ronds, puissances de 10, … 7.3 Exemple avec la surface des quartiers de Paris quartiers &lt;- st_read(&quot;data/quartier_paris.shp&quot;) plot(quartiers$geometry) 7.4 Allure de la distribution hist(quartiers$surface,breaks = 15) 7.5 Affichage par défaut : par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;]) par defaut la fonction plot de sf utilise la méthode “pretty” avec 10 ruptures (\\(9\\pm1\\) classes) =&gt; ce sont des intervalles égaux. 7.6 Jenks à 5 , 7 et 9 classes 7.7 Jenks à 5 , 7 et 9 classes Code R correspondant : par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 5, main = &quot;5 breaks&quot;) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 7, main=&quot;7 breaks&quot;) plot(quartiers[&quot;surface&quot;], breaks=&quot;jenks&quot;, nbreaks = 9, main= &quot;9 breaks&quot;) 7.8 Effectifs égaux 7.9 Intervalles égaux (7) par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;equal&quot;, nbreaks = 7, main = &quot;Intervalles égaux&quot;) 7.10 Ecart types par(mar=c(0,0,0,0)) plot(quartiers[&quot;surface&quot;], breaks=&quot;sd&quot;,main = &quot;Écart-type&quot;) \\(\\approx\\) méthode des jolies ruptures sur variable centrée réduite 7.11 Guides de choix de la méthode de classification Pour les classification manuelles : les classes doivent contenir toutes les valeurs, être sans recouvrement, contigües et distinctes. Procéder par essai-erreur attention aux décimales et aux extrémités si distribution uniforme \\(\\rightarrow\\) Intervalles égaux si distribution asymétrique \\(\\rightarrow\\) Effectifs égaux, Jenks , progression géométrique (rare). si distribution symétrique \\(\\rightarrow\\) Écart-type, intervalle égaux 7.12 Autres classifications consultez la doc de la fonction classInt du package du même nom 7.13 Transformations des données \\(x \\mapsto log(x)\\) pour une distribution asymétrique à droite ou \\(x \\mapsto \\sqrt x\\) si moins asymétrique \\(x \\mapsto x^2\\) pour une distribution asymétrique à gauche ou \\(x \\mapsto x^3\\) si très asymétrique (⚠ toujours vérifier l’allure de la distribution transformée) 7.14 Variables centrées-réduites ⚠ En principe, uniquement lorsque la distribution d’une variable est proche d’une gaussienne ⚠ Centrer : soustraire la moyenne Réduire : diviser par l’écart-type une variable centrée réduite est exprimée en «écarts-types à la moyenne» \\(\\rightarrow\\) permet de repérer les valeurs extrèmes (\\(&lt;2\\sigma\\) ou \\(&gt;2\\sigma\\)) \\(\\rightarrow\\) utile pour comparer des individus selon un grand nombre de variables (tableaux de synthèse) "],["visualiser-une-distribution.html", "Chapitre 8 Visualiser une distribution 8.1 Histogramme : Code R + ggplot 8.2 Distribution : Code R + ggplot 8.3 BoxPlot : Code R + ggplot 8.4 Violin plot 8.5 Violin plot et Boxplot : Code R + ggplot 2 8.6 Pyramides (histogrammes juxtaposés) 8.7 Polygones de fréquences 8.8 Distribution cumulée , Fonction de répartition , CDF 8.9 Distribution cumulée , Fonction de répartition , CDF 8.10 Distribution cumulée simple : Code R + ggplot 8.11 Distribution cumulée par groupe : Code R + ggplot 8.12 Dot Strip Plot", " Chapitre 8 Visualiser une distribution Histogramme Distribution BoxPlot Violin plot Pyramides (histogrammes jusxtaposés) Polygones de fréquences Distribution cumulée , Fonction de répartition , CDF Dot strip plot 8.1 Histogramme : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins histo_mass &lt;- ggplot(mydata)+ geom_histogram(aes(x=body_mass_g), fill=&quot;darkorchid4&quot;, color=&quot;darkgray&quot;, bins=50)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Histogram&quot;)+ ylab(&quot;Count&quot;)+theme_light() histo_mass 8.2 Distribution : Code R + ggplot ⚠ ce n’est pas exactement une probabilité, mais une densité de probabilité. Pour obtenir la probabilité , il faut intégrer sur un petit \\(dx\\). library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins distrib_mass &lt;- ggplot(mydata)+ geom_density(aes(x=body_mass_g), fill=&quot;darkorchid4&quot;, color=&quot;darkgray&quot;)+ geom_vline(aes(xintercept=mean(body_mass_g, na.rm = T)), color=&quot;black&quot;, size=0.4, linetype=&quot;dashed&quot; )+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Probability density and mean&quot;)+ ylab(&quot;Count&quot;)+theme_light() distrib_mass 8.3 BoxPlot : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins boxplot_mass &lt;- ggplot(mydata)+ geom_boxplot(aes(x=body_mass_g, y=species, color=species))+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;BoxPlot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() boxplot_mass 8.4 Violin plot Dsitribution+miroir Utile pour des distributions complexes, e.g. mal résumées par la moyenne et la dispersion. library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins violin_mass &lt;- ggplot(mydata)+ geom_violin(aes(y=body_mass_g, x=species, fill=species), color=&quot;gray&quot;, trim=F)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;ViolinPlot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() violin_mass 8.5 Violin plot et Boxplot : Code R + ggplot 2 library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins violin_mass &lt;- ggplot(mydata)+ geom_violin(aes(y=body_mass_g, x=species, fill=species), color=&quot;lightgray&quot;, trim=F)+ geom_boxplot(aes(y=body_mass_g, x=species, fill=species), color=&quot;black&quot;, fill=&quot;#eeeeee&quot; ,width=0.1)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;ViolinPlot and Boxplot by Species&quot;)+ ylab(&quot;Count&quot;)+theme_light() violin_mass 8.6 Pyramides (histogrammes juxtaposés) lorsqu’une des variables est qualitatives à deux modalités : library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins pyramide_mass &lt;- ggplot(mydata, aes(fill = sex)) + geom_bar(data = subset(mydata, sex == &quot;female&quot;), stat = &quot;bin&quot;, aes(x=body_mass_g, y=..count..*(-1)), color=&quot;grey&quot;) + geom_bar(data = subset(mydata, sex == &quot;male&quot;), stat = &quot;bin&quot;, aes(x=body_mass_g), color=&quot;grey&quot;) + scale_y_continuous(labels = paste0(as.character(c(seq(20, 0, -10), seq(10, 20, 10))))) + ylab(&quot;count&quot;)+ coord_flip()+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Pyramid Plot by sex&quot;)+ theme_light() pyramide_mass 8.7 Polygones de fréquences “Histogramme en courbe” Utile pour comparer plusieurs distributions library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins freqpoly_mass &lt;- ggplot(mydata)+ geom_freqpoly(aes(x=body_mass_g, color=species), bins=50)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Frequence Polygons&quot;)+ ylab(&quot;Count&quot;)+theme_light() freqpoly_mass 8.8 Distribution cumulée , Fonction de répartition , CDF Courbe \\(x,y\\), en \\(x\\) la valeur de la variable \\(V\\), en \\(y\\) la probabilité empririque d’avoir dans la population, un individu pour lequel \\(V\\leq x\\) i.e. c’est la fonction \\(F_{V}(x)=\\mathbb {P} (V\\leq x)\\) 8.9 Distribution cumulée , Fonction de répartition , CDF Permet de superposer les CDF de sous groupes de la population. ici : la race des penguins 8.10 Distribution cumulée simple : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins plot_mass &lt;- ggplot(mydata)+ stat_ecdf(aes(x= body_mass_g),color=&quot;darkorchid4&quot;)+ labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Cumulative Distribution Function&quot;)+ ylab(&quot;Probability&quot;)+theme_light() plot_mass 8.11 Distribution cumulée par groupe : Code R + ggplot library(palmerpenguins) data(package = &#39;palmerpenguins&#39;) mydata &lt;- penguins plot_mass &lt;- ggplot(mydata)+ stat_ecdf(aes(x= body_mass_g,color=species))+ #on affecte la couleur à la variable modale labs(title = &quot;Penguins Body Mass&quot;, subtitle = &quot;Cumulative Distribution Function&quot;)+ ylab(&quot;Probability&quot;)+theme_light() plot_mass 8.12 Dot Strip Plot "],["bonus.html", "Chapitre 9 Bonus 9.1 Fat-tail distributions 9.2 Distribution rang-taille des villes de france 9.3 Transformation logarithmique 9.4 Distribution rang-log(taille)", " Chapitre 9 Bonus 9.1 Fat-tail distributions Les distributions très asymétriques et très étendues sont délicates à résumer. Les indicateurs traditionnels sont plus efficaces lorsque la variabilité des valeurs est moindre, et leur distribution plus symétrique. e.g. Considérer la population moyenne des villes de France a-t’elle du sens ? 9.2 Distribution rang-taille des villes de france Pour mieux voir la distribution et les écarts, on trace la taille des villes en fonction de leur rang 9.3 Transformation logarithmique Appliquer une transformation monotone, bijective et inversible qui “applatisse” la distribution. réduit les écarts entre les valeurs resserre l’essentiel des valeurs \\(\\implies\\) mesure de façon plus robuste tendance, dispersion et forme Ici : le logarithme décimal 9.4 Distribution rang-log(taille) "],["bivariee.html", "Chapitre 10 Analyse Bivariée", " Chapitre 10 Analyse Bivariée "],["introduction-rappels.html", "Chapitre 11 Introduction &amp; Rappels 11.1 Rappel : Deux familles statistiques 11.2 Rappel : Deux familles statistiques 11.3 Rappel : Vocabulaire 11.4 L’objet du cours : l’ Analyse Bivariée 11.5 Mise en garde 11.6 Analyse bivariée avec des données spatiales", " Chapitre 11 Introduction &amp; Rappels 11.1 Rappel : Deux familles statistiques 11.1.1 Statistiques inférentielles Pour répondre à la question : «A partir d’un échantillon , que peut-on attendre (inférer) de la population ?» Modèles, estimateurs, … : régression, estimation, extrapolation Liaisons statistiques : corrélation, covariance test statistiques, notions de probabilités e.g. sondages, rencensement, intervalle de confiance , prédictions, … 11.2 Rappel : Deux familles statistiques 11.2.1 Statistiques descriptives Pour résumer, synthétiser, rendre intelligible, les propriétés d’une population à partir des variables qui décrivent les individus et la répartition de leurs valeurs. Graphiques (histogrammes, boxplots, ) Mesures (fréquences , distributions , moments) classification, ACP,… 11.3 Rappel : Vocabulaire Population : Ensemble d’individus “données”, “corpus”, “échantillon”, “data” Individu : Unité statistique élémentaire = «les lignes du tableau» Variables : Caractéristiques, propriétés d’un individu, mesurées par des enquêtes, des observations,… = «les colonnes du tableau» 11.4 L’objet du cours : l’ Analyse Bivariée Objectif : Analyser le lien entre deux variables, par exemple : lien entre deux variables quantitatives “nombre d’habitants et nombre de lignes de bus par département” “nombre de lignes de bus en 1998 et en 2018” lien entre deux variables qualitatives “couleur des yeux et port de lunettes” lien entre une variable quantitative, une variable qualitative “taille et couleur des yeux” 11.5 Mise en garde Une liaison, même très forte, entre deux variables, n’indique pas la causalité! ⚠ Erreur très courrante, très tentante. © TylerVigen http://tylervigen.com/spurious-correlations 11.6 Analyse bivariée avec des données spatiales 11.6.1 Données spatiales Individus restreints spatialement (selection spatiale) variables “géographique” (e.g. lieu de résidence) renseignées pour les individus prise en compte des distances ? \\(\\rightarrow\\) modèle gravitaire 11.6.2 Données localisées Auto-corrélation spatiale (Moran’s I) Geographicaly Weightd Regression (GWR) \\(\\approx\\) regression linéaire avec prise en compte de la distance entre individus "],["régression-linéaire.html", "Chapitre 12 Régression linéaire 12.1 Première étape 12.2 Diverses formes des dépendances 12.3 Les étapes 12.4 Régression linéaire 12.5 Régression linéaire 12.6 Régression linéaire : le modèle 12.7 La grande question 12.8 Comment evaluer la “validité” du modèle linaire ? 12.9 le \\(R^2\\) 12.10 le \\(R^2\\) 12.11 la p-value 12.12 la p-value 12.13 l’Hypothèse nulle 12.14 Format des resultats donnés par avec R 12.15 Bonus: Critères de significativité du lien linéaire 12.16 Bonus: Evaluation de l’indépendance des résidus avec R 12.17 Bonus:Les 4 graphiques résultats de la fonction lm 12.18 Bonus: Évaluer l’homogénéité des résidus avec R 12.19 Bonus: Evaluer la normalité de la distribution des résidus avec R 12.20 Bonus: Evaluer l’homoscédasticité des résidus", " Chapitre 12 Régression linéaire 12.1 Première étape Toujours en premier: Regarder l’aspect des données avec des graphiques (“exploration visuelle”) data(iris) plot(iris) Existe-t-il un lien entre des variables ? 12.2 Diverses formes des dépendances ## ## Attaching package: &#39;reshape2&#39; ## The following object is masked from &#39;package:tidyr&#39;: ## ## smiths En pratique les formes sont beaucoup moins régulières. 12.3 Les étapes Tracer le nuage de points Existe-t-il une relation ? Est-elle de forme linéaire ? De quel sens ? Si la liaison est de forme linéaire \\(\\rightarrow\\) faire une régression Si la liaison est non linéaire, est-elle monotone ? De forme connue ?\\(\\rightarrow\\) Proposer un modèle 5bis. Réaliser un modèle LOESS avec prudence (uniquement descriptif , aucun pouvoir de généralisation) cf le blog de Lise Vaudor [http://perso.ens-lyon.fr/lise.vaudor/regression-loess/] 12.4 Régression linéaire Si la forme du nuage de points s’y prête, on peut faire une régression linéaire (aussi appelé ajustement linéaire). On cherche la droite qui «passe au mieux» (=ajustée) dans le nuage de points de deux variables quantitatives \\(V_1\\) et \\(V_2\\), qui permet de vsiualiser: l’intensité du lien / de la dépendance : points proche de la droite ou non ? la forme de la dépendance : linéaire ou non ? le sens de la dépendance : nulle, positive ou négative ? 12.5 Régression linéaire «Droite qui passe au mieux» = qui minimise la somme des écarts quadratiques entre la droite et les points du nuage. 12.6 Régression linéaire : le modèle L’équation de la droite est un modèle linéaire de la relation statistique qui lie \\(V_1\\) et \\(V_2\\); Ici le modèle est : \\(\\hat{V_2}=aV_1+b\\) Si la régression linéaire est avérée, alors pour un individu \\(i\\) dont on connait \\(V1_i\\), on infère la valeur \\(V2_i\\) par le modèle : \\(\\hat{V_{2i}} = aV_{1i} +b\\) On dit aussi que \\(V_1\\) explique \\(V_2\\) , ou que le modèle prédit \\(V_2\\) à partir de \\(V_1\\) (on note les valeurs prédites \\(\\hat{V_2}\\)) 12.7 La grande question Comment déterminer qu’une régression linéaire est «correcte» ? 12.8 Comment evaluer la “validité” du modèle linaire ? En pratique, il faut réunir deux critères : des coefficients avec des p-values associées faibles (e.g. &lt;0.05) \\(\\leftrightarrow\\) “on a peu de chances de se tromper” un \\(R^2\\) élevé \\(\\leftrightarrow\\) “le modèle prédit bien les observations” 12.9 le \\(R^2\\) \\(R^2 \\in [0;1]\\) , c’est le coefficient de détermination linéaire. Donne la qualité de prédiction de la régression. “Proche de 1”\" \\(\\equiv\\) “très bonne qualité” C’est le pourcentage de “variation” de \\(V_2\\) due à la “variation” de \\(V_1\\) 12.10 le \\(R^2\\) défini par : \\(R^2 = 1 - \\frac{\\sum_{i=1}^{n} (y_i - \\hat{y})^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}\\) si on note \\(\\hat{V_2}\\) les valeurs de \\(V_2\\) prédite par le modèle linéaire, alors: \\(R^2=cor(\\hat{V_2},V_2)^2\\) (au sens de la corrélation de Pearson) 12.11 la p-value Elle peut s’interpréter comme «la probabilité d’avoir un résultat de regression identique avec deux variables véritablement indépendantes» La p-value est associée à la notion d’hypothèses nulle. Ici , l’hypothèse nulle est “les deux séries sont indépendantes”. 12.12 la p-value Plus grossièrement : la p-value est le pourcentage de chances de se tromper en rejetant l’hypothèse nulle, c’est à dire se tromper en considérant que les deux séries ne sont pas indépendantes et qu’il existe une relation entre les deux (ici, linéaire car nous testons un modèle linéaire). 12.13 l’Hypothèse nulle \\(H_0\\) : «les deux variables sont indépendantes» conserver \\(H_0\\) : considérer les deux variables comme indépendantes rejeter \\(H_0\\) : considérer les deux variables comme dépendantes = ayant une relation statistique, un lien. 12.14 Format des resultats donnés par avec R regression &lt;- lm(iris$Petal.Length~iris$Petal.Width) summary(regression) ## ## Call: ## lm(formula = iris$Petal.Length ~ iris$Petal.Width) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.33542 -0.30347 -0.02955 0.25776 1.39453 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.08356 0.07297 14.85 &lt;2e-16 *** ## iris$Petal.Width 2.22994 0.05140 43.39 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.4782 on 148 degrees of freedom ## Multiple R-squared: 0.9271, Adjusted R-squared: 0.9266 ## F-statistic: 1882 on 1 and 148 DF, p-value: &lt; 2.2e-16 Distribution des résidus, coefficients du modèle ajusté et leur p-value associée (ici sur un test de Student, notée Pr(&gt;|t|) et \\(R^2\\)) 12.15 Bonus: Critères de significativité du lien linéaire Les résidus \\(\\epsilon_i\\) (écart entre valeur observée et valeur prédite (\\(V_2 - \\hat{V_2}\\)) par le modèle pour l’individu \\(i\\)) doivent: être indépendants : covariance nulle ou très faible \\(cov(x_i, \\epsilon_i) = 0\\) être distribués selon un loi normale de moyenne nulle \\(\\epsilon \\sim \\mathscr{N}(0,\\sigma_{\\epsilon})\\) être distribués de façon homogène (homoscédasticité), i.e. de variance constante \\(var(\\epsilon_i)=\\sigma_{\\epsilon}^2\\) , indépendante de l’observation 12.16 Bonus: Evaluation de l’indépendance des résidus avec R Graphique de la fonction acf: Si une barre exceptée la première dépasse la ligne en pointillés, on peut remettre en cause l’indépendance des résidus. Ici, c’est le cas. modele1 &lt;- lm(iris$Petal.Length~ iris$Petal.Width) acf(residuals(modele1)) 12.17 Bonus:Les 4 graphiques résultats de la fonction lm La fonction lm de R et ses résultats permettent de tracer 4 graphiques pour évaluer certains des critères de significativité. modele1 &lt;- lm(iris$Petal.Length~ iris$Petal.Width) par(mfrow=c(2,2)) # pour avoir une matrice de graphes plot(modele1) 12.18 Bonus: Évaluer l’homogénéité des résidus avec R Premier graphique : pour vérifier que le nuage de points est homogène (e.g. pas de relation non-linéaire entre résidus et valeurs prédites) Une éventuelle relation non-linéaire pourrait se retrouver dans les résidus(Ici : légère structure parabolique ) modele1 &lt;- lm(iris$Petal.Length~ iris$Petal.Width) plot(modele1,1) 12.19 Bonus: Evaluer la normalité de la distribution des résidus avec R Le deuxième graphique “Q-Q plot” : pour vérifier l’hypothèse de normalité des résidus, les points doivent être proches de la bissectrice modele1 &lt;- lm(iris$Petal.Length~ iris$Petal.Width) plot(modele1,2) 12.20 Bonus: Evaluer l’homoscédasticité des résidus Le troisème graphique “Scale location” : si les résidus sont distribués de façon homogène suivant les valeurs “fittées”, alors la droite est plutôt horizontale et les points sont disposés de façon homogène autour. modele1 &lt;- lm(iris$Petal.Length~ iris$Petal.Width) plot(modele1,3) Ici: légère pente mais les points sont distribués de façon relativement homogène autour de la droite. "],["corrélation-de-deux-variables-quantitatives.html", "Chapitre 13 Corrélation de deux variables quantitatives 13.1 Corrélation (linéaire) 13.2 Test de corrélation entre deux variables avec R 13.3 Calcul direct du coefficient de corrélation 13.4 Matrice de corrélations 13.5 Sensibilité aux ‘outliers’ 13.6 Sensibilité aux ‘outliers’ 13.7 Sensibilité aux ‘outliers’", " Chapitre 13 Corrélation de deux variables quantitatives 13.1 Corrélation (linéaire) Dans le cas d’une liaison statistique linéaire entre deux variables, on peut calculer l’«intensité» de ce lien sans nécessairement trouver les coefficients modèle linéaire : c’est la corrélation \\(cor(x,y) \\in [-1;1]\\) entre deux variables \\(x\\) et \\(y\\) . +1 : les deux variables croissent ou décroissent conjointement -1 : quand l’une des variables croît, l’autre décroît. 0 : pas de relation linéaire entre les deux variables R donne le coefficient de Pearson par defaut, l’argument method de la fonction cor() permet de spécifier deux autres coefficients : Kendall et Spearman. 13.2 Test de corrélation entre deux variables avec R Version plus complète : c’est un test, on a plusieurs indicateurs statistiques sur ce test, notamment la p-value et l’intervalle de confiance cor.test(iris$Petal.Length, iris$Petal.Width) ## ## Pearson&#39;s product-moment correlation ## ## data: iris$Petal.Length and iris$Petal.Width ## t = 43.387, df = 148, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.9490525 0.9729853 ## sample estimates: ## cor ## 0.9628654 Rappel : la p-value quantifie la significativité du test. En général, on considère le test significatif si elle est en dessous de 5%, soit 0.05. 13.3 Calcul direct du coefficient de corrélation Soient deux variables \\(V_1\\) et \\(V_2\\) Le coefficient de corrélation \\(r\\) de \\(V_1\\) et \\(V_2\\) est la normalisation de la covariance par le produit des écart-types des variables \\(r= \\frac{cov(V_1,V_2)}{\\sigma_{V_1}\\sigma_{V_2}}\\) La covariance est la moyenne du produit des écarts à la moyenne \\(cov(V_1,V_2)= E[(V_1-E[V_1])(V_2-E[V_2])]\\) 13.4 Matrice de corrélations cor(iris[,1:4]) ## Sepal.Length Sepal.Width Petal.Length Petal.Width ## Sepal.Length 1.0000000 -0.1175698 0.8717538 0.8179411 ## Sepal.Width -0.1175698 1.0000000 -0.4284401 -0.3661259 ## Petal.Length 0.8717538 -0.4284401 1.0000000 0.9628654 ## Petal.Width 0.8179411 -0.3661259 0.9628654 1.0000000 Présentation des corrélations entre les variables quantitatives d’un tableau, pour tous les couples de variables. La matrice de corrélation est symétrique, et sa diagonale est constituée de 1. 13.5 Sensibilité aux ‘outliers’ X &lt;- c(3,2,3,4,1,2,3,4,5,2,3,4,3) Y &lt;- c(1,2,2,2,3,3,3,3,3,4,4,4,5) plot(X, Y, xlim = c(0,16), ylim= c(0,16)) cor.test(X,Y)$estimate ## cor ## 0 13.6 Sensibilité aux ‘outliers’ X &lt;- c(3,2,3,4,1,2,3,4,5,2,3,4,3,15) Y &lt;- c(1,2,2,2,3,3,3,3,3,4,4,4,5,15) plot(X, Y, xlim = c(0,16), ylim= c(0,16)) cor.test(X,Y)$estimate ## cor ## 0.9052224 13.7 Sensibilité aux ‘outliers’ Outlier : observation “anormale”, par sa valeur extrème , comparée aux autres. La corrélation et la régression linéaire sont très sensibles aux outliers. \\(\\rightarrow\\) s’interroger sur la nécessité de nettoyer/filter les données et des conséquences "],["régression-linéaire-avec-r.html", "Chapitre 14 Régression linéaire avec R 14.1 Regression linéaire avec R 14.2 Que faire lorsque la relation n’est pas linéaire ? 14.3 Obtenir le coefficient de Spearman avec R 14.4 Utilisation conjointe des coefficients de Pearson et Spearman", " Chapitre 14 Régression linéaire avec R 14.1 Regression linéaire avec R Fonction lm() , modèle de la forme Variable_a_expliquer ~ Variable_explicative my_model &lt;- lm(Petal.Width~Petal.Length, data=iris) summary(my_model) ## ## Call: ## lm(formula = Petal.Width ~ Petal.Length, data = iris) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.56515 -0.12358 -0.01898 0.13288 0.64272 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -0.363076 0.039762 -9.131 4.7e-16 *** ## Petal.Length 0.415755 0.009582 43.387 &lt; 2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.2065 on 148 degrees of freedom ## Multiple R-squared: 0.9271, Adjusted R-squared: 0.9266 ## F-statistic: 1882 on 1 and 148 DF, p-value: &lt; 2.2e-16 14.2 Que faire lorsque la relation n’est pas linéaire ? Quand les deux variables sembles corrélées , de façon monotone mais non linéaire, \\(\\rightarrow\\) Coefficient de Spearman, basé sur le rang des individus. \\(\\rho = 1 - \\frac{6\\sum_{i=1}^{n}(rg(X_i)-rg(Y_i))^2 }{n^3 -n}\\) avec : \\(rg(X_i)\\) le rang de \\(X_i\\) (le classement de sa valeur) dans la distribution de \\(X\\) \\(n\\) le nombre d’individus 14.3 Obtenir le coefficient de Spearman avec R cor.test(iris$Sepal.Length, iris$Sepal.Width, method=&quot;spearman&quot;, exact = FALSE) ## ## Spearman&#39;s rank correlation rho ## ## data: iris$Sepal.Length and iris$Sepal.Width ## S = 656283, p-value = 0.04137 ## alternative hypothesis: true rho is not equal to 0 ## sample estimates: ## rho ## -0.1667777 l’argument exact doit être précisé en cas de valeurs ex aequo dans les données. 14.4 Utilisation conjointe des coefficients de Pearson et Spearman \\(r\\) (Pearson) et \\(\\rho\\) (Spearman) sont deux moyens d’estimer la corrélation: lequel choisir ? si \\(r = \\rho\\): on garde \\(r\\) (plus simple à interpréter) si \\(r &lt; \\rho\\): la relation est non-linéaire : prendre \\(\\rho\\) si \\(r &gt; \\rho\\): il y a un biais, prendre \\(\\rho\\) (plus robuste) … et toujours tracer le nuage de points pour examiner la nature de la relation. "],["trucs-pour-linéariser-des-relations-non-linéaires.html", "Chapitre 15 “trucs” pour linéariser des relations non-linéaires 15.1 Relation log-linéaire 15.2 Relation géométrique (exponentielle) 15.3 Relation logarithmique 15.4 Relation logistique", " Chapitre 15 “trucs” pour linéariser des relations non-linéaires 15.1 Relation log-linéaire Relation de type \\(y=ax^b\\) se linéarise par \\(ln(y)=aln(x) + ln(b)\\) 15.2 Relation géométrique (exponentielle) Relation de type \\(y=e^{ax+b}\\) se linéarise par \\(ln(y)=ax + ln(b)\\) 15.3 Relation logarithmique Relation de type \\(y=a*ln(x)+b\\) \\(\\rightarrow\\) changement de variable 15.4 Relation logistique Relation de type \\(y= y_{min} * \\frac{y_{max}-y_{min}}{1+e^{ax+b}}\\) se linéarise par \\(ln\\bigg(\\frac{y_{max}-y}{y-y_{min}}\\bigg)=ax+b\\) "],["lien-entre-deux-variables-qualitatives.html", "Chapitre 16 Lien entre deux variables qualitatives 16.1 Représentation graphique 16.2 Test statistique dit du “Chi 2” ou “Chi carré” 16.3 Test statistique dit du “Chi 2” ou “Chi carré” 16.4 Principe du Chi 2 16.5 Tableau de contingence 16.6 Construction de la distribution théorique. 16.7 Construction de la distribution théorique 16.8 Construction de la distribution théorique 16.9 Construction de la distribution théorique 16.10 Construction de la distribution théorique 16.11 Tableau des effectifs théoriques 16.12 Calcul du Chi 2 16.13 Interprétation du Chi 2 16.14 Table de loi de Student 16.15 Interprétation du Chi 2 16.16 Les étapes du \\(\\chi ^2\\)", " Chapitre 16 Lien entre deux variables qualitatives 16.1 Représentation graphique Pour deux variables qualitatives, on ne peut pas produire de nuages de points, ni de droite de régression. \\(\\rightarrow\\) on peut représenter la table de contingence (cf. fonction mosaicplot de R). 16.2 Test statistique dit du “Chi 2” ou “Chi carré” Le test du \\(\\chi ^2\\) est un test d’indépendance, il mesure l’écart, la différence, entre deux distributions de variables qualitatives Il répond à la question : “Existe-t-il un lien statistique entre deux séries de valeurs qualitatives” (La réponse est de type OUI/NON , le \\(\\chi^2\\) ne donne pas l’intensité du lien) 16.3 Test statistique dit du “Chi 2” ou “Chi carré” Hypothèse nulle \\(H_0\\) : les deux distributions sont indépendantes. «faire le test» permet de conserver ou de rejeter cette hypothèse 16.4 Principe du Chi 2 On génère une population théorique à laquelle on va comparer la population observée en considérant leurs distribution. Cette distribution théorique reflête ce qui se passerait si on suppose que \\(H_0\\) est vraie Avec cette comparaison, on pourra rejeter ou conserver l’hypothèse nulle. La construction de cette distribution se fait à partir du tableau de contingence 16.5 Tableau de contingence C’est un tableau à double entrée qui croise deux variables qualitatives. Dans une case on trouve l’effectif (= le nombre) des individus caractérisés par la conjonction des modalités en ligne et en colonnes. Exemple sur des formes géométriques de couleurs : \\[\\begin{array}{c|c|c} &amp; blanc &amp; noir \\\\ \\hline carré &amp; 22 &amp; 12 \\\\ \\hline rond &amp; 10 &amp; 30 \\\\ \\hline triangle &amp; 26 &amp; 5 \\\\ \\end{array}\\] Dans R : fonction table() 16.6 Construction de la distribution théorique. On commence par sommer les effectifs selon les modalités (en ligne et en colonne) \\[\\begin{array}{c|c|c|c} &amp; blanc &amp; noir &amp; \\texttt{total}\\\\ \\hline carré &amp; 22 &amp; 12 &amp; 34\\\\ \\hline rond &amp; 10 &amp; 30 &amp; 40 \\\\ \\hline triangle &amp; 26 &amp; 5 &amp; 31\\\\ \\hline \\texttt{total} &amp; 58 &amp; 47 &amp; 105 \\end{array}\\] On appelle les sommes en lignes et en colonnes sommes marginales, elles sont mises dans les “marges” du tableau. 16.7 Construction de la distribution théorique En divisant par la taille de la population, on obtient les fréquences observées. \\[\\begin{array}{c|c|c|c} &amp; blanc &amp; noir &amp; \\texttt{total}\\\\ \\hline carré &amp; 0.20952381&amp; 0.11428571 &amp; 0.3238095\\\\ \\hline rond &amp; 0.09523810 &amp; 0.28571429 &amp; 0.3809524 \\\\ \\hline triangle &amp; 0.24761905 &amp; 0.04761905 &amp; 0.2952381\\\\ \\hline \\texttt{total} &amp; 0.552381 &amp; 0.447619 &amp; 1 \\end{array}\\] On obtient les pourcentages de l’effectif dans les cases du tableau. C’est également la probabilité , qu’un individu de la population observée soit caractérisé par les modalités en ligne et en colonne. 16.8 Construction de la distribution théorique \\[\\begin{array}{c|c|c|c} &amp; blanc &amp; noir &amp; \\texttt{total}\\\\ \\hline carré &amp; 0.20952381&amp; 0.11428571 &amp; \\textbf{0.3238095}\\\\ \\hline rond &amp; 0.09523810 &amp; 0.28571429 &amp; \\textbf{0.3809524} \\\\ \\hline triangle &amp; 0.24761905 &amp; 0.04761905 &amp; \\textbf{0.2952381}\\\\ \\hline \\texttt{total} &amp; \\textbf{0.552381} &amp; \\textbf{0.447619} &amp; 1 \\end{array}\\] De la même façon, les fréquences marginales (marges divisées par la taille de la pop.), donnent la probabilité d’observer un individu de la modalité correspondant à la ligne ou à la colonne considérée. Exemple : dans cette population , j’ai 29.5% de chances de tirer un triangle, et 55% de chances de tirer une pièce blanche. 16.9 Construction de la distribution théorique Rappel : Probabilité conjointe de deux évènements \\(A\\) et \\(B\\) indépendants \\(P(A \\cap B) = P(A) \\times P(B)\\) À partir des fréquences marginales précédentes, on obtient pour chaque couple de modalités, la probabilité théorique, celle qui suppose \\(H_0\\), par un simple produit. Exemple : Si \\(H_0\\) est vraie, la probabilité d’observer un triangle noir est donnée par: \\(P(triangle \\cap noir) = P(triangle) \\times P(noir)\\) \\(P(triangle \\cap noir) =0.447619 \\times 0.2952381 = 0.1321542\\) La probabilité théorique d’observer un triangle noir est de 13,2% 16.10 Construction de la distribution théorique On crée un second tableau, dont chaque case vaut le produit des fréquences marginales calculées sur le tableau des observations. \\[\\begin{array}{c|c|c|c} &amp; blanc &amp; noir &amp; \\texttt{total}\\\\ \\hline carré &amp; 0.1788662 &amp; 0.1449433 &amp; \\textbf{0.3238095}\\\\ \\hline rond &amp; 0.2104309 &amp;0.1705215 &amp; \\textbf{0.3809524} \\\\ \\hline triangle &amp; 0.1630839 &amp; 0.1321542 &amp; \\textbf{0.2952381}\\\\ \\hline \\texttt{total} &amp; \\textbf{0.552381} &amp; \\textbf{0.447619} &amp; 1 \\end{array}\\] C’est le tableau des fréquences théoriques. 16.11 Tableau des effectifs théoriques On l’obtient en multipliant les fréquences théoriques par la taille de la population observée (ici 105) \\[\\begin{array}{c|c|c} &amp; blanc &amp; noir \\\\ \\hline carré &amp; 18.78095 &amp; 15.21905 \\\\ \\hline rond &amp; 22.09524 &amp; 17.90476 \\\\ \\hline triangle &amp; 17.12381 &amp; 13.87619 \\\\ \\end{array}\\] N.B. Il n’est pas nécessaire d’arrondir les effectifs théoriques 16.12 Calcul du Chi 2 C’est la somme, pour chaque case du tableau de contingence (i.e. pour chaque couple de modalités), des écarts carrés entre effectif observé et effectif théorique**, divisés par l’effectif théorique. Soient \\(T^{obs}\\) le tableau des effectifs observés, \\(T^{theo}\\) le tableau des effectifs théoriques, \\(\\chi^2 = \\sum_{i,j} \\frac{( T^{obs}_{i,j} - T^{theo}_{i,j})^2}{T^{obs}_{i,j}}\\) ici : \\(\\chi^2 = 26.30329\\) 16.13 Interprétation du Chi 2 Il faut comparé la valeur du \\(\\chi^2\\) calculée avec la valeur critique qu’on trouve dans une table de loi de Student (ou table de loi du chi 2). C’est un tableau à double entrée : une valeur de quantile, et un degré de liberté. On peut considérer que la valeur de quantile est le pourcentage d’erreur qu’on s’autorise de faire. On prend souvent 5% : la colonne 1-0.05 = 0.95 Le degré de liberté est obtenu en calculant la valeur \\((nb\\_lignes - 1)*(nb\\_colonnes -1)\\). Dans notre exemple , le degré de liberté est 2*1 = 2 16.14 Table de loi de Student &lt;img src=“table.loi.de.student.png”, width=100%&gt; 16.15 Interprétation du Chi 2 D’après le tableau de la loi de Student , la valeur critique pour un test avec 5% de chances de se tromper est un degré de liberté de 2 vaut 4.303. Si la valeur calculée du \\(\\chi^2\\) est supérieure à la valeur critique, on rejette \\(H_0\\). Pour notre exemple: On rejette \\(H_0\\), i.e. les deux variables sont dépendantes, car \\(\\chi ^2 \\approx 26 &gt; 4.303\\) Interprétation: «la forme est liée à la couleur dans cette population, nous pouvons l’affirmer avec un risque d’erreur d’au moins 5%» 16.16 Les étapes du \\(\\chi ^2\\) Tableau de contingence Sommes marginales Calcul des fréquences observées Calcul des fréquences théoriques Tableau d’effectifs théoriques Calcul de la valeur du test Comparaison avec les valeurs de la table de Student "],["lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html", "Chapitre 17 Lien entre une variable qualitative et une variable quantitative. 17.1 Représentation graphique. 17.2 Les boîtes à moustaches 17.3 Boxplot et Distribution 17.4 Boxplot par catégories", " Chapitre 17 Lien entre une variable qualitative et une variable quantitative. 17.1 Représentation graphique. Pas de moyen simple de calculer le lien entre une variable qualitative et une variable quantitative. corrélation de rang régression logistique analyse de la variance (ANOVA) \\(\\implies\\) Alors on fait un graphique ! La variable qualitative sert de catégorie, on fait varier la représentation graphique de la variable quantitative suivant cette catégorie. 2 possibilités : boîtes à moustaches superposition d’ histogrammes / densités 17.2 Les boîtes à moustaches “Boîte à moustaches”, aussi appellées “boxplot”, montre les quartiles d’une variable Quartile = «quantile de 4», valeurs qui séparent une variable quantitative en quarts, i.e. paquets d’un quart de l’effectif Premier quartile : sépare les 25% inférieurs des valeurs Second quartile : mediane, sépare les 50% inférieurs des valeurs troisième quartile : sépare les 75% inférieurs des valeurs Dans R, fonction quantile 17.3 Boxplot et Distribution 17.4 Boxplot par catégories Principe : on trace un boxplot par modalité de la variable qualitative. E.g. : consommation de véhicules par type (dataset mpg de R) "],["références-supplémentaires.html", "Chapitre 18 Références supplémentaires 18.1 Refs", " Chapitre 18 Références supplémentaires 18.1 Refs Cours complet sur les modèles linéaires : [https://www.math.univ-toulouse.fr/~barthe/M1modlin/poly.pdf] Interprétation des graphique de lm en R : [https://data.library.virginia.edu/diagnostic-plots/] "],["applications.html", "Chapitre 19 Applications 19.1 Example one 19.2 Example two", " Chapitre 19 Applications Some significant applications are demonstrated in this chapter. 19.1 Example one 19.2 Example two "],["final-words.html", "Chapitre 20 Final Words", " Chapitre 20 Final Words We have finished a nice book. "],["references.html", "References", " References "]]
