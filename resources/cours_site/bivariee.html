<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 9 Analyse Bivariée | Analyse Statistique M2 IGAST</title>
  <meta name="description" content="Ce cours collecte le contenu des diapositives des cours d’analyse statistique du M2 IGAST dans une forme plus proche du document. Le contenu est plus «rédigé» que celui des diapositives Une version PDF et une version HTML sont proposées." />
  <meta name="generator" content="bookdown 0.21.6 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 9 Analyse Bivariée | Analyse Statistique M2 IGAST" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ce cours collecte le contenu des diapositives des cours d’analyse statistique du M2 IGAST dans une forme plus proche du document. Le contenu est plus «rédigé» que celui des diapositives Une version PDF et une version HTML sont proposées." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 9 Analyse Bivariée | Analyse Statistique M2 IGAST" />
  
  <meta name="twitter:description" content="Ce cours collecte le contenu des diapositives des cours d’analyse statistique du M2 IGAST dans une forme plus proche du document. Le contenu est plus «rédigé» que celui des diapositives Une version PDF et une version HTML sont proposées." />
  

<meta name="author" content="PC" />


<meta name="date" content="2021-01-18" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="visualiser-une-distribution-avec-r.html"/>
<link rel="next" href="correlation.html"/>
<script src="book_assets/jquery-2.2.3/jquery.min.js"></script>
<link href="book_assets/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="book_assets/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="book_assets/accessible-code-block-0.0.1/empty-anchor.js"></script>
<link href="book_assets/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="book_assets/anchor-sections-1.0.1/anchor-sections.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="index.html">Analyse Statistique M2 IGAST </a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préambule</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#programme-du-cours-et-contenu"><i class="fa fa-check"></i>Programme du cours et Contenu</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#reférences"><i class="fa fa-check"></i>Reférences</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#ressources-pour-lapprentissage-du-langage-r"><i class="fa fa-check"></i>Ressources pour l’apprentissage du langage R</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction générale</a><ul>
<li class="chapter" data-level="1.1" data-path="intro.html"><a href="intro.html#analyse-spatiale-définition"><i class="fa fa-check"></i><b>1.1</b> Analyse spatiale : définition</a></li>
<li class="chapter" data-level="1.2" data-path="intro.html"><a href="intro.html#analyse-spatiale-analyse-statistique"><i class="fa fa-check"></i><b>1.2</b> Analyse spatiale &amp; Analyse Statistique</a></li>
<li class="chapter" data-level="1.3" data-path="intro.html"><a href="intro.html#deux-approches-en-analyse-spatiale"><i class="fa fa-check"></i><b>1.3</b> Deux approches en analyse spatiale</a></li>
<li class="chapter" data-level="1.4" data-path="intro.html"><a href="intro.html#deux-familles-statistiques"><i class="fa fa-check"></i><b>1.4</b> Deux familles statistiques</a><ul>
<li class="chapter" data-level="1.4.1" data-path="intro.html"><a href="intro.html#statistiques-inférentielles"><i class="fa fa-check"></i><b>1.4.1</b> Statistiques inférentielles</a></li>
<li class="chapter" data-level="1.4.2" data-path="intro.html"><a href="intro.html#statistiques-inférentielles-lexemple-des-pingouins"><i class="fa fa-check"></i><b>1.4.2</b> Statistiques inférentielles : l’exemple des pingouins</a></li>
<li class="chapter" data-level="1.4.3" data-path="intro.html"><a href="intro.html#statistiques-descriptives"><i class="fa fa-check"></i><b>1.4.3</b> Statistiques descriptives</a></li>
<li class="chapter" data-level="1.4.4" data-path="intro.html"><a href="intro.html#les-formats-de-données-wide-et-long"><i class="fa fa-check"></i><b>1.4.4</b> Les formats de données <em>wide</em> et <em>long</em></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="intro.html"><a href="intro.html#vocabulaire"><i class="fa fa-check"></i><b>1.5</b> Vocabulaire</a><ul>
<li class="chapter" data-level="1.5.1" data-path="intro.html"><a href="intro.html#variables-quantitatives"><i class="fa fa-check"></i><b>1.5.1</b> Variables quantitatives</a></li>
<li class="chapter" data-level="1.5.2" data-path="intro.html"><a href="intro.html#variables-qualitatives"><i class="fa fa-check"></i><b>1.5.2</b> Variables qualitatives</a></li>
<li class="chapter" data-level="1.5.3" data-path="intro.html"><a href="intro.html#valeur-et-nature-des-variables"><i class="fa fa-check"></i><b>1.5.3</b> Valeur et Nature des variables</a></li>
<li class="chapter" data-level="1.5.4" data-path="intro.html"><a href="intro.html#types-de-variables-et-représentations"><i class="fa fa-check"></i><b>1.5.4</b> Types de variables et représentations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html"><i class="fa fa-check"></i><b>2</b> Difficultés de la statistique</a><ul>
<li class="chapter" data-level="2.1" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#plusieurs-discours-sont-possibles"><i class="fa fa-check"></i><b>2.1</b> Plusieurs discours sont possibles</a></li>
<li class="chapter" data-level="2.2" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#taille-et-représentativité-de-léchantillon"><i class="fa fa-check"></i><b>2.2</b> Taille et représentativité de l’échantillon</a></li>
<li class="chapter" data-level="2.3" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#le-paradoxe-de-simpsons"><i class="fa fa-check"></i><b>2.3</b> Le paradoxe de Simpsons</a></li>
<li class="chapter" data-level="2.4" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#échelle-individuelle-vs.-échelle-agrégée"><i class="fa fa-check"></i><b>2.4</b> Échelle individuelle vs. Échelle agrégée</a></li>
<li class="chapter" data-level="2.5" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#à-quelle-échelle-observer-le-maup"><i class="fa fa-check"></i><b>2.5</b> À quelle échelle observer ? le MAUP</a><ul>
<li class="chapter" data-level="2.5.1" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#effet-de-zonage"><i class="fa fa-check"></i><b>2.5.1</b> Effet de zonage</a></li>
<li class="chapter" data-level="2.5.2" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#maup-exemples"><i class="fa fa-check"></i><b>2.5.2</b> MAUP : exemples</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="difficultés-de-la-statistique.html"><a href="difficultés-de-la-statistique.html#rappel-la-première-chose-à-faire"><i class="fa fa-check"></i><b>2.6</b> Rappel: La première “chose à faire”</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="univariee.html"><a href="univariee.html"><i class="fa fa-check"></i><b>3</b> Analyse Univariée</a><ul>
<li class="chapter" data-level="3.1" data-path="univariee.html"><a href="univariee.html#densite"><i class="fa fa-check"></i><b>3.1</b> Le concept de distribution</a><ul>
<li class="chapter" data-level="3.1.1" data-path="univariee.html"><a href="univariee.html#interpret_dens"><i class="fa fa-check"></i><b>3.1.1</b> Interpréter la courbe de densité</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="univariee.html"><a href="univariee.html#exemples-de-distributions-de-lois-connues"><i class="fa fa-check"></i><b>3.2</b> Exemples de distributions de lois connues</a><ul>
<li class="chapter" data-level="3.2.1" data-path="univariee.html"><a href="univariee.html#loi-gaussienne"><i class="fa fa-check"></i><b>3.2.1</b> Loi Gaussienne</a></li>
<li class="chapter" data-level="3.2.2" data-path="univariee.html"><a href="univariee.html#loi-uniforme"><i class="fa fa-check"></i><b>3.2.2</b> Loi uniforme</a></li>
<li class="chapter" data-level="3.2.3" data-path="univariee.html"><a href="univariee.html#loi-log-normale"><i class="fa fa-check"></i><b>3.2.3</b> Loi log-normale</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="univariee.html"><a href="univariee.html#histogramme-dune-distribution-réelle"><i class="fa fa-check"></i><b>3.3</b> Histogramme d’une distribution réelle</a></li>
<li class="chapter" data-level="3.4" data-path="univariee.html"><a href="univariee.html#afficher-histogrammes-et-distributions-en-r"><i class="fa fa-check"></i><b>3.4</b> Afficher histogrammes et distributions en R</a><ul>
<li class="chapter" data-level="3.4.1" data-path="univariee.html"><a href="univariee.html#histogramme-dune-variable-quantitative"><i class="fa fa-check"></i><b>3.4.1</b> Histogramme d’une variable quantitative</a></li>
<li class="chapter" data-level="3.4.2" data-path="univariee.html"><a href="univariee.html#histogramme-et-variable-qualitative"><i class="fa fa-check"></i><b>3.4.2</b> Histogramme et variable qualitative</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="tendance.html"><a href="tendance.html"><i class="fa fa-check"></i><b>4</b> La Tendance</a><ul>
<li class="chapter" data-level="4.1" data-path="tendance.html"><a href="tendance.html#moyenne"><i class="fa fa-check"></i><b>4.1</b> Moyenne</a><ul>
<li class="chapter" data-level="4.1.1" data-path="tendance.html"><a href="tendance.html#moyenne-pondérée"><i class="fa fa-check"></i><b>4.1.1</b> Moyenne pondérée</a></li>
<li class="chapter" data-level="4.1.2" data-path="tendance.html"><a href="tendance.html#avantages-et-inconvénients-de-la-moyenne"><i class="fa fa-check"></i><b>4.1.2</b> Avantages et inconvénients de la moyenne</a></li>
<li class="chapter" data-level="4.1.3" data-path="tendance.html"><a href="tendance.html#autres-moyennes"><i class="fa fa-check"></i><b>4.1.3</b> Autres Moyennes</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="tendance.html"><a href="tendance.html#mode"><i class="fa fa-check"></i><b>4.2</b> Mode</a><ul>
<li class="chapter" data-level="4.2.1" data-path="tendance.html"><a href="tendance.html#avantages-et-inconvénients-du-mode"><i class="fa fa-check"></i><b>4.2.1</b> Avantages et inconvénients du mode</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="tendance.html"><a href="tendance.html#mediane"><i class="fa fa-check"></i><b>4.3</b> Médiane</a><ul>
<li class="chapter" data-level="4.3.1" data-path="tendance.html"><a href="tendance.html#étapes-de-calcul"><i class="fa fa-check"></i><b>4.3.1</b> Étapes de calcul</a></li>
<li class="chapter" data-level="4.3.2" data-path="tendance.html"><a href="tendance.html#avantages-et-inconvénients-de-la-médiane"><i class="fa fa-check"></i><b>4.3.2</b> Avantages et inconvénients de la médiane</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="tendance.html"><a href="tendance.html#quelle-mesure-de-tendance-choisir"><i class="fa fa-check"></i><b>4.4</b> Quelle mesure de tendance choisir ?</a><ul>
<li class="chapter" data-level="4.4.1" data-path="tendance.html"><a href="tendance.html#exemple-idéal-distribution-unimodale-symétrique"><i class="fa fa-check"></i><b>4.4.1</b> Exemple idéal: Distribution unimodale symétrique</a></li>
<li class="chapter" data-level="4.4.2" data-path="tendance.html"><a href="tendance.html#exemple-dun-cas-délicat-distribution-bimodale"><i class="fa fa-check"></i><b>4.4.2</b> Exemple d’un cas délicat : distribution bimodale</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="dispersion.html"><a href="dispersion.html"><i class="fa fa-check"></i><b>5</b> La Dispersion</a><ul>
<li class="chapter" data-level="5.1" data-path="dispersion.html"><a href="dispersion.html#la-dispersion"><i class="fa fa-check"></i><b>5.1</b> La dispersion</a></li>
<li class="chapter" data-level="5.2" data-path="dispersion.html"><a href="dispersion.html#variance"><i class="fa fa-check"></i><b>5.2</b> Variance et Écart-type</a><ul>
<li class="chapter" data-level="5.2.1" data-path="dispersion.html"><a href="dispersion.html#variance-et-écart-type-avec-r"><i class="fa fa-check"></i><b>5.2.1</b> Variance et écart type avec R</a></li>
<li class="chapter" data-level="5.2.2" data-path="dispersion.html"><a href="dispersion.html#si-la-distribution-est-proche-de-la-gaussienne"><i class="fa fa-check"></i><b>5.2.2</b> Si la distribution est proche de la Gaussienne</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="dispersion.html"><a href="dispersion.html#quantiles"><i class="fa fa-check"></i><b>5.3</b> Quantiles</a><ul>
<li class="chapter" data-level="5.3.1" data-path="dispersion.html"><a href="dispersion.html#quartiles"><i class="fa fa-check"></i><b>5.3.1</b> Quartiles</a></li>
<li class="chapter" data-level="5.3.2" data-path="dispersion.html"><a href="dispersion.html#déciles"><i class="fa fa-check"></i><b>5.3.2</b> Déciles</a></li>
<li class="chapter" data-level="5.3.3" data-path="dispersion.html"><a href="dispersion.html#écarts-inter-quartiles-et-inter-déciles"><i class="fa fa-check"></i><b>5.3.3</b> Écarts inter-quartiles et inter-déciles</a></li>
<li class="chapter" data-level="5.3.4" data-path="dispersion.html"><a href="dispersion.html#avantages-et-inconvénient-des-quantiles"><i class="fa fa-check"></i><b>5.3.4</b> Avantages et inconvénient des quantiles</a></li>
<li class="chapter" data-level="5.3.5" data-path="dispersion.html"><a href="dispersion.html#les-boîtes-à-moustaches-boxplots-avec-r"><i class="fa fa-check"></i><b>5.3.5</b> Les boîtes à moustaches (boxplots) avec R</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="dispersion.html"><a href="dispersion.html#le-coefficient-de-variation"><i class="fa fa-check"></i><b>5.4</b> Le coefficient de variation</a></li>
<li class="chapter" data-level="5.5" data-path="dispersion.html"><a href="dispersion.html#comparer-les-dispersions-de-deux-distributions."><i class="fa fa-check"></i><b>5.5</b> Comparer les dispersions de deux distributions.</a><ul>
<li class="chapter" data-level="5.5.1" data-path="dispersion.html"><a href="dispersion.html#comparaison-visuelle-de-deux-distributions"><i class="fa fa-check"></i><b>5.5.1</b> Comparaison visuelle de deux distributions</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="forme.html"><a href="forme.html"><i class="fa fa-check"></i><b>6</b> La Forme</a><ul>
<li class="chapter" data-level="6.1" data-path="forme.html"><a href="forme.html#asymétrie"><i class="fa fa-check"></i><b>6.1</b> Asymétrie</a><ul>
<li class="chapter" data-level="6.1.1" data-path="forme.html"><a href="forme.html#les-coefficients-dasymétrie-de-pearson"><i class="fa fa-check"></i><b>6.1.1</b> les Coefficients d’asymétrie de Pearson</a></li>
<li class="chapter" data-level="6.1.2" data-path="forme.html"><a href="forme.html#le-coefficient-dasymétrie-de-fischer"><i class="fa fa-check"></i><b>6.1.2</b> Le coefficient d’asymétrie de Fischer</a></li>
<li class="chapter" data-level="6.1.3" data-path="forme.html"><a href="forme.html#calculer-le-coefficient-dasymétrie-avec-r"><i class="fa fa-check"></i><b>6.1.3</b> Calculer le coefficient d’asymétrie avec R</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="forme.html"><a href="forme.html#kurtosis"><i class="fa fa-check"></i><b>6.2</b> L’Aplatissement (kurtosis)</a><ul>
<li class="chapter" data-level="6.2.1" data-path="forme.html"><a href="forme.html#coefficient-daplatissement-ou-kurtosis"><i class="fa fa-check"></i><b>6.2.1</b> Coefficient d’aplatissement (ou kurtosis)</a></li>
<li class="chapter" data-level="6.2.2" data-path="forme.html"><a href="forme.html#exemple-de-distribution-à-écart-type-faible-mais-à-kurtosis-important"><i class="fa fa-check"></i><b>6.2.2</b> Exemple de distribution à écart-type faible, mais à kurtosis important</a></li>
<li class="chapter" data-level="6.2.3" data-path="forme.html"><a href="forme.html#calculer-le-kurtosis-avec-r"><i class="fa fa-check"></i><b>6.2.3</b> Calculer le kurtosis avec R</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="forme.html"><a href="forme.html#transformations-des-données"><i class="fa fa-check"></i><b>6.3</b> Transformations des données</a></li>
<li class="chapter" data-level="6.4" data-path="forme.html"><a href="forme.html#fat-tail-distributions-un-exemple"><i class="fa fa-check"></i><b>6.4</b> Fat-tail distributions : un exemple</a><ul>
<li class="chapter" data-level="6.4.1" data-path="forme.html"><a href="forme.html#distribution-rang-taille-des-villes-de-france"><i class="fa fa-check"></i><b>6.4.1</b> Distribution rang-taille des villes de france</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="carto-discretis.html"><a href="carto-discretis.html"><i class="fa fa-check"></i><b>7</b> Cartographie, Distribution et Échelle de couleurs</a><ul>
<li class="chapter" data-level="7.1" data-path="carto-discretis.html"><a href="carto-discretis.html#méthodes-usuelles-de-discrétisation"><i class="fa fa-check"></i><b>7.1</b> Méthodes usuelles de discrétisation</a></li>
<li class="chapter" data-level="7.2" data-path="carto-discretis.html"><a href="carto-discretis.html#les-données"><i class="fa fa-check"></i><b>7.2</b> Les données</a><ul>
<li class="chapter" data-level="7.2.1" data-path="carto-discretis.html"><a href="carto-discretis.html#géométrie-des-quartiers-de-paris"><i class="fa fa-check"></i><b>7.2.1</b> Géométrie des quartiers de Paris</a></li>
<li class="chapter" data-level="7.2.2" data-path="carto-discretis.html"><a href="carto-discretis.html#distribution-des-surfaces-des-quartiers"><i class="fa fa-check"></i><b>7.2.2</b> Distribution des surfaces des quartiers</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="carto-discretis.html"><a href="carto-discretis.html#résultats-des-méthodes-de-classification"><i class="fa fa-check"></i><b>7.3</b> Résultats des méthodes de classification</a><ul>
<li class="chapter" data-level="7.3.1" data-path="carto-discretis.html"><a href="carto-discretis.html#classification-par-défaut"><i class="fa fa-check"></i><b>7.3.1</b> Classification par défaut</a></li>
<li class="chapter" data-level="7.3.2" data-path="carto-discretis.html"><a href="carto-discretis.html#méthode-jenks-à-5-7-et-9-classes"><i class="fa fa-check"></i><b>7.3.2</b> Méthode Jenks à 5 , 7 et 9 classes</a></li>
<li class="chapter" data-level="7.3.3" data-path="carto-discretis.html"><a href="carto-discretis.html#effectifs-égaux"><i class="fa fa-check"></i><b>7.3.3</b> Effectifs égaux</a></li>
<li class="chapter" data-level="7.3.4" data-path="carto-discretis.html"><a href="carto-discretis.html#intervalles-égaux"><i class="fa fa-check"></i><b>7.3.4</b> Intervalles égaux</a></li>
<li class="chapter" data-level="7.3.5" data-path="carto-discretis.html"><a href="carto-discretis.html#écart-types"><i class="fa fa-check"></i><b>7.3.5</b> Écart-types</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="carto-discretis.html"><a href="carto-discretis.html#quelle-méthode-de-classification-choisir"><i class="fa fa-check"></i><b>7.4</b> Quelle méthode de classification choisir ?</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html"><i class="fa fa-check"></i><b>8</b> Visualiser une distribution avec R</a><ul>
<li class="chapter" data-level="8.0.1" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#histogramme-code-r-ggplot"><i class="fa fa-check"></i><b>8.0.1</b> Histogramme : Code R + ggplot</a></li>
<li class="chapter" data-level="8.0.2" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#distributiondensité-code-r-ggplot"><i class="fa fa-check"></i><b>8.0.2</b> Distribution/densité : Code R + ggplot</a></li>
<li class="chapter" data-level="8.0.3" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#boxplot-code-r-ggplot"><i class="fa fa-check"></i><b>8.0.3</b> BoxPlot : Code R + ggplot</a></li>
<li class="chapter" data-level="8.0.4" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#violin-plot-code-r-ggplot"><i class="fa fa-check"></i><b>8.0.4</b> Violin plot : Code R + ggplot</a></li>
<li class="chapter" data-level="8.0.5" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#violin-plot-et-boxplot-code-r-ggplot-2"><i class="fa fa-check"></i><b>8.0.5</b> Violin plot et Boxplot : Code R + ggplot 2</a></li>
<li class="chapter" data-level="8.0.6" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#pyramides-histogrammes-juxtaposés"><i class="fa fa-check"></i><b>8.0.6</b> Pyramides (histogrammes juxtaposés)</a></li>
<li class="chapter" data-level="8.0.7" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#polygones-de-fréquences"><i class="fa fa-check"></i><b>8.0.7</b> Polygones de fréquences</a></li>
<li class="chapter" data-level="8.0.8" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#distribution-cumulée-fonction-de-répartition-cdf"><i class="fa fa-check"></i><b>8.0.8</b> Distribution cumulée, Fonction de répartition, CDF</a></li>
<li class="chapter" data-level="8.0.9" data-path="visualiser-une-distribution-avec-r.html"><a href="visualiser-une-distribution-avec-r.html#dot-strip-plot"><i class="fa fa-check"></i><b>8.0.9</b> Dot Strip Plot</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bivariee.html"><a href="bivariee.html"><i class="fa fa-check"></i><b>9</b> Analyse Bivariée</a><ul>
<li class="chapter" data-level="9.0.1" data-path="bivariee.html"><a href="bivariee.html#analyse-bivariée-mais-sans-la-localisation"><i class="fa fa-check"></i><b>9.0.1</b> Analyse bivariée, mais sans la localisation</a></li>
<li class="chapter" data-level="9.0.2" data-path="bivariee.html"><a href="bivariee.html#ressources-pour-lanalyse-des-localisation-et-des-distances"><i class="fa fa-check"></i><b>9.0.2</b> Ressources pour l’analyse des localisation et des distances</a></li>
<li class="chapter" data-level="9.1" data-path="bivariee.html"><a href="bivariee.html#corrélation-nimplique-pas-causalité"><i class="fa fa-check"></i><b>9.1</b> Corrélation n’implique pas causalité</a><ul>
<li class="chapter" data-level="9.1.1" data-path="bivariee.html"><a href="bivariee.html#diverses-formes-de-dépendances"><i class="fa fa-check"></i><b>9.1.1</b> Diverses formes de dépendances</a></li>
<li class="chapter" data-level="9.1.2" data-path="bivariee.html"><a href="bivariee.html#les-étapes-de-lanalyse-bivariée"><i class="fa fa-check"></i><b>9.1.2</b> Les étapes de l’analyse bivariée</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bivariee.html"><a href="bivariee.html#régression-linéaire"><i class="fa fa-check"></i><b>9.2</b> Régression linéaire</a><ul>
<li class="chapter" data-level="9.2.1" data-path="bivariee.html"><a href="bivariee.html#avant-toute-chose"><i class="fa fa-check"></i><b>9.2.1</b> Avant toute chose</a></li>
<li class="chapter" data-level="9.2.2" data-path="bivariee.html"><a href="bivariee.html#principe-et-vocabulaire"><i class="fa fa-check"></i><b>9.2.2</b> Principe et Vocabulaire</a></li>
<li class="chapter" data-level="9.2.3" data-path="bivariee.html"><a href="bivariee.html#interpréter-la-droite-de-régression"><i class="fa fa-check"></i><b>9.2.3</b> Interpréter la droite de régression</a></li>
<li class="chapter" data-level="9.2.4" data-path="bivariee.html"><a href="bivariee.html#utiliser-un-modèle-linéaire"><i class="fa fa-check"></i><b>9.2.4</b> Utiliser un modèle linéaire</a></li>
<li class="chapter" data-level="9.2.5" data-path="bivariee.html"><a href="bivariee.html#évaluer-la-qualité-dune-régression-linaire-le-r2"><i class="fa fa-check"></i><b>9.2.5</b> Évaluer la qualité d’une régression linaire : le <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="9.2.6" data-path="bivariee.html"><a href="bivariee.html#évaluer-la-qualité-dune-régression-linaire-la-p-value"><i class="fa fa-check"></i><b>9.2.6</b> Évaluer la qualité d’une régression linaire : la p-value</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bivariee.html"><a href="bivariee.html#effectuer-une-régression-linéaire-avec-r"><i class="fa fa-check"></i><b>9.3</b> Effectuer une régression linéaire avec R</a><ul>
<li class="chapter" data-level="9.3.1" data-path="bivariee.html"><a href="bivariee.html#la-commande-lm"><i class="fa fa-check"></i><b>9.3.1</b> La commande <code>lm</code></a></li>
<li class="chapter" data-level="9.3.2" data-path="bivariee.html"><a href="bivariee.html#format-des-résultats"><i class="fa fa-check"></i><b>9.3.2</b> Format des résultats</a></li>
<li class="chapter" data-level="9.3.3" data-path="bivariee.html"><a href="bivariee.html#residuslm"><i class="fa fa-check"></i><b>9.3.3</b> Bonus: Critères de significativité du lien linéaire</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="correlation.html"><a href="correlation.html"><i class="fa fa-check"></i><b>10</b> Corrélation de deux variables quantitatives</a><ul>
<li class="chapter" data-level="10.1" data-path="correlation.html"><a href="correlation.html#corrélation-linéaire"><i class="fa fa-check"></i><b>10.1</b> Corrélation (linéaire)</a></li>
<li class="chapter" data-level="10.2" data-path="correlation.html"><a href="correlation.html#test-de-corrélation-entre-deux-variables-avec-r"><i class="fa fa-check"></i><b>10.2</b> Test de corrélation entre deux variables avec R</a></li>
<li class="chapter" data-level="10.3" data-path="correlation.html"><a href="correlation.html#calcul-direct-du-coefficient-de-corrélation"><i class="fa fa-check"></i><b>10.3</b> Calcul direct du coefficient de corrélation</a></li>
<li class="chapter" data-level="10.4" data-path="correlation.html"><a href="correlation.html#matrice-de-corrélations"><i class="fa fa-check"></i><b>10.4</b> Matrice de corrélations</a></li>
<li class="chapter" data-level="10.5" data-path="correlation.html"><a href="correlation.html#sensibilité-aux-outliers"><i class="fa fa-check"></i><b>10.5</b> Sensibilité aux ‘outliers’</a></li>
<li class="chapter" data-level="10.6" data-path="correlation.html"><a href="correlation.html#sensibilité-aux-outliers-1"><i class="fa fa-check"></i><b>10.6</b> Sensibilité aux ‘outliers’</a></li>
<li class="chapter" data-level="10.7" data-path="correlation.html"><a href="correlation.html#sensibilité-aux-outliers-2"><i class="fa fa-check"></i><b>10.7</b> Sensibilité aux ‘outliers’</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="régression-linéaire-avec-r.html"><a href="régression-linéaire-avec-r.html"><i class="fa fa-check"></i><b>11</b> Régression linéaire avec R</a><ul>
<li class="chapter" data-level="11.1" data-path="régression-linéaire-avec-r.html"><a href="régression-linéaire-avec-r.html#regression-linéaire-avec-r"><i class="fa fa-check"></i><b>11.1</b> Regression linéaire avec R</a></li>
<li class="chapter" data-level="11.2" data-path="régression-linéaire-avec-r.html"><a href="régression-linéaire-avec-r.html#que-faire-lorsque-la-relation-nest-pas-linéaire"><i class="fa fa-check"></i><b>11.2</b> Que faire lorsque la relation n’est pas linéaire ?</a></li>
<li class="chapter" data-level="11.3" data-path="régression-linéaire-avec-r.html"><a href="régression-linéaire-avec-r.html#obtenir-le-coefficient-de-spearman-avec-r"><i class="fa fa-check"></i><b>11.3</b> Obtenir le coefficient de Spearman avec R</a></li>
<li class="chapter" data-level="11.4" data-path="régression-linéaire-avec-r.html"><a href="régression-linéaire-avec-r.html#utilisation-conjointe-des-coefficients-de-pearson-et-spearman"><i class="fa fa-check"></i><b>11.4</b> Utilisation conjointe des coefficients de Pearson et Spearman</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="trucs-pour-linéariser-des-relations-non-linéaires.html"><a href="trucs-pour-linéariser-des-relations-non-linéaires.html"><i class="fa fa-check"></i><b>12</b> “trucs” pour linéariser des relations non-linéaires</a><ul>
<li class="chapter" data-level="12.1" data-path="trucs-pour-linéariser-des-relations-non-linéaires.html"><a href="trucs-pour-linéariser-des-relations-non-linéaires.html#relation-log-linéaire"><i class="fa fa-check"></i><b>12.1</b> Relation log-linéaire</a></li>
<li class="chapter" data-level="12.2" data-path="trucs-pour-linéariser-des-relations-non-linéaires.html"><a href="trucs-pour-linéariser-des-relations-non-linéaires.html#relation-géométrique-exponentielle"><i class="fa fa-check"></i><b>12.2</b> Relation géométrique (exponentielle)</a></li>
<li class="chapter" data-level="12.3" data-path="trucs-pour-linéariser-des-relations-non-linéaires.html"><a href="trucs-pour-linéariser-des-relations-non-linéaires.html#relation-logarithmique"><i class="fa fa-check"></i><b>12.3</b> Relation logarithmique</a></li>
<li class="chapter" data-level="12.4" data-path="trucs-pour-linéariser-des-relations-non-linéaires.html"><a href="trucs-pour-linéariser-des-relations-non-linéaires.html#relation-logistique"><i class="fa fa-check"></i><b>12.4</b> Relation logistique</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html"><i class="fa fa-check"></i><b>13</b> Lien entre deux variables qualitatives</a><ul>
<li class="chapter" data-level="13.1" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#représentation-graphique"><i class="fa fa-check"></i><b>13.1</b> Représentation graphique</a></li>
<li class="chapter" data-level="13.2" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#test-statistique-dit-du-chi-2-ou-chi-carré"><i class="fa fa-check"></i><b>13.2</b> Test statistique dit du “Chi 2” ou “Chi carré”</a></li>
<li class="chapter" data-level="13.3" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#test-statistique-dit-du-chi-2-ou-chi-carré-1"><i class="fa fa-check"></i><b>13.3</b> Test statistique dit du “Chi 2” ou “Chi carré”</a></li>
<li class="chapter" data-level="13.4" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#principe-du-chi-2"><i class="fa fa-check"></i><b>13.4</b> Principe du Chi 2</a></li>
<li class="chapter" data-level="13.5" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#tableau-de-contingence"><i class="fa fa-check"></i><b>13.5</b> Tableau de contingence</a></li>
<li class="chapter" data-level="13.6" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#construction-de-la-distribution-théorique."><i class="fa fa-check"></i><b>13.6</b> Construction de la distribution théorique.</a></li>
<li class="chapter" data-level="13.7" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#construction-de-la-distribution-théorique"><i class="fa fa-check"></i><b>13.7</b> Construction de la distribution théorique</a></li>
<li class="chapter" data-level="13.8" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#construction-de-la-distribution-théorique-1"><i class="fa fa-check"></i><b>13.8</b> Construction de la distribution théorique</a></li>
<li class="chapter" data-level="13.9" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#construction-de-la-distribution-théorique-2"><i class="fa fa-check"></i><b>13.9</b> Construction de la distribution théorique</a></li>
<li class="chapter" data-level="13.10" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#construction-de-la-distribution-théorique-3"><i class="fa fa-check"></i><b>13.10</b> Construction de la distribution théorique</a></li>
<li class="chapter" data-level="13.11" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#tableau-des-effectifs-théoriques"><i class="fa fa-check"></i><b>13.11</b> Tableau des effectifs théoriques</a></li>
<li class="chapter" data-level="13.12" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#calcul-du-chi-2"><i class="fa fa-check"></i><b>13.12</b> Calcul du Chi 2</a></li>
<li class="chapter" data-level="13.13" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#interprétation-du-chi-2"><i class="fa fa-check"></i><b>13.13</b> Interprétation du Chi 2</a></li>
<li class="chapter" data-level="13.14" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#table-de-loi-de-student"><i class="fa fa-check"></i><b>13.14</b> Table de loi de Student</a></li>
<li class="chapter" data-level="13.15" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#interprétation-du-chi-2-1"><i class="fa fa-check"></i><b>13.15</b> Interprétation du Chi 2</a></li>
<li class="chapter" data-level="13.16" data-path="lien-entre-deux-variables-qualitatives.html"><a href="lien-entre-deux-variables-qualitatives.html#les-étapes-du-chi-2"><i class="fa fa-check"></i><b>13.16</b> Les étapes du <span class="math inline">\(\chi ^2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><a href="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><i class="fa fa-check"></i><b>14</b> Lien entre une variable qualitative et une variable quantitative.</a><ul>
<li class="chapter" data-level="14.1" data-path="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><a href="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html#représentation-graphique."><i class="fa fa-check"></i><b>14.1</b> Représentation graphique.</a></li>
<li class="chapter" data-level="14.2" data-path="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><a href="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html#les-boîtes-à-moustaches"><i class="fa fa-check"></i><b>14.2</b> Les boîtes à moustaches</a></li>
<li class="chapter" data-level="14.3" data-path="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><a href="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html#boxplot-et-distribution"><i class="fa fa-check"></i><b>14.3</b> Boxplot et Distribution</a></li>
<li class="chapter" data-level="14.4" data-path="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html"><a href="lien-entre-une-variable-qualitative-et-une-variable-quantitative-.html#boxplot-par-catégories"><i class="fa fa-check"></i><b>14.4</b> Boxplot par catégories</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="références-supplémentaires.html"><a href="références-supplémentaires.html"><i class="fa fa-check"></i><b>15</b> Références supplémentaires</a><ul>
<li class="chapter" data-level="15.1" data-path="références-supplémentaires.html"><a href="références-supplémentaires.html#refs"><i class="fa fa-check"></i><b>15.1</b> Refs</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="anaspat.html"><a href="anaspat.html"><i class="fa fa-check"></i><b>16</b> Analyse spatiale</a><ul>
<li class="chapter" data-level="16.1" data-path="anaspat.html"><a href="anaspat.html#contenu-du-cours"><i class="fa fa-check"></i><b>16.1</b> Contenu du cours</a></li>
<li class="chapter" data-level="16.2" data-path="anaspat.html"><a href="anaspat.html#linformation-géographique"><i class="fa fa-check"></i><b>16.2</b> L’information géographique</a></li>
<li class="chapter" data-level="16.3" data-path="anaspat.html"><a href="anaspat.html#précautions"><i class="fa fa-check"></i><b>16.3</b> Précautions</a></li>
<li class="chapter" data-level="16.4" data-path="anaspat.html"><a href="anaspat.html#semis-de-points"><i class="fa fa-check"></i><b>16.4</b> Semis de points</a></li>
<li class="chapter" data-level="16.5" data-path="anaspat.html"><a href="anaspat.html#statistiques-simples-sur-un-semis"><i class="fa fa-check"></i><b>16.5</b> Statistiques simples sur un semis</a></li>
<li class="chapter" data-level="16.6" data-path="anaspat.html"><a href="anaspat.html#concentrations-du-semis"><i class="fa fa-check"></i><b>16.6</b> Concentrations du semis</a></li>
<li class="chapter" data-level="16.7" data-path="anaspat.html"><a href="anaspat.html#le-modele-nul-pour-un-semis-de-points"><i class="fa fa-check"></i><b>16.7</b> Le modele nul pour un semis de points</a></li>
<li class="chapter" data-level="16.8" data-path="anaspat.html"><a href="anaspat.html#afficher-la-distribution-le-retour"><i class="fa fa-check"></i><b>16.8</b> Afficher la distribution, le retour</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html"><i class="fa fa-check"></i><b>17</b> Autorcorrélation spatiale : Moran et Geary</a><ul>
<li class="chapter" data-level="17.1" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#lautocorrélation-spatiale"><i class="fa fa-check"></i><b>17.1</b> L’autocorrélation spatiale</a></li>
<li class="chapter" data-level="17.2" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#lindice-de-moran"><i class="fa fa-check"></i><b>17.2</b> L’indice de Moran</a></li>
<li class="chapter" data-level="17.3" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#lindice-de-geary"><i class="fa fa-check"></i><b>17.3</b> L’indice de Geary</a></li>
<li class="chapter" data-level="17.4" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#commandes-r"><i class="fa fa-check"></i><b>17.4</b> Commandes R</a></li>
<li class="chapter" data-level="17.5" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#exemples"><i class="fa fa-check"></i><b>17.5</b> Exemples</a></li>
<li class="chapter" data-level="17.6" data-path="autorcorrélation-spatiale-moran-et-geary.html"><a href="autorcorrélation-spatiale-moran-et-geary.html#exemples-1"><i class="fa fa-check"></i><b>17.6</b> Exemples</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="les-flux.html"><a href="les-flux.html"><i class="fa fa-check"></i><b>18</b> Les flux</a><ul>
<li class="chapter" data-level="18.1" data-path="les-flux.html"><a href="les-flux.html#matrice-de-flux"><i class="fa fa-check"></i><b>18.1</b> Matrice de flux</a></li>
<li class="chapter" data-level="18.2" data-path="les-flux.html"><a href="les-flux.html#indices"><i class="fa fa-check"></i><b>18.2</b> Indices</a></li>
<li class="chapter" data-level="18.3" data-path="les-flux.html"><a href="les-flux.html#cartographie-des-flux"><i class="fa fa-check"></i><b>18.3</b> Cartographie des flux</a></li>
<li class="chapter" data-level="18.4" data-path="les-flux.html"><a href="les-flux.html#exemple"><i class="fa fa-check"></i><b>18.4</b> Exemple</a></li>
<li class="chapter" data-level="18.5" data-path="les-flux.html"><a href="les-flux.html#pour-aller-plus-loin"><i class="fa fa-check"></i><b>18.5</b> Pour aller plus loin</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html"><i class="fa fa-check"></i><b>19</b> Le modèle gravitaire</a><ul>
<li class="chapter" data-level="19.1" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html#fin-xixe-les-lois-de-ravenstein"><i class="fa fa-check"></i><b>19.1</b> Fin XIX<sup>e</sup> : Les lois de Ravenstein</a></li>
<li class="chapter" data-level="19.2" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html#le-modèle-gravitaire-1"><i class="fa fa-check"></i><b>19.2</b> Le modèle gravitaire</a></li>
<li class="chapter" data-level="19.3" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html#distance-et-interaction"><i class="fa fa-check"></i><b>19.3</b> Distance et interaction</a></li>
<li class="chapter" data-level="19.4" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html#utilisation-du-modèle-gravitaire"><i class="fa fa-check"></i><b>19.4</b> Utilisation du modèle gravitaire</a></li>
<li class="chapter" data-level="19.5" data-path="le-modèle-gravitaire.html"><a href="le-modèle-gravitaire.html#variantes-du-modèles-gravitaires"><i class="fa fa-check"></i><b>19.5</b> Variantes du modèles gravitaires</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="la-cartographie-comme-support.html"><a href="la-cartographie-comme-support.html"><i class="fa fa-check"></i><b>20</b> la Cartographie comme support</a><ul>
<li class="chapter" data-level="20.1" data-path="la-cartographie-comme-support.html"><a href="la-cartographie-comme-support.html#cartographier-le-résultats-de-traitements-statistiques"><i class="fa fa-check"></i><b>20.1</b> Cartographier le résultats de traitements statistiques</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="létape-daprès-modèles-dynamiques.html"><a href="létape-daprès-modèles-dynamiques.html"><i class="fa fa-check"></i><b>21</b> L’étape d’après : modèles dynamiques</a><ul>
<li class="chapter" data-level="21.1" data-path="létape-daprès-modèles-dynamiques.html"><a href="létape-daprès-modèles-dynamiques.html#modèles-simples-les-automates-cellulaires"><i class="fa fa-check"></i><b>21.1</b> Modèles simples : les automates cellulaires</a></li>
<li class="chapter" data-level="21.2" data-path="létape-daprès-modèles-dynamiques.html"><a href="létape-daprès-modèles-dynamiques.html#modèles-complexes-mobilité"><i class="fa fa-check"></i><b>21.2</b> Modèles complexes : mobilité</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Published with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Analyse Statistique M2 IGAST</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bivariee" class="section level1">
<h1><span class="header-section-number">Chapitre 9</span> Analyse Bivariée</h1>
<p>L’analyse bivariée , comme son nom l’indique, a pour objectif d’analyser le lien qui peut exister entre <strong>deux</strong> variables.</p>
<p>En guise de rappel sur les types de variables (cf section <a href="intro.html#vocabulaire">1.5</a>) , donnons des exemples:</p>
<p>Pour deux variables quantitatives , on pourrait analyser le lien entre :</p>
<ul>
<li>le nombre d’habitants et nombre de lignes de bus des départements français</li>
<li>le nombre de lignes de bus en Isère en 1998 et en 2018</li>
</ul>
<p>Pour deux variables qualitatives, on pourrait analyser le lien entre :</p>
<ul>
<li>la couleur des yeux et le fait de porter des lunettes</li>
<li>les catégories de séries télé et la plate-forme où ils sont disponibles</li>
</ul>
<p>Enfin, pour une variable quantitative et une variable qualitative :</p>
<ul>
<li>le lien entre la taille et la couleur des yeux,</li>
<li>le lien entre le nombre d’aces d’un joueur et le côté du cours de tennis qu’il occupe</li>
</ul>
<div id="analyse-bivariée-mais-sans-la-localisation" class="section level3">
<h3><span class="header-section-number">9.0.1</span> Analyse bivariée, mais sans la localisation</h3>
<p>L’analyse bivariée que nous allons aborder dans ce chapitre concerne des variables traditionnelles, i.e. <strong>pas des variables de localisation</strong> . Si elles proviennent de données spatiales, ce sera :</p>
<ul>
<li>soit des individus restreints spatialement (sélection spatiale)</li>
<li>soit des variables “géographiques” (e.g. lieu de résidence) renseignées pour les individus</li>
</ul>
<p>La <strong>localisation en tant que variable</strong> n’interviendra <strong>pas</strong> dans ce cours.</p>
</div>
<div id="ressources-pour-lanalyse-des-localisation-et-des-distances" class="section level3">
<h3><span class="header-section-number">9.0.2</span> Ressources pour l’analyse des localisation et des distances</h3>
<p>Il existe des outils statistiques pour analyser le lien qui existe entre des variables localisées dans l’espace <em>et leur localisation elle-même</em>. Ces techniques <strong>ne sont pas au programme de ce cours</strong>, je les mentionne pour les curieux.</p>
<p>On peut ainsi mesurer l’ <strong>auto-corrélation spatiale</strong> , qui indique si les valeurs proches sont regroupées ou au contraire disséminées dans l’espace, à l’aide de l’<a href="https://en.wikipedia.org/wiki/Moran%27s_I">indice de Moran global</a>, et identifier des clusters de valeurs plus fortes ou plus faibles que la normale à l’aide de l’<a href="https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html">indice de Moran local</a>.</p>
<p>On peut également effectuer des régressions qui tiennent compte de la localisation des observations dans l’espace, qu’on appelle GWR pour <strong>Geographicaly Weighted Regression</strong> (plus de détails <a href="https://fr.wikipedia.org/wiki/R%C3%A9gression_g%C3%A9ographiquement_pond%C3%A9r%C3%A9e">sur wikipedia</a> et la <a href="https://www.google.com/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=&amp;ved=2ahUKEwjxtrK85pvuAhX2DmMBHdDaCTwQFjAAegQIAxAC&amp;url=https%3A%2F%2Fwww.insee.fr%2Fen%2Fstatistiques%2Ffichier%2F3635545%2Fimet131-m-chapitre-9.pdf&amp;usg=AOvVaw0Mli34vfm-BI1PymvssD5Y">fiche de l’INSEE</a>)</p>
<p>Enfin , si on désire prendre en compte les <strong>distances</strong> dans les flux entre unités spatiales (par exemple pour expliquer les déplacements domicile-travail dans une région) on peut se tourner vers les <a href="https://www.hypergeo.eu/spip.php?article76">modèles gravitaires</a></p>
<p>Nous donnerons à la fin de ce cours quelques éléments à ce sujet dans la section <a href="anaspat.html#anaspat">16</a></p>
</div>
<div id="corrélation-nimplique-pas-causalité" class="section level2">
<h2><span class="header-section-number">9.1</span> Corrélation n’implique pas causalité</h2>
<p>Nous allons voir comment quantifier l’intensité du <strong>lien statistique</strong> qui peut exister entre deux variables.</p>
<center>
<span style="color:red; font-size:1.5em"> ⚠ Une liaison, même très forte, entre deux variables, n’indique pas la causalité! ⚠</span>
</center>
<p><br>
Cette erreur d’amalgame entre corrélation et causalité est très courante, très tentante, justement à cause du fait que l’amalgame «marche» dans de nombreux cas empiriques.</p>
<p>De nombreux contre-exemples sont heureusement disponibles pour finir de se convaincre que la <strong>corrélation n’implique pas la causalité</strong>:</p>
<p><img src="chart.svg"/></p>
<p>© TylerVigen <a href="http://tylervigen.com/spurious-correlations" class="uri">http://tylervigen.com/spurious-correlations</a> <span class="math inline">\(\leftarrow\)</span> D’autres exemples sont disponibles à cette adresse.</p>
<div id="diverses-formes-de-dépendances" class="section level3">
<h3><span class="header-section-number">9.1.1</span> Diverses formes de dépendances</h3>
<p>Ce qu’on appelle <strong>lien</strong> ou <strong>liaison</strong> ou encore <strong>dépendance</strong> entre les variables expriment le fait que les valeurs de deux variables n’évoluent pas indépendamment mais au contraire présentent une certaine <strong>forme</strong> une certaine <strong>régularité</strong>.</p>
<p>Ces «régularités» peuvent être de plusieurs formes, en voici quelques unes :</p>
<p><img src="bookdown_cours_stats_files/figure-html/formes-1.png" width="768" style="display: block; margin: auto;" /></p>
<p>Cette matrice de graphes, de gauche à droite et de haut en bas montre :</p>
<ul>
<li>une dépendance linéaire positive</li>
<li>une dépendance linéaire négative</li>
<li>une dépendance non-linéaire , peut-être exponentielle</li>
<li>une dépendance périodique, sinusoïdale</li>
<li>une absence de dépendance, les deux variables sont indépendantes</li>
<li>une absence de dépendance, la variable de l’axe des <span class="math inline">\(y\)</span> est constante</li>
</ul>
<p>En pratique les formes sont beaucoup moins régulières que ces exemples très «mathématiques» : les données peuvent être bruitées, incomplètes, contenir des outliers, etc.</p>
</div>
<div id="les-étapes-de-lanalyse-bivariée" class="section level3">
<h3><span class="header-section-number">9.1.2</span> Les étapes de l’analyse bivariée</h3>
<p>On peut résumer la démarche ‘mentale’ à adopter devant un jeu de données par cette séquence:</p>
<ol style="list-style-type: decimal">
<li>Tracer le nuage de points</li>
<li>Existe-t-il une relation ?</li>
<li>Est-elle de forme linéaire ? De quel sens ?</li>
<li>Si la liaison est de forme linéaire <span class="math inline">\(\rightarrow\)</span> faire une <strong>régression</strong></li>
<li>Si la liaison est non linéaire, est-elle monotone ? De forme connue ?<span class="math inline">\(\rightarrow\)</span> proposer un <strong>modèle</strong>, i.e. une équation qui décrive la forme de la dépendance entre les deux variables.</li>
<li>(5bis)Réaliser un modèle <strong>LOESS</strong> avec prudence (uniquement descriptif , aucun pouvoir de généralisation)
cf le blog de Lise Vaudor [<a href="http://perso.ens-lyon.fr/lise.vaudor/regression-loess/" class="uri">http://perso.ens-lyon.fr/lise.vaudor/regression-loess/</a>]</li>
</ol>
<p>Voici un arbre de décision plus précis :</p>
<p><img src="decisionTreeCorr.svg"/></p>
</div>
</div>
<div id="régression-linéaire" class="section level2">
<h2><span class="header-section-number">9.2</span> Régression linéaire</h2>
<div id="avant-toute-chose" class="section level3">
<h3><span class="header-section-number">9.2.1</span> Avant toute chose</h3>
<p>Vous devriez commencer à avoir l’habitude de ce mantra, encore plus valable dans le cas d’une analyse bivariée :</p>
<p><span style="color:red; font-size: 1.5em;">Toujours en premier: Regarder l’aspect des données avec des graphiques </span></p>
<p>Si le nuage de point n’est pas allongé, si vous “voyez” clairement qu’une droite ne le résulera pas, ou alors très mal, il n’est pas nécessaire d’entreprendre une rregression linéaire, qui sera de toute façon décevante!</p>
<p>La regression linéaire ne concerne que les <strong>variables quantitatives</strong>.</p>
</div>
<div id="principe-et-vocabulaire" class="section level3">
<h3><span class="header-section-number">9.2.2</span> Principe et Vocabulaire</h3>
<div id="droite-de-régression" class="section level4">
<h4><span class="header-section-number">9.2.2.1</span> Droite de régression</h4>
<p>Si la forme du nuage de points s’y prête, c’est-à-dire bien allongée, rectiligne, on peut entreprendre une <strong>régression linéaire</strong> (aussi appelé <strong>ajustement</strong> linéaire).</p>
<p>Cela consiste à trouver la droite qui passe «<strong>au mieux</strong>» dans le nuage de points de deux variables quantitatives <span class="math inline">\(V_1\)</span> et <span class="math inline">\(V_2\)</span>, celle qui <strong>résume</strong> le nuage de points d’une façon satisfaisante.</p>
<p>«<strong>au mieux</strong>» est ici employé au sens des <strong>moindres carrés</strong>, c’est-à-dire que parmi toutes les droites qui peuvent passer au milieu du nuage de points, on va choisir celle pour laquelle l’erreur commise est la plus faible.</p>
<p>On cherche la droite (en fait on cherche les deux coefficients <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> de son équation <span class="math inline">\(y=ax+b\)</span>) qui minimise la somme des carrés des écarts, d’où le nom d’estimation MCO (Moindres Carrés Ordinaires) ou OLS (Ordinary Least Squares in english).</p>
<p>Si le nuage de points n’est pas amorphe, sans forme, et que les deux variables ne sont pas totalement indépendantes, ou constantes, alors cette droite est <strong>unique</strong>.</p>
</div>
<div id="modèle-linéaire" class="section level4">
<h4><span class="header-section-number">9.2.2.2</span> Modèle linéaire</h4>
<p>En réalisant une régression linéaire, on cherche à <strong>expliquer</strong> une variable à partir d’une autre. «Expliquer» signifie ici «avoir un <strong>modèle</strong> pour calculer une valeur de la variable à partir d’une autre».</p>
<p>Dans le cas d’une régression linéaire, le modèle est l’équation de <strong>la</strong> droite ajustée, de la forme <span class="math inline">\(y=ax +b\)</span>, celle qui minimise la somme des écarts au carré.</p>
<p>On cherche donc les valeurs de <span class="math inline">\(a\)</span> et de <span class="math inline">\(b\)</span> (les coefficients du modèles linéaire) qui nous permettrait de calculer la valeur d’une variable (la variable dite <strong>expliquée</strong>) à partir d’une autre (la variable dite <strong>explicative</strong> ), que l’on peut écrire naïvement de cette façon :</p>
<p><span class="math display">\[Valeurs\ de\ la\ variable\ expliquée = modèle(Valeurs\ de\ la\ variable\ explicative)\]</span></p>
<p><span class="math display">\[Valeurs\ prédites\ de\ V_2 = modèle(V_1)\]</span></p>
<p>Ici, notre modèle est linaire, donc:</p>
<p><span class="math display">\[Valeurs\ prédites\ de\ V_2 = a\times V_1 + b\]</span></p>
<p><strong>Variable explicative</strong>:
C’est celle qui est utilisée par le modèle pour calculer les valeurs de la variable expliquée. Dans notre exemple , c’est <span class="math inline">\(V_1\)</span>. Par convention , on la met sur l’axe des <span class="math inline">\(x\)</span> dans les graphes.</p>
<p><strong>Variable expliquée</strong> :
C’est la variable pour laquelle le modèle propose des valeurs: dans notre exemple c’est <span class="math inline">\(V_2\)</span>. Par convention on la met sur l’axe des <span class="math inline">\(y\)</span> dans les graphes.</p>
</div>
<div id="estimation-prédiction-résidu" class="section level4">
<h4><span class="header-section-number">9.2.2.3</span> Estimation, Prédiction, Résidu</h4>
<p>On peut utiliser le modèle, pour <strong>estimer</strong> (=calculer, prédire) les valeurs de <span class="math inline">\(V_2\)</span>, avec les valeurs de <span class="math inline">\(V_1\)</span> et à l’aide de l’équation de droite. On note souvent les valeurs prédites <span class="math inline">\(\hat{V_2}\)</span>.</p>
<p>L’écart entre <span class="math inline">\(\hat{V_2}\)</span> et <span class="math inline">\(V_2\)</span> est appelé <strong>résidu</strong>.</p>
<p>Ainsi pour toutes les observations du jeu de données, on a :</p>
<p><span class="math display">\[V_2 =  prediction(V_1) + residu\]</span>
<span class="math display">\[V_2 =  \hat{V_2} + residu\]</span></p>
</div>
<div id="lerreur-commise-par-le-modèle" class="section level4">
<h4><span class="header-section-number">9.2.2.4</span> L’erreur commise par le modèle</h4>
<p>L’erreur commise par la droite, c’est la somme des écarts entre les points du nuage et la droite, les <strong>résidus</strong>, ces écarts sont élevés au carré avant d’être sommés pour que les erreurs positives et négatives ne se compensent pas. On appelle parfois cette somme la SSE (Sum of Square Erros in english) ou la RSS (Residuals Sum of Squares in english).</p>
<p>On peut l’écrire avec des notations différentes, mais la signification est toujours la même :</p>
<p><span class="math display">\[SSE = \sum_i (prediction_i - observation_i)^2\]</span>
<span class="math display">\[SSE = \sum_i ( modele(x_i)- x_i)^2\]</span>
<span class="math display">\[SSE = \sum_i ( ax_i + b - x_i)^2\]</span>
<span class="math display">\[SSE = \sum_i ( \hat{y_i}- x_i)^2\]</span></p>
<blockquote>
<p>On peut noter qu’il ne s’agit pas de la distance entre les points et la droite (leur projeté orthogonal), mais bien l’écart en ordonnée qui intervient dans ce calcul.</p>
</blockquote>
<p>Quasiment toutes les statistiques inférentielles reposent sur ce genre d’équation : on cherche un modèle d’une variable, à partir d’autres variables explicatives, et parmi les modèles possibles, on essaye de réduire l’erreur et de trouver le «bon» modèle: celui qui produise des résidus avec de nombreuses propriétés souhaitables : valeurs faibles, identiquement distribuées, de distributions proches de la gaussienne, sans auto-corrélation temporelle ni spatiale, etc.</p>
<p>Nous reviendrons dans la section bonus @ref{residuslm} sur la façon de qualifier les erreurs commises par un modèle linaire avec R.</p>
</div>
</div>
<div id="interpréter-la-droite-de-régression" class="section level3">
<h3><span class="header-section-number">9.2.3</span> Interpréter la droite de régression</h3>
<p>L’objectif de la régression linéaire est trouver le meilleur modèle linéaire entre deux variables. Ce modèle est l’équation d’une droite, qu’on appelle <strong>droite de régression</strong> et qui permet de visualiser:</p>
<ul>
<li>l’<strong>intensité</strong> de la dépendance, suivant que les points sont proches de la droite ou non</li>
<li>la <strong>forme</strong> de la dépendance, suivant que le nuage soit bien de forme linéaire</li>
<li>le <strong>sens</strong> de la dépendance : nulle, positive ou négative</li>
</ul>
<p><img src="bookdown_cours_stats_files/figure-html/regline-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Dans cet exemple, le nuage de point est assez allongé, on constate une dépendance linaire négative. Les points sont relativement proches de la droite.</p>
</div>
<div id="utiliser-un-modèle-linéaire" class="section level3">
<h3><span class="header-section-number">9.2.4</span> Utiliser un modèle linéaire</h3>
<p>L’<strong>équation</strong> de la droite est un <strong>modèle linéaire</strong> de la relation statistique qui lie <span class="math inline">\(V_1\)</span> et <span class="math inline">\(V_2\)</span>;</p>
<p>Ici le modèle est : <span class="math inline">\(\hat{V_2}=aV_1+b\)</span></p>
<p>Si la régression linéaire est réussie, alors pour un individu <span class="math inline">\(i\)</span> dont on connait <span class="math inline">\(V1_i\)</span>, on infère la valeur <span class="math inline">\(V_{2i}\)</span> par le modèle : <span class="math inline">\(\hat{V_{2i}} = aV_{1i} +b\)</span></p>
<p>On dit aussi que <span class="math inline">\(V_1\)</span> <strong>explique</strong> <span class="math inline">\(V_2\)</span> , ou que le modèle <strong>prédit</strong> <span class="math inline">\(V_2\)</span> à partir de <span class="math inline">\(V_1\)</span> (on note les valeurs prédites <span class="math inline">\(\hat{V_2}\)</span>).</p>
<p>Il est intéressant d’avoir un (bon) modèle de la relation entre <span class="math inline">\(V_2\)</span> et <span class="math inline">\(V_1\)</span>, car en l’absence d’observations supplémentaires de <span class="math inline">\(V_2\)</span> , on peut estimer les valeurs qu’elles prendraient si on dispose d’observations supplémentaires de <span class="math inline">\(V_1\)</span>.</p>
<p>Imaginez que des observations de <span class="math inline">\(V_2\)</span> soient particulièrement coûteuses à recueillir, et les observations de <span class="math inline">\(V_1\)</span> particulièrement peu coûteuses, par exemple la production de salive d’un tigre adulte en colère (<span class="math inline">\(V_2\)</span>) et la largeur de ses empreintes (<span class="math inline">\(V_1\)</span>).
En cas de bonne qualité de régressions, le.la zoologiste sera ravi.e de mesurer les largeurs d’empreintes.</p>
</div>
<div id="évaluer-la-qualité-dune-régression-linaire-le-r2" class="section level3">
<h3><span class="header-section-number">9.2.5</span> Évaluer la qualité d’une régression linaire : le <span class="math inline">\(R^2\)</span></h3>
<p>En pratique, pour considérer qu’une régression linéaire est de bonne qualité, i.e. que le modèle linéaire qui lie les deux variables décrit (explique, prédit, ..) bien les données, il faut réunir deux critères :</p>
<ul>
<li>des coefficients avec des <strong>p-values</strong> associées <strong>faibles</strong> (e.g. &lt;0.05) qu’on peut grossièrement traduire par “on a peu de chances de se tromper”</li>
<li>un <strong><span class="math inline">\(R^2\)</span> élevé</strong>, qu’on peut traduire par “le modèle prédit bien les observations”</li>
</ul>
<p>D’autres critères sont donnés en bonus à la section <a href="bivariee.html#residuslm">9.3.3</a>.</p>
<p>On commence par le <span class="math inline">\(R^2\)</span>.</p>
<div id="le-r2" class="section level4">
<h4><span class="header-section-number">9.2.5.1</span> le <span class="math inline">\(R^2\)</span></h4>
<p>Le <strong>coefficient de détermination linéaire</strong> , noté <span class="math inline">\(R^2\)</span> est une valeur qui décrit la <strong>qualité de prédiction</strong> de la régression, c’est-à-dire à quel point la droite de régression estime correctement les valeurs de la variable expliquée.</p>
<p>Il est défini par :
<span class="math display">\[R^2  = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y})^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</span></p>
<ul>
<li><span class="math inline">\(R^2 \in [0;1]\)</span></li>
<li>Plus le <span class="math inline">\(R^2\)</span> est proche de 1, meilleure est la qualité.</li>
</ul>
<p>Pour avoir l’intuition de l’interprétation de cette formule, on peut remarquer que la fraction est un ratio entre la somme des résidus au carrés (écart entre valeurs observées <span class="math inline">\(y_i\)</span> et valeur prédite <span class="math inline">\(\hat{y_i}\)</span>) et la variance (cf. section <a href="dispersion.html#variance">5.2</a>) de la variable expliquée (<span class="math inline">\(y\)</span>).</p>
<p>Le dénominateur de la fraction est constant , il vaut <span class="math inline">\(var(y)\)</span>
Alors, intuitivement , pour un mauvais modèle, qui prédit mal les observations de <span class="math inline">\(y\)</span>, la somme des résidus au carré sera importante, donc la fraction également, et la valeur de <span class="math inline">\(R^2\)</span> sera petite, proche de 0.
De la même manière, pour un bon modèle, qui prédit bien les valeurs de <span class="math inline">\(y\)</span>, les résidus seront faibles, donc leur somme quadratique également, ainsi que la valeur de la fraction, ce qui donnera un <span class="math inline">\(R^2\)</span> proche de 1.</p>
<p>Mentalement , on peut réécrire la formule ainsi :</p>
<p><span class="math display">\[R^2 \approx 1- \frac{résidus^2}{variance\ de\ y}\]</span></p>
<p><span class="math display">\[R^2 \approx 1- (erreur\ commise\ normalisée)\]</span></p>
</div>
<div id="propriétés-et-interprétation-additionnelles-du-r2" class="section level4">
<h4><span class="header-section-number">9.2.5.2</span> Propriétés et interprétation additionnelles du <span class="math inline">\(R^2\)</span></h4>
<p>Le <span class="math inline">\(R^2\)</span> peut s’écrire de plusieurs façons, notamment ainsi :</p>
<p><span class="math display">\[R^2  =  \frac{\sum_{i=1}^{n} (\hat{y_i} -\bar{y} )^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}\]</span></p>
<p>Cette expression est intéressante pour nous car on reconnait encore une fois une fraction de <em>variances</em> (cf. section <a href="dispersion.html#variance">5.2</a>) :</p>
<ul>
<li>au dénominateur , c’est la variance de <span class="math inline">\(y\)</span> , la variable expliquée</li>
<li>au numérateur , c’est la variance de <span class="math inline">\(\hat{y}\)</span>, la variable prédite par le modèle</li>
</ul>
<p>(les termes en <span class="math inline">\(\frac{1}{n}\)</span> des variances au numérateur et dénominateur se simplifient )</p>
<p>On peut donc voir le <span class="math inline">\(R^2\)</span> comme un ratio de variances : celles des estimations et celles des observations.
En faisant une regression, on cherche à «capturer» la variance de la variable expliquée à l’aide de la variance de la variable estimée par le modèle, d’où une valeur de <span class="math inline">\(R^2\)</span> proche de 1 lorsque la variance des estimations est proche de la variance des observations</p>
</div>
<div id="exemples-avec-différentes-valeurs-de-r2" class="section level4">
<h4><span class="header-section-number">9.2.5.3</span> Exemples avec différentes valeurs de <span class="math inline">\(R^2\)</span></h4>
<p>Voici des exemples de régression linéaire de différentes qualités avec la valeurs correspondante de <span class="math inline">\(R^2\)</span>, on donne aussi la valeur de la p-value, que nous aborderons juste après.</p>
<p><img src="bookdown_cours_stats_files/figure-html/expleR2_1-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Cette première régression est de bonne qualité: le <span class="math inline">\(R^2\)</span> est proche de 1, la droite décrit bien les données : peu de point s’en écartent significativement.</p>
<p><img src="bookdown_cours_stats_files/figure-html/expleR2_2-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Cette deuxième régression est de moindre qualité.
Certes, le nuages de points à une forme suffisamment “allongée” pour qu’on entreprenne une régression linéaire, mais celle-ci est de qualité intermédiaire : beaucoup de points sont éloignés de la droite, le nuage est assez dispersé, ce qui augmente les erreurs et donc amoindrit le score du <span class="math inline">\(R^2\)</span>.</p>
<p><img src="bookdown_cours_stats_files/figure-html/expleR2_3-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Avec ce dernier exemple volontairement exagéré, la qualité de la régression est mauvaise.</p>
<p>Certes la forme du nuage de points est linéaire, mais la bande est tellement large que les erreurs seront très grandes, même si la droite de régression passe bien au milieu. La variance de la variable 2 est telle qu’elle n’est pas suffisamment “capturée” par la droite.
On notera que les p-value sont très faibles, ce qui on va le voir, indique qu’on est à peu près certains de l<em>’équation de la droite</em>, c’est bien celle-ci qui passe “au mieux” dans le nuage de points. Le problème, c’est que ce nuage de points est tout simplement «mal» décrit par une droite, vu sa forme !</p>
</div>
</div>
<div id="évaluer-la-qualité-dune-régression-linaire-la-p-value" class="section level3">
<h3><span class="header-section-number">9.2.6</span> Évaluer la qualité d’une régression linaire : la p-value</h3>
<div id="la-p-value-et-lhypothèse-nulle" class="section level4">
<h4><span class="header-section-number">9.2.6.1</span> la p-value et l’hypothèse nulle</h4>
<p>La p-value est la seconde quantité qui nous renseigne sur la qualité d’une régression linéaire.
Le <span class="math inline">\(R^2\)</span> mesurait la qualité de prédiction du modèle linéaire, la <strong>p-value</strong> est plutôt associée avec la notion de confiance qu’on peut placer dans les coefficients du modèle linéaire que l’on obtient.</p>
<p>La façon d’interpréter correctement une p-value fait l’objet de nombreux débats, on en propose une ici, mais il y en a de nombreuses autres.</p>
<p><strong>Approximation grossière </strong> :</p>
<p>la p-value est le <strong>pourcentage de chances de se tromper</strong> en rejetant l’hypothèse nulle, c’est-à-dire se tromper en considérant que les deux séries ne sont pas indépendantes et qu’il existe une relation entre les deux (ici, linéaire car nous testons un modèle linéaire).</p>
<p>Sur la base de cette approximation, on peut d’ores et déjà dire que plus cette p-value est petite , mieux c’est.</p>
<p>La p-value est associée à la notion d’<strong>hypothèses nulle</strong>.
Ici , l’hypothèse nulle <span class="math inline">\(H_0\)</span> est <strong>“les deux variables sont indépendantes”</strong>.</p>
<ul>
<li><strong>rejeter <span class="math inline">\(H_0\)</span></strong> c’est considérer que les deux variables <strong>ne sont pas indépendantes</strong></li>
<li>(par abus de langage) <strong>conserver <span class="math inline">\(H_0\)</span></strong> c’est considérer qu’elles <strong>sont indépendantes</strong></li>
</ul>
<p>En statistique, on raisonne avec des hypothèses, qu’on rejette ou qu’on conserve, suivant la valeur de <strong>tests statistiques</strong>.</p>
<p>Par exemple, lorsqu’on teste si deux variables sont linéairement liées, on formule en fait une hypothèse <strong>alternative</strong> , <span class="math inline">\(H_1\)</span>, qui est «les deux variables sont linéairement liées».</p>
<p>Quand on rejette <span class="math inline">\(H_0\)</span> et qu’on a formulé une hypothèse alternative , on accepte <em>de facto</em> <span class="math inline">\(H_1\)</span>.</p>
<p><span class="math inline">\(H_0\)</span>, est l’hypothèse à formuler dans le cas <strong>le plus général possible</strong>, quand on ne sait rien du tout sur les données. Dans ce cas là, étant donné deux variables, on pose l’hypothèse qu’elles sont indépendantes, tout simplement parce qu’il n’y a aucune raison qu’elles soient liées.</p>
</div>
<div id="approximation-moins-grossière-à-propos-de-la-p-value" class="section level4">
<h4><span class="header-section-number">9.2.6.2</span> Approximation moins grossière à propos de la p-value</h4>
<p>La p-value peut s’interpréter comme «la probabilité d’avoir un résultat au moins aussi marqué étant donné l’hypothèse nulle»</p>
<p>Imaginez que vous ayez un jeu de données <span class="math inline">\(D_{ini}\)</span> constitué de 2 variables quantitatives pour 500 individus.
Le nuage de points est suffisamment allongé pour que vous entrepreniez une régression linéaire.
Vous obtenez une certaine valeur pour vos coefficients <span class="math inline">\(a_{D_ini}\)</span> et <span class="math inline">\(b_{D_ini}\)</span> de régression linéaire.
Vous pouvez même faire une test de corrélation de Pearson, et obtenir une valeur de corrélation élevée, bref , <strong>vous rejetez <span class="math inline">\(H_0\)</span> pour <span class="math inline">\(D_{ini}\)</span></strong></p>
<p>Maintenant imaginez qu’on génère une infinité de jeu de données <span class="math inline">\(\Gamma\)</span> à 2 variables et à 500 individus <strong>sachant</strong> <span class="math inline">\(H_0\)</span>, donc avec des variables indépendantes, des variables pour lesquelles on <strong>sait</strong> qu’il n’y a aucun lien.</p>
<p>Parmi cette infinité de jeu de données, il y en a une proportion qui, <strong>par hasard</strong>, <strong>par chance</strong>, présente des données qui ont la même forme que notre jeu de données, ou une forme suffisamment proche, qui donnerait des résultats <strong>aussi remarquables</strong> c’est à dire égaux ou encore plus marqués , de régression, la même droite, la même corrélation.</p>
<p>Trions l’infinité de jeu de données <span class="math inline">\(\Gamma\)</span> selon ce critère de résultats, d’un côté les jeux de données qui indique les même résultats que notre régression sur <span class="math inline">\(D_{ini}\)</span>, qu’on va noter <span class="math inline">\(\Gamma_{corrélés}\)</span>, de l’autre les jeux de données pour lesquels on ne peut pas conclure aux même résultats: il n’y a pas de corrélation entre les deux variables, la forme du nuage de points n’est pas assez linéaire pour qu’un analyste décide d’en faire une régression linéaire. On note ces jeux <span class="math inline">\(\Gamma_{indépendants}\)</span>.</p>
<p>Rappelons qu’on a généré cette infinité de jeu de données sous l’hypothèse <span class="math inline">\(H_0\)</span>.
On s’est donc trompés, pour tous les jeux de données étiquetés <span class="math inline">\(\Gamma_{corrélés}\)</span>, en obtenant des résultats de corrélation et de régression linéaire similaires (ou plus marqués encore) à ceux obtenus sur <span class="math inline">\(D_{ini}\)</span>.</p>
<p>On ne s’est pas trompés pour tous les jeux de <span class="math inline">\(\Gamma_{indépendants}\)</span></p>
<p>La p-value c’est la proportion <span class="math display">\[\frac{\Gamma_{corrélés}}{\Gamma}=\frac{\Gamma_{corrélés}}{\Gamma_{indépendants}+\Gamma_{corrélés}} \]</span>.</p>
<p>C’est la proportion de fois où on s’est trompés en affirmant à propos de <span class="math inline">\(\Gamma_{corrélés}\)</span> les résultats obtenus sur <span class="math inline">\(D_{ini}\)</span> alors qu’on avait des jeux de données où <span class="math inline">\(H_0\)</span> était vraie par construction.</p>
<blockquote>
<p>Évidemment cette proportion est très faible pour des cas où le lien entre les deux variables est marquée, mais comme on raisonne à l’infini elle ne sera jamais nulle !</p>
</blockquote>
</div>
<div id="ce-quil-faut-retenir-de-la-p-value" class="section level4">
<h4><span class="header-section-number">9.2.6.3</span> Ce qu’il faut retenir de la p-value</h4>
<ul>
<li>plus elle est petite, mieux c’est</li>
<li>en sciences expérimentales, le seuil de significativité est bas (~5%), en sciences sociales , il est plus haut.</li>
<li>elle s’interprète comme un pourcentage de chances de se tromper en première approximation</li>
<li>il faut plutôt le voir comme la probabilité d’obtenir par chance les même résultats de régression linéaire, pour une jeu de données de variables indépendantes de même taille.</li>
</ul>
</div>
</div>
</div>
<div id="effectuer-une-régression-linéaire-avec-r" class="section level2">
<h2><span class="header-section-number">9.3</span> Effectuer une régression linéaire avec R</h2>
<div id="la-commande-lm" class="section level3">
<h3><span class="header-section-number">9.3.1</span> La commande <code>lm</code></h3>
<p>La régression linéaire entre deux variables <code>x</code> et <code>y</code> s’obtient avec la fonction <code>lm(y ~ x)</code>.</p>
<p>Le premier argument est sous une forme particulière d’expression en R :une <strong>formule</strong>.</p>
<p>Elle s’écrit <code>Variable expliquée ~ Variable explicative</code> dans notre cas, puisque nous faisons une régression <em>univariée</em> , c’est-à-dire qu’on essaye d’expliquer une variable à l’aide d’une seule autre variable.</p>
<div class="sourceCode" id="cb53"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb53-1"><a href="bivariee.html#cb53-1"></a><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span>iris<span class="op">$</span>Petal.Width)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = iris$Petal.Length ~ iris$Petal.Width)
## 
## Coefficients:
##      (Intercept)  iris$Petal.Width  
##            1.084             2.230</code></pre>
</div>
<div id="format-des-résultats" class="section level3">
<h3><span class="header-section-number">9.3.2</span> Format des résultats</h3>
<p>La fonction <code>lm</code> renvoie une objet complexe, qui contient beaucoup d’informations.
Elles sont heureusement résumées sous une forme lisible en console par la fonction <code>summary()</code></p>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="bivariee.html#cb55-1"></a>regression &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb55-2"><a href="bivariee.html#cb55-2"></a><span class="kw">summary</span>(regression)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = iris$Petal.Length ~ iris$Petal.Width)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.33542 -0.30347 -0.02955  0.25776  1.39453 
## 
## Coefficients:
##                  Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)       1.08356    0.07297   14.85   &lt;2e-16 ***
## iris$Petal.Width  2.22994    0.05140   43.39   &lt;2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.4782 on 148 degrees of freedom
## Multiple R-squared:  0.9271, Adjusted R-squared:  0.9266 
## F-statistic:  1882 on 1 and 148 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>On y trouve dans l’ordre:</p>
<ul>
<li>la formule de la regression (section <code>Call</code>)</li>
<li>les quartiles des résidus (section <code>Residuals</code>)</li>
<li>les coefficients du modèle ajusté et leur <strong>p-value</strong> associée, ici sur un test de Student, notée <code>Pr(&gt;|t|)</code> (section <code>Coefficients</code>)</li>
<li>le <span class="math inline">\(R^2\)</span>, on pourra prendre la valeur étiquetée <code>Adjusted R-squared</code> (dernière section)</li>
</ul>
</div>
<div id="residuslm" class="section level3">
<h3><span class="header-section-number">9.3.3</span> Bonus: Critères de significativité du lien linéaire</h3>
<p>Ces critères portent sur les <strong>résidus</strong> <span class="math inline">\(\epsilon_i\)</span>, i.e. l’écart entre valeur observée et valeur prédite de la variable <span class="math inline">\(y\)</span> pour l’individu <span class="math inline">\(i\)</span></p>
<p><span class="math display">\[\epsilon_i= y_i - \hat{y_i}\]</span></p>
<p>Les résidus doivent:</p>
<ul>
<li>être indépendants : covariance nulle ou très faible <span class="math inline">\(cov(x_i, \epsilon_i) = 0\)</span></li>
<li>être distribués selon un loi normale de moyenne nulle <span class="math inline">\(\epsilon \sim \mathscr{N}(0,\sigma_{\epsilon})\)</span></li>
<li>être distribués de façon homogène (homoscédasticité), i.e. de variance constante <span class="math inline">\(var(\epsilon_i)=\sigma_{\epsilon}^2\)</span> , indépendante de l’observation</li>
</ul>
<p>On peut vérifier une partie de ces critères à l’aide des quartiles que donne R dans les résultats de régression.</p>
<div id="évaluation-de-lindépendance-des-résidus-avec-r" class="section level4">
<h4><span class="header-section-number">9.3.3.1</span> Évaluation de l’indépendance des résidus avec R</h4>
<p>On utilise les graphique de la fonction <code>acf</code>.</p>
<p>Si une barre exceptée la première dépasse la ligne en pointillés, on peut remettre en cause l’indépendance des résidus. Ici, c’est le cas. Cela ne veut pas pour autant dire que le modèle linéaire est à mettre à la poubelle, simplement qu’il y a une erreur systématique dans ses résidus, qui ne sont pas assez indépendants.</p>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="bivariee.html#cb57-1"></a>modele1 &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span><span class="st"> </span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb57-2"><a href="bivariee.html#cb57-2"></a><span class="kw">acf</span>(<span class="kw">residuals</span>(modele1))</span></code></pre></div>
<p><img src="bookdown_cours_stats_files/figure-html/residualSigni3-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="les-4-graphiques-résultats-de-la-fonction-lm" class="section level4">
<h4><span class="header-section-number">9.3.3.2</span> Les 4 graphiques résultats de la fonction <code>lm</code></h4>
<p>La fonction <code>lm</code> de R et ses résultats permettent de tracer 4 graphiques pour évaluer certains des critères de significativité.
Pour cela il suffit d’appeler la fonction <code>plot</code> sur l’objet résultat de la régression.</p>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="bivariee.html#cb58-1"></a>modele1 &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span><span class="st"> </span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb58-2"><a href="bivariee.html#cb58-2"></a><span class="kw">par</span>(<span class="dt">mfrow=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>)) <span class="co"># pour avoir une matrice de graphes</span></span>
<span id="cb58-3"><a href="bivariee.html#cb58-3"></a><span class="kw">plot</span>(modele1)</span></code></pre></div>
<p><img src="bookdown_cours_stats_files/figure-html/residualSignif-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="évaluer-lhomogénéité-des-résidus-avec-r" class="section level4">
<h4><span class="header-section-number">9.3.3.3</span> Évaluer l’homogénéité des résidus avec R</h4>
<p>Le premier graphique sert à vérifier que le nuage de points est homogène c’est-à-dire qu’il n’y a pas de relation non-linéaire entre résidus et valeurs prédites.</p>
<p>Une éventuelle relation non-linéaire pourrait se retrouver dans les résidus, et c’est normal. C’est «normal» puisqu’un modèle linéaire ne va capturer que des structures, des tendances <strong>linéaires</strong> entre deux variables. En cas de structure trop marquée dans les résidus, il faut peut être proposer un modèle non-linéaire, plus délicat à ajuster mais qui capturera plus de variance et laissera des résidus moins marqués.</p>
<p>Ici on observe une légère structure parabolique:</p>
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="bivariee.html#cb59-1"></a>modele1 &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span><span class="st"> </span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb59-2"><a href="bivariee.html#cb59-2"></a><span class="kw">plot</span>(modele1,<span class="dv">1</span>)</span></code></pre></div>
<p><img src="bookdown_cours_stats_files/figure-html/residualSignif1-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="bonus-évaluer-la-normalité-de-la-distribution-des-résidus-avec-r" class="section level4">
<h4><span class="header-section-number">9.3.3.4</span> Bonus: Évaluer la normalité de la distribution des résidus avec R</h4>
<p>Le deuxième graphique “Q-Q plot” : pour vérifier l’<strong>hypothèse de normalité des résidus</strong>, les points doivent être proches de la bissectrice</p>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="bivariee.html#cb60-1"></a>modele1 &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span><span class="st"> </span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb60-2"><a href="bivariee.html#cb60-2"></a><span class="kw">plot</span>(modele1,<span class="dv">2</span>)</span></code></pre></div>
<p><img src="bookdown_cours_stats_files/figure-html/residualSignif2-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="bonus-évaluer-lhomoscédasticité-des-résidus" class="section level4">
<h4><span class="header-section-number">9.3.3.5</span> Bonus: évaluer l’homoscédasticité des résidus</h4>
<p><span style="font-size:18px;"> Le troisème graphique “Scale location” : si les résidus sont distribués de façon homogène suivant les valeurs “fittées”, alors la droite est plutôt horizontale et les points sont disposés de façon homogène autour.</span></p>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="bivariee.html#cb61-1"></a>modele1 &lt;-<span class="st"> </span><span class="kw">lm</span>(iris<span class="op">$</span>Petal.Length<span class="op">~</span><span class="st"> </span>iris<span class="op">$</span>Petal.Width)</span>
<span id="cb61-2"><a href="bivariee.html#cb61-2"></a><span class="kw">plot</span>(modele1,<span class="dv">3</span>)</span></code></pre></div>
<p><img src="bookdown_cours_stats_files/figure-html/residualSignif3-1.png" width="576" style="display: block; margin: auto;" /></p>
<p><span style="font-size:18px;">Ici: légère pente mais les points sont distribués de façon relativement homogène autour de la droite.</span></p>
</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="visualiser-une-distribution-avec-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="correlation.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="book_assets/gitbook-2.6.7/js/app.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/lunr.js"></script>
<script src="book_assets/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="book_assets/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="book_assets/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["bookdown_cours_stats.pdf", "bookdown_cours_stats.epub"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
