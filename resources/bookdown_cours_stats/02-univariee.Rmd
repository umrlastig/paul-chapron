# Analyse Univariée {#univariee}

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.width =6,fig.align="center", fig.height = 3)
library(revealjs)
library(tidyverse)
library(palmerpenguins)
library(knitr)
library(xtable)
library(ggplot2)
library(gridExtra)
library(dplyr)
library(sf)
quartiers <-  st_read("data/quartier_paris.shp")

```




## Le concept de distribution

L'analyse univariée a pour but de **décrire**  et **mesurer** la **répartition** des valeurs que peut prendre une variable.

On appelle la répartition des valeurs d'un variable sa  **distribution** , que l'on peut approximativement voir comme son «histogramme en continu».

Voilà une distribution d'une variable réelle (courbe noire), superposée à son histogramme :  

```{r , expledistribhist, cache=TRUE, fig.height=2, echo=FALSE, warning=FALSE, message=FALSE}
library(palmerpenguins)
ggplot(penguins, aes(flipper_length_mm))+
   geom_histogram(aes(y=..density..), alpha=0.9, fill="darkcyan", color="darkgrey" ,
                position="identity")+
 geom_density(alpha=.5, fill="darkcyan")+
   labs(title= "Flipper length density of penguins population", x="Flipper length in mm")
```

Vous pouvez voir avec cet exemple, que la courbe suit les variations de hauteur des colonnes de l'histogramme, tout en lissant les aspérités.



 C'est de cette courbe que l'on parle lorsqu'on évoque la  **distribution** de la variable.

> Plus formellement, pour une population donnée,  la distribution d'une variable $V$ est définie comme une fonction qui donne la probabilité qu'un individu $x$ pris au hasard dans la population ait la valeur $V_x$  pour la variable $V$ : 
$$distribution(V) \equiv P(V=V_x), \forall V_x \in \Omega_V$$
> avec $\Omega_V$ l'ensemble des valeurs que peut prendre $V$ : l'univers de $V$. 
>Lorsque la variable prend des valeurs réelles, on parle de **densité** de probabilité, c'est pourquoi on retrouve ce terme "density" sur les axes des ordonnées dans les graphiques de distribution.   


La forme d'une distribution donne beaucoup d'informations sur les valeurs d'une variable dans une population  : 

 - valeurs les plus représentées dans la population : les "pics"
 - présence de valeurs extrêmes : la courbe de la distribution est tirées à gauche ou à droite du graphique
 - caractéristiques de sa forme : symétrie, aplatissement etc...


 Dans notre exemple de distribution de longueur de nageoires en millimètres, on observe deux pics assez  doux : l'un aux alentours de 190mm, l'autre de 215mm. On peut l'interpréter ainsi : «la valeurs la plus représentée dans les longueurs de nageoires de cette population de pingouins est de 190mm, suivie de 215mm»






### Interpréter la courbe de densité  {#interpret_dens}


L'histogramme représente l'effectif de la population en fonction de la valeur d'une variable, son interprétation est directe et aisée puisque ce graphique donne une représentation du nombre d'individus par intervalles de valeurs. 

La représentation d'une distribution est légèrement plus délicate à comprendre mathématiquement.
En première approximation , vous pouvez l'interpréter comme un histogramme dont les barres seraient infiniement fines, et dont l'axe des $y$ représenteraient une probabilité au lieu d'un effectif.

La densité de probabilité comme son nom l'indique, représente des probabilités: celles d'obtenir, pour un individu dans la population, une certaine valeur de la variable. 

Le point délicat est qu'une variable continue (i.e. définie sur un intervalle de $\mathbb{R}$), peut prendre une **infinité** de valeurs possibles, et que la probabilité d'obtenir **exactement**, c'est à dire avec une précision infinie, une valeur est infinitésimale, en fait carrément nulle. 


Il faut alors considérer la probabilité d'obtenir une valeur, non pas de façon exacte , mais dans un **intervalle** de valeur. Par exemple, dans le graphique ci-dessous, de s'intérroger sur la probabilité , pour un individu tiré au hasard dans la population , d'avoir une valeur de Variable 1 dans l'intervalle [25;30].

Cela pourrait s'écrire $P( 25  \leq   V_1  \leq 30)$ et serait égal à l'intégrale de la fonction de densité notée $f_{V_1}$ entre les bornes 25 et 30 de l'intervalle de $V_1$ : \int

$$P( 25  \leq   V_1  \leq 30) = \int_{25}^{30} f_{V_1}(x)dx$$


En pratique , le graphique d'une densité  s’interprète en observant la **quantité d'aire sous la courbe** 

L'aire totale sous la courbe vaut 1 (cela revient à considérer la somme de toutes les probabilités d'avoir une valeur particulière $X$  dans l’intervalle de valeur de $V_1$) et par approximation , la valeur de la probabilité d'obtenir une certaine valeur se lit comme la **proportion d'aire** sous la courbe comprise entre deux bornes proche de la valeur.  



```{r exple_dist, echo=FALSE, cache=TRUE, warning=FALSE, message=FALSE}
dens <- density(mpg$hwy)
idxborne25 <- which(dens$x > 25  )[1]
idxborne30 <- which(dens$x > 30  )[1]
dens$y[idxborne25:idxborne30] %>% sum
ggplot(data = mpg) +
  geom_density(aes(x=hwy), color="white", fill="darkcyan", alpha=0.7) +
  geom_vline(xintercept = 25)+
  geom_vline(xintercept = 30)+
  labs(title = "Distribution",
       subtitle = "",
       x = "Variable 1",
       y = "Densité"
       ) +
  theme_minimal()
```


ici , la valeur de $P( 25  \leq   V_1  \leq 30)$ vaut XXX



## Exemples de distributions de lois  connues

Parfois certaines distributions ressemblent à des distributions bien connues : on appelle ces distributions des **lois**.

Ce sont des distributions de probabilités que l'on peut formaliser par une équation et dont les statisticiens ont pu dériver des caractéristiques par le calcul.



### Loi Gaussienne 

La plus connue est la **distribution Gaussienne**, on dit aussi **distribution normale** du nom de la loi de probabilité qu'elle suit : la loi dite **normale**. 

Cette loi a deux paramètres : 

 - $\mu$ la moyenne, i.e. la valeur moyenne qu'auront les valeurs tirées de cette distribution
 - $\sigma$ l'écart type,  qui représente leur écartement par rapport à cette moyenne  

Nous reviendrons plus loin sur ces deux caractéristiques


Voici la distribution d'une population dont la variable $V1$ suit une loi normale de moyenne 0 et d'écart-type 1, qu'on note  $\mathscr{N}(0,1)$ 

```{r , expledistrib, cache=TRUE, fig.height=3.5 }
xx <- data.frame(value=rnorm(8000))
plot1 <- ggplot(xx)+
        geom_density(aes(x = value), color="#aaaaaa", fill="#44DD99" )+
        theme_light()+
        labs(title = "Loi Normale", x="Valeur de la variable V1 ", y="densité")
plot1
```

Voici un histogramme de la même population

```{r gaussienne1, cache=TRUE, fig.width=8, fig.height=3.5}
plot1 <- ggplot(xx)+
        geom_histogram(aes(x = value),bins = 50, color="#aaaaaa", fill="#44DD99" )+
        theme_light()+
        labs(title = "Loi Normale", x="Valeur de la variable V1", y="Effectif")
plot1
```


### Loi uniforme

Comme son nom l'indique, la loi uniforme vaut partout la même valeur entre deux bornes $a$ et $b$, autrement dit , la probabilité d'obtenir une certaine valeur $v\in[a;b]$ est constante.

La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout   mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois, la distribution, qui devrait être plate, est courbée aux extrémités.

```{r , distribunif1, cache=TRUE, fig.height=2, echo=FALSE}
yy <- data.frame(value=runif(1000000))
plot2 <- ggplot(yy)+
        geom_density(aes(x = value), color="#aaaaaa", fill="#44DD99" )+
        theme_light()+
        labs(title = "Loi uniforme", x="Valeur de la variable", y="densité")
plot2
```


La forme de sa distribution est théoriquement une fonction en créneau, qui vaut 1 partout sur $[a;b]$ mais en pratique quand on échantillonne (i.e. génère) des valeurs suivant cette loi, même un grand nombre de fois comme ici, la distribution, qui devrait être plate, est courbée aux extrémités. Cela est dû à la façon dont R estime la densité numériquement, biaisée aux extrémités de l'intervalle  

### Loi log-normale 


La loi log-normale  est comme son nom l'indique, le résultat d'un logarithme appliqué à une variable suivant une loi normale. 
Notez comme la distribution est «tirée vers la droite». On parle de «queue de distribution». 


Cette longue queue ("fat tail" in english) indique une grande inégalité dans la population: quelques individus, peu nombreux mais aux valeurs de variable très élevées, et une vaste majorité d'individus dont la valeur de la variable est faible  qui constitue le pic de la distribution.


```{r , distribexp1, cache=TRUE, fig.height=2, echo=FALSE}
yy <- data.frame(value=rlnorm(8000))
plot2 <- ggplot(yy)+
        geom_density(aes(x = value), color="#aaaaaa", fill="#44DD99" )+
        theme_light()+
        labs(title = "Loi log normale (0,1)", x="Valeur de la variable", y="densité")
plot2
```


Cette loi modélise par exemple l'effet d'un «grand nombre de petits facteurs considérés comme indépendants».

[Wikipedia](https://en.wikipedia.org/wiki/Log-normal_distribution#Occurrence_and_applications) nous apprend qu'elle modélise des phénomènes réels tels que la répartition de 97% des salaires du monde, celle de la la longueur et le poids de spécimen d'animaux, la durée des parties d'échecs, etc.
 




## Histogramme d'une distribution réelle


Les distribution de données empiriques ont rarement des formes aussi régulière et identifiable que celles des lois. Voici par exemple l'histogramme de la hauteur des arbres à Paris, selon les données disponibles sur  [https://opendata.paris.fr/]

```{r arbres1, cache=TRUE, fig.width=10, fig.height=3.5, echo=FALSE, message=FALSE,warning=FALSE}
library(sf)
xx <- read_sf("data/les-arbres.geojson") 
plot1 <- ggplot(xx)+
        geom_histogram(aes(x = hauteurenm),bins = 50, color="#aaaaaa", fill="#44DD99" )+
  xlab("Hauteur en mètres")+ ylab("Nombre")+
        theme_light()
plot2 <- ggplot(xx)+
        geom_histogram(aes(x = circonferenceencm),bins = 50, color="#aaaaaa", fill="#44DD99" )+
  xlab("Circonférences en centimètres")+ylab("Nombre")+
        theme_light()
grid.arrange(plot1, plot2,  ncol=2, nrow =1)
```


Cet histogramme n'est pas très informatif en l'état : si on le lit naïvement, il semblerait que tous les arbres aient une valeur nulle ou quasi-nulle pour leur hauteur en mètres et la circonférences de leur tronc en centimètres. 

Pourquoi ? 



Parce que le logiciel qui trace l'histogramme (R) fait du mieux qu'il peut pour tracer les colonnes de l'histogramme correspondant aux valeurs : 

- il ne doit pas en oublier,  
- la hauteur des colonnes doit correspondre à l'effectif (le nombre) d'individus (ici des arbres) par valeur de la variable
- l'échelle de l'axes $x$ doit «faire tenir» l'étendue des valeurs ($x_{max} - x_{min}$),sur une quantité de pixels limitée.


Ce qui se produit ici est que certains individus ont des hauteurs ou des circonférences renseignées à des valeurs totalement irréalistes, comme nous l'indique les bornes du dernier décile (i.e. les 10% des valeurs les plus élevées ) : 

```{r arbresQQ, cache=TRUE, fig.width=10, fig.height=3.5, echo=FALSE, message=FALSE,warning=FALSE}
quantile(xx$hauteurenm,probs = seq(0,1,0.1) )
```

10% des arbres ont une hauteur comprise entre 12 et 881818 mètres: il y a donc quelques arbres, au moins un,  dont la hauteur est clairement defectueuse, on peut supposer qu'il s'agit d'une erreur de saisie ou d' encodage des données (les plus hauts arbres font autour de 120m). On constate aussi qu'au moins 10% des données ont une hauteur nulle.

En affichant l'histogramme de cette variable, R a donc du afficher une colonne aux alentours de la valeur 881818, dont la hauteur est vraisemblablement très faible (1 ou 2 individus), en tout cas  si faible qu'on ne la distingue pas :  son épaisseur est dans le trait de l'axe des $x$  

Nous allons donc filtrer les données, pour ne conserver que les arbres dont la hauteur est comprise entre 1 et 60 mètres, ce qui me semble correct comme intervalle pour des hauteurs d'arbres parisiens, mais qui pourrait être discuté. De même , on écarte les arbres dont le tronc excède 2500 cm : 


```{r arbres2, cache=TRUE, fig.width=10, fig.height=3.5, echo=FALSE, message=FALSE,warning=FALSE}
library(sf)
xx <-xx %>%  filter(hauteurenm < 60 & hauteurenm > 1 & circonferenceencm < 2500  )

plot1 <- ggplot(xx)+
        geom_histogram(aes(x = hauteurenm),bins = 50, color="#aaaaaa", fill="#44DD99" )+
  xlab("Hauteur en mètres")+ ylab("Nombre")+
        theme_light()
plot2 <- ggplot(xx)+
        geom_histogram(aes(x = circonferenceencm),bins = 50, color="#aaaaaa", fill="#44DD99" )+
  xlab("Circonférences en centimètres")+ylab("Nombre")+
        theme_light()
grid.arrange(plot1, plot2,  ncol=2, nrow =1)
```




On voit ici comme la représentation graphique des variables nous renseigne à deux niveaux : elle nous indique la présence de valeurs aberrantes lors de son affichage "brut", et une fois filtrée, elle nous montre comment la population varie dans les valeurs de ses variables.


Nous allons maintenant voir comment décrire la forme de la répartition de ces valeurs avec des mesures statistiques.


# Statistique descriptive univariée : la tendance {#tendance}



Les distributions de variables dans les données du monde réel sont rarement constantes ou uniformes. Elles exhibent ce qu'on appelle une **tendance**, c'est-à-dire une valeur autour de laquelle se retrouvent la majorité des individus. 

Si la forme de la distribution est suffisamment régulière, cette tendance peut servir de **résumé** statistique de la variable de la population.


Les indicateurs de tendance centrale de la distribution d'une variable sont la 
**moyenne** et ses variantes, la **médiane** et le **mode**.

## Moyenne


La moyenne d'une variable $x$ , notée $\bar{x}$ , s'écrit :

$$ \bar{x} = \frac{1}{n}\sum_{i=0}^{n} x_i $$


### Moyenne pondérée

Lorsque des poids $p_i$ sont affectés aux individus, la moyenne pondérée s'écrit :

$$ \bar{x} = \frac{1}{\sum_{i=0}^n pi}\sum_{i=0}^{n} p_i x_i $$



### Avantages et inconvénients de la moyenne

**Avantage** : chaque valeur compte dans le calcul.

**Inconvénients** : 

* sensibilité aux valeurs extrêmes 
* pas de signification directe sur les variables quantitatives discrètes (e.g. «2.5 enfants/femme» )



Pour y remédier : 

- exclure les outliers, ou restreindre les valeurs considérées par filtrage
- utiliser un autre estimateur, par exemple la médiane
- étudier la distribution des valeurs et en cas de multi-modalités, opérer une classification




### Autres Moyennes


#### Moyenne geométrique:

Elle s'écrit ainsi : 

$$ \bar{x} = \sqrt[n]{\prod _{i=0}^{n} x_i}$$  



Elle a l'avantage d'être moins sensible à la présence de valeurs extrêmes que la moyenne algébrique. 


#### Moyenne quadratique (RMS) 

Elle s'écrit : 


$$\bar{x} = \sqrt{\frac{1}{n}\sum _{i=0}^{n} x_i^2} $$


#### Hors sujet : Moyenne glissante

Ce n'est pas une moyenne comme les autres, au sens où elle ne résume pas toute une série de valeurs 

Dans le cas de séries temporelles (i.e. valeurs successives de la même variable), la moyenne glissante est calculée sur une «fenêtre» de $n$ valeurs consécutives.
La fenêtre est centrée sur l'instant auquel on calcule la valeur de la moyenne. 

Par exemple, pour une moyenne glissante sur une fenêtre de taille 10, la valeur en chaque points $x_i$ à la position $i$ dans la série temporelle (on suppose que $i>5$)  vaut la moyenne des de $x_i$ et des 10 valeurs environnantes, 5 en avant , 5 en arrière :   

 

$$\bar{x} = \frac{1}{11}\sum _{j=i-5}^{j=i+5} x_j$$




## Mode {#mode}

Le **mode** d'une variable est **la valeur la plus fréquente** ( d'effectif maximum) d'une variable.


Si la variable est quantitative et continue, il faut découper l'étendue de la variable (la différence entre la valeur maximum et minimum) en intervalle égaux , puis réaliser une classification des individus dans ces intervalles et un comptage des effectifs de chaque classe. 
Dans ce cas, le mode est la moyenne des valeurs min et max des bornes de la classe de plus grand effectif.


C'est exactement ce que fait un histogramme graphiquement ! 



### Avantages et inconvénients du mode

**Avantages** : 

- Peu sensible aux valeurs extrêmes (moins sensible que la moyenne)
- il s'interprète facilement : c'est la situation la plus fréquente dans la population

**Inconvénients** : 

le mode ne dépends pas de toutes les observations : la modification d'une seule valeur n’entraîne pas une modification du mode. Cet inconvénient explique sa robustesse aux valeurs extrêmes



## Médiane {#mediane}

La **médiane** est la valeur qui partage une série de valeurs en **deux sous-ensembles d’égal effectif**

Comme en géométrie, la médiane est la valeur de la variable qui est la plus proche de toutes les autres.


### Étapes de calcul 

Déterminer la médiane d'un ensemble de valeurs est très simple : 

  1.  Ordonner les $n$ valeurs de $V$ selon un ordre croissant
  2. Calculer le rang $rg=\frac{n+1}{2}$
  3. si $n$ impair, la valeur médiane est $V[rg]$. Si $n$ est pair, la valeur médiane est entre deux valeurs et est égale à la moyenne de $V[\frac{n}{2}]$ et $V[\frac{n}{2}-1]$ 

<small> Dans cet algo , on suppose qu'on compte les cellules d'un tableau à partir de 0, comme en python. En R, où on compte les cellules à partir de 1 , il faudrait ajouter 1 à tous les indices. </small>


### Avantages et inconvénients de la médiane 

**Avantages** : 

 - Souvent plus pertinente que la moyenne 
 - Peu sensible aux valeurs extrêmes: quelques valeurs très fortes ou très faibles ne modifie pas sa valeur 
 - elle s'interprète facilement : comme elle divise en deux la distribution, un individu sur deux a une valeur inférieure (respectivement supérieure) à  la médiane.

**Inconvénient** :

Comme le mode, la médiane ne dépend pas de toutes les observations : la modification d'une seule valeur n’entraine pas une modification de la médiane. 





Notons que la robustesse de la médiane est bien utile dans le cas de distribution particulièrement asymétriques, où la moyenne est dégradée par les valeurs extrêmes, à droite (valeurs très élevées) ou à gauche (valeurs très faibles). 

Par exemple , pour les revenus mensuels en équivalent temps plein en France en 2016 : 
le revenu mensuel net moyen est de 2 238 €, le revenu mensuel net médian est de  1 789 € :
selon l'[https://www.insee.fr/fr/statistiques/4277680?sommaire=4318291]

Supposons qu'on cherche à évaluer si un salaire mensuel net équivalent temps plein de 2000€ est un *bon salaire* en France, sans définir trop rigoureusement ce qui signifie «bon».

 - 2000€ est inférieur à la moyenne du pays, on peut le considérer comme trop bas pour être «bon».
 - 2000€ est supérieur au salaire médian, il est supérieur à (au moins) la moitié des salaires du pays, et on peut le considérer comme un «bon» salaire.


 Cette double interprétation est due au fait que certains salaires très élevés, mais d'effectifs peu nombreux, tirent la distribution du salaire vers la droite, et avec eux, la moyenne. 





## Quelle mesure de tendance choisir ?

Tout dépend de la distribution ! 

(cette réponse est malheureusement quasiment universelle, d'où l'importance de **toujours représenter visuellement les variables** pour décider en connaissance de cause )



Si la distribution n'a pas de longue queue (on dit aussi **traîne**) , la moyenne et la médiane sont adaptées.


Si la distribution exhibe plusieurs modes , il faut réaliser une classification puis calculer médiane et moyenne pour chaque classe.


Le **mode** est privilégié pour les variables  **nominales** c'est-à-dire des variables qualitatives dont les modalités ne sont pas ordonnées, et si on désire considérer «le cas le plus fréquent»





### Cas délicat : Distribution bimodale 

```{r bimod1, cache=TRUE, echo=FALSE,fig.width=8, fig.height=3.5}
xx <- data.frame(value=rnorm(1600,mean = 5, sd = 1))
yy <- data.frame(value= rnorm(1400, mean = 10, sd=2) )
xx <-  rbind(xx, yy)
plot1 <- ggplot(xx)+
        geom_line(aes(x = value),stat = "density", color="#44DD99", lwd= 1.3)+
        geom_vline(xintercept = mean(xx$value), color="red")+
        geom_vline(xintercept = median(xx$value),color="blue")+
        annotate("text", x=c(8,5.5), y=c(0.2,0.2), colour=c("red","blue"),label=c("mean", "median"))+
        theme_light()
plot1
```

Que choisir : moyenne ou médiane ? 


## Distribution unimodale symétrique 

```{r gaussienne2, cache=TRUE, fig.width=8, fig.height=3.5}
xx <- data.frame(value=rnorm(2900,mean = 5, sd = 1))
plot1 <- ggplot(xx)+
        geom_line(aes(x = value),stat = "density", color="#44DD99", lwd= 1.3)+
        geom_vline(xintercept = mean(xx$value), color="red")+
        geom_vline(xintercept = median(xx$value) + 0.02,color="blue")+
        annotate("text", x=c(4.5,5.5), y=c(0.2,0.2), colour=c("red","blue"),label=c("mean", "median"))+
        theme_light()
plot1
```


## Histogramme et distribution en R


la fonction `hist` affiche un histogramme d'un vecteur **numerique**:

```{r histoR}
x <-  rnorm(2500) #init
hist(x)
```

## Histogramme et distribution en R

un histogramme n'a pas de sens  pour une variable **qualitative**. 

On peut utiliser `barplot`,<span style="color:red; font-size:1;">&#9888;</span> mais ce n'est plus une distribution ! 

```{r histoR2,fig.width=8 }
x <-  sample(month.name, 2500, replace=T)
tx <- table(x)
barplot(tx , las=2)
```



# Statistique descriptive univariée : la dispersion
<br><br><br>
Variance, écart-type, Coeff. de variation.



## La **dispersion** statistique 

Tendance des valeurs d'une variable à se disperser autour des valeurs des tendances centrales.
```{r gaussienne2D, cache=TRUE, fig.width=10}
mydataset <- data.frame(X=rnorm(900), Y=rnorm(900))
plot1 <- ggplot(mydataset)+
        geom_point(aes(x=X, y=Y), fill="#44DD99", color="#666666", shape=21)+
        coord_equal()+theme_light()
plot1
```


## Variance et Écart-type

La **variance** est la somme des écarts carrés à la moyenne rapporté à l'effectif

$\displaystyle var_X= \frac{1}{n}\sum_{i=1}^{n}(x_i -\bar{x})^2$

Avec :
  * $X$ une variable
  * $x_i$ les valeurs de la variables
  * $\bar{x}$ la moyenne de $X$ 
  * $n$ l'effectif

$\sigma_X = \sqrt{var_X}$  : l'**écart type** est la racine carrée de la variance

## Variance et Écart-type

Variance et écart-type rendent compte de la **dispersion** de la variable autour de sa moyenne.

Ils sont **sensibles** aux valeurs extrèmes et toujours **positifs**.

Si $var_X = 0$ ou $\sigma_X = 0$ , alors $X$ est **constante**.

Un écart-type faible indique que les valeurs sont réparties de façon **homogène** autour de la moyenne.

## Précaution {.flexbox .vcenter}

<span style="color:red; font-size:1.5em;">&#9888;</span>Variance et écart type n'ont d'intérêt que pour qualifier des distributions **unimodales**, et (à peu près) **symétriques**


(i.e. proche de la Gaussienne)


## Lorsque $X\sim \mathscr{N}(\mu,\sigma)$

```{r stddev1, cache=TRUE, echo=FALSE}
library(latex2exp)
X <- data.frame(value=rnorm(1900))
plot1 <- ggplot(X)+
        geom_line(aes(x = value),stat="density", color="#44DD99", lwd=1.2)+
        geom_vline(xintercept = c(-sd(X$value), sd(X$value)), color="red")+
        geom_vline(xintercept = c(-2*sd(X$value), 2*sd(X$value)), color="blue")+
        annotate("text", x=c(1.5,2.5), y=c(0.3,0.12), colour=c("red","blue"),label=c("68,27% de l'effectif ", "95,45% de l'effectif "))+
        theme_light()
plot1
```


<br>
$[-\sigma;\sigma] \approx \frac{2}{3}$  de l'effectif
<br>
<br>
$[-2\sigma;2\sigma] \approx$ 95% de l'effectif

## Quantiles

La **médiane** sépare une population en **deux** classes d'égal effectif selon la valeur d'une variable (quantitative).

Les **quantiles**  séparent une population en **$n$** classes d'égal effectif 

Les **quartiles** d'une population selon une variable $X$ sont trois valeurs, $Q_1,Q_2,Q_3$ qui séparent la population en **quatre** classes d'égal effectif.
<small>

  * 25% des valeurs de $X$ sont strictement inférieures à $Q_1$
  * 50% des valeurs de $X$ sont strictement inférieures à $Q_2$ (médiane)
  * 75% des valeurs de $X$ sont strictement inférieures à $Q_3$
  
</small>

## Déciles

Les déciles sont les **9** quantiles $Q_1,Q_2,\dots,Q_9$ qui séparent une population  selon la valeur d'une variable quantitative en **10** classes d'égal effectif.

## Ecarts inter-quartiles et inter-déciles

Deux mesures de la **dispersion** d'une distribution : 

<br><br>
**Écart inter-quartile**: $Q_3-Q_1$ , capture 50% des valeurs de la population les plus proches de la médiane

<br><br>
**Écart inter-déciile**: $Q_9-Q_1$ , capture 80% des valeurs de la population les plus proches de la médiane

## Les boîtes à moustaches (boxplots)

représentation courante de la dispersion d'une variable à l'aide de **quartiles**


```{r boxplot1, cache=TRUE}
plot1 <- ggplot(iris)+
  geom_boxplot(aes(y=Sepal.Width,x= Species) ) + coord_flip()
plot1
```

## Interprétation des boxplots

* La marque centrale de la boîte est la médiane 
* Les bords de la boîte sont les quartiles $Q_1$ et $Q_3$
* Les extrémités des moustaches vont jusqu'à la plus grande (resp. la plus petite ) valeur inférieure (resp. supérieure)  à 1.5 fois l’écart interquartile 
* Les valeurs qui dépassent les moustaches sont affichées sous formes de points

```{r boxplot2, cache=TRUE, echo=FALSE}
plot1 <- ggplot(iris)+
  geom_boxplot(aes(y=Sepal.Width,x= Species) ) + coord_flip()
plot1
```



## Avantages et inconvénient des quantiles

### Avantages

Peu sensibles aux distributions aplaties et aux valeurs extrèmes

L'écart inter-quantile est plus robuste que l'écart-type

### Inconvénients

Parfois délicat pour les variables quantitatives discrètes

Les écarts inter-quantiles négligent l'influence des valeurs extrèmes sur la distribution

## Le coefficient de variation 

Le **coefficient de variation** ($CV$) est une autre mesure de dispersion.

C'est le ratio entre l'écart-type $\sigma_x$ et la moyenne $\bar{x}$ d'une variable quantitative $X$.

$\displaystyle CV(X)=\frac{\sigma_x}{\bar{x}}$

Plus il est important , plus la dispersion est grande.

Plus il est proche de 0, plus les données sont homogènes.


Il souffre des mêmes inconvénients que la moyenne et l'écart-type : sensibilité aux valeurs extrèmes.

## Comparaison de dispersion de deux distributions de valeurs.



Exemple : deux communes  versent des aides aux entreprises locales. 

Commune A :  moyenne = 390 euros, $\sigma$ = 30 euros 

Commune B :  moyenne = 152 euros, $\sigma$ = 8 euros

Pour quelle commune les aides sont les plus homogènes?

<br><br>
<small>On pourrait aussi comparer des distribution de valeurs exprimées dans des unités différentes !</small>

## **(Mauvaise)** Comparaison visuelle de deux distributions

<span style="font-size:60%; margin-top:-50px">Pour échantilloner dans une loi normale : fonction `rnorm`</span>

```{r compDistNorm1, fig.height=2.8}
A <-  rnorm(n = 10000, mean = 390, sd = 30)
B <-  rnorm(n = 10000, mean = 152, sd = 8)
par(mfrow=c(1, 2)) #2 graphes en colonnes
hist(A, probability = T)
lines(density(A), col="red")
hist(B, probability = T)
lines(density(B), col="red")
```
Qu'est ce qui ne va pas ?


##  Comparaison visuelle de dispersion de deux distributions


Il faut une **échelle commune** !

```{r compDistNorm2}
A <-  rnorm(n = 10000, mean = 390, sd = 30)
B <-  rnorm(n = 10000, mean = 152, sd = 8)
par(mfrow=c(1, 2))
hist(A, probability = T, xlim = c(50,600), ylim = c(0,0.05))
lines(density(A), col="red")
hist(B, probability = T,xlim = c(50,600), ylim = c(0,0.05))
lines(density(B), col="red")
```



# Statistique descriptive univariée : la forme
 
 <br>
 <br> <br> 
 Symétrie , applatissement
 
  
## **Asymétrie** des distributions.


```{r asym1, echo=FALSE, fig.width=8, fig.height=4, cache=TRUE}

xx <- seq(-5,5, length.out = 100)
normale <-  dnorm(xx,mean = 0, sd=1)
xxx <- seq(0,10, length.out = 100)
droite <-  dgamma(xxx,2,1)

droiteValues <-  rgamma(1000,2,1)
droiteValues <-  rgamma(1000,2,1)

xxxx <-seq(10,0, length.out = 100) 
gauche <- dgamma(xxxx, 2,1)
mydata <- data.frame(value=xx, dens=normale, type="Normale", moy=0, med=0, mod=0)
droitedata <- data.frame(value=xxx, dens=droite, type="Asymétrique positive", moy=mean(droiteValues), med=median(droiteValues), mod = 1)
gauchedata <- data.frame(value=xxx, dens=gauche, type="Asymétrique négative", moy=10-mean(droiteValues), med=10-median(droiteValues), mod=9)

gauchedata <- rbind( gauchedata, mydata)
gauchedata <- rbind(gauchedata, droitedata)

ggplot(gauchedata, aes(x=value, y=dens))+geom_line(color="#44DD99", lwd=1.2)+
  geom_vline(aes(xintercept = moy), col="red")+
  geom_vline(aes(xintercept = med), col="blue")+
  geom_vline(aes(xintercept = mod), col="orange")+
  facet_grid(cols=vars(type), scales="free")+
  ylab(label = "density")+
  theme_light()+
  annotate("text", x=3.5, y=0.4, colour=c("red"),label="moyennne")+
  annotate("text", x=3.5, y=0.37, colour=c("blue"),label="médiane")+
annotate("text", x=3.5, y=0.34, colour=c("orange"),label="mode")
```


## les Coefficients de Pearson
<br><br>

Deux moyens simples d'estimer l'asymétrie 
<br><br>
$\displaystyle C_1 = \frac{\bar{x} - mode(X)}{\sigma_x}$
<br><br>
$\displaystyle C_2 = \frac{3(\bar{x} - mediane(X))}{\sigma_x}$

## Interprétation des coefficients d'asymétrie
<br><br>

  * si le coefficient **nul**, la distribution est **symétrique**
  * si le coefficient est **négatif**, la distribution est **déformée à gauche** de la médiane (sur-représentation de valeurs faibles, à gauche)
  * si le coefficient est **positif**, la distribution est **déformée à droite** de la médiane (sur-représentation de valeurs fortes, à droite)

## Le coefficient de Fischer
<br><br>

Ce coefficient est le moment  d'ordre 3  de la variable $X$ ( de moyenne $\mu$ et d'écart-type $\sigma$) **centrée réduite**

$\displaystyle skewness'=\mathbb{E}\bigg[\bigg(\frac{X-\mu}{\sigma}\bigg)^3\bigg]=\frac{\sum_{i=0}^{n} (x_i - \bar{x})^3}{n\sigma^3}$



## L'aplatissement des distributions (kurtosis)


```{r kurtos1, echo=FALSE, fig.width=10, fig.height=2, cache=TRUE}

normaleC <- 1 
picC <- 0.6
plateC <- 3


xx <- seq(-5,5, length.out = 100)
normale <-  dnorm(xx,mean = 0, sd=normaleC)
pic <-  dnorm(xx, mean = , sd=picC)
plate <- dnorm(xx, mean=, sd=plateC)

mydata <- data.frame(value=xx, dens=normale, type="Normale")
piquee <- data.frame(value=xx, dens=pic, type="Leptokurtique")
applatie <-  data.frame(value=xx, dens=plate, type="Platokurtique")


mydata <- rbind(mydata, piquee)
mydata <- rbind(mydata, applatie)

ggplot(mydata, aes(x=value, y=dens))+geom_line(color="#44DD99", lwd=1.2)+
  facet_grid(cols=vars(type), scales="free")+
  ylab(label = "density")+
  theme_light()
```

Courbe piquée: Peu de variation, distribution relativement homogène, beaucoup de valeurs égales ou proches de la moyenne.

Courbe applatie: Variations importantes, distribution relativement hétérogène, beaucoup de valeurs s'éloignent de la moyenne.


## Coefficient d'applatissement : kurtosis 

Coefficient non normalisé :


$\displaystyle K=\frac{\sum_{i=1}^{n}(x_i -\bar{x})^4}{n\sigma^4}$

Si la distribution est normale , $K= 3$

Si $K>3$, la distribution est **plus applatie** 

Si $K<3$, la distribution est **moins applatie** 

On normalise parfois en considérant $K'=K-3$ (excès d'applatissement)


# Représentation d'une distribution et Échelle de couleurs


## Distribution et Échelle de couleurs

Pour une variable quanti. continue qu'on souhaite colorer, il n'est pas toujours possible de graduer une échelle de couleur continue. 
<br>
Il faut (souvent) classer les valeurs en catégories.
Le **nombre** de classes et les **méthodes** de classification varient. 

En général 

- 5,7 ou 9 classes :
  - $<5$ trop peu de détails  
  - $>9$ difficile de distinguer les classes proches

## Distribution et Échelle de couleurs

Méthodes de classifications de Qgis

- Ruptures Naturelles (Jenks) : Minimisation des variances intra-classe et maximisation des variances inter-classe
- Effectifs égaux (quantiles)
- Intervalles égaux 
- Ecart-type  :  intervales de 1 ou 0.5 $\sigma$
- Jolies ruptures :  intervalle égaux "décalés" pour faire joli : nombre ronds, puissances de 10, ... 



## Exemple avec la surface des quartiers de Paris 


```{r quartierparis, echo=TRUE,eval=FALSE}
quartiers <-  st_read("data/quartier_paris.shp")
plot(quartiers$geometry)
```


```{r quartierparis2, eval=TRUE, echo=FALSE, cache=TRUE, fig.width=8, fig.height=5}
par(mar=c(0,0,0,0))
plot(quartiers$geometry)
```


## Allure de la distribution


```{r quartierparis3, eval=TRUE, echo=TRUE, cache=TRUE, fig.width=8, fig.height=5}
hist(quartiers$surface,breaks = 15)
```

## Affichage par défaut : 

```{r quartierparis4, eval=TRUE, cache=TRUE, fig.width=8, fig.height=4}
par(mar=c(0,0,0,0))
plot(quartiers["surface"])
```

par defaut la fonction `plot`  de sf utilise la méthode "pretty" avec 10 ruptures ($9\pm1$ classes) => ce sont des intervalles égaux. 


## Jenks à 5 , 7 et 9 classes

<div class="col3">
```{r quartierparis6, eval=TRUE, cache=TRUE, echo=FALSE, fig.width=12, fig.height=3}
par(mar=c(0,0,0,0))
plot(quartiers["surface"], breaks="jenks", nbreaks = 5, main = "5 breaks")
plot(quartiers["surface"], breaks="jenks", nbreaks = 7, main="7 breaks")
plot(quartiers["surface"], breaks="jenks", nbreaks = 9, main= "9 breaks")
```
</div>



## Jenks à 5 , 7 et 9 classes
Code R correspondant :

<div class="col3">
```{r quartierparis6bis, eval=FALSE, cache=TRUE, echo=TRUE, fig.width=12, fig.height=3}
par(mar=c(0,0,0,0))
plot(quartiers["surface"], breaks="jenks", nbreaks = 5, main = "5 breaks")
plot(quartiers["surface"], breaks="jenks", nbreaks = 7, main="7 breaks")
plot(quartiers["surface"], breaks="jenks", nbreaks = 9, main= "9 breaks")
```
</div>



## Effectifs égaux

```{r quartierparis7, eval=TRUE, cache=TRUE, echo=FALSE, fig.width=12, fig.height=6}
par(mar=c(0,0,0,0))
plot(quartiers["surface"], breaks="quantile",main = "Effectifs égaux")
```



## Intervalles égaux (7)

```{r quartierparis8, eval=TRUE, cache=TRUE, echo=TRUE, fig.width=12, fig.height=6}
par(mar=c(0,0,0,0))
plot(quartiers["surface"], breaks="equal", nbreaks = 7, main = "Intervalles égaux")
```


## Ecart types

```{r quartierparis9, eval=TRUE, cache=TRUE, echo=TRUE, fig.width=12, fig.height=6}
par(mar=c(0,0,0,0))
plot(quartiers["surface"], breaks="sd",main = "Écart-type")
```

$\approx$ méthode des jolies ruptures sur variable centrée réduite


## Guides de choix de la méthode de classification 


Pour les classification manuelles : 
<br><br>

- les classes **doivent** contenir toutes les valeurs, être sans recouvrement, contigües et distinctes.
- Procéder par essai-erreur
- attention aux décimales et aux extrémités
<br><br>


- si distribution uniforme $\rightarrow$ Intervalles égaux
- si distribution asymétrique $\rightarrow$ Effectifs égaux, Jenks , progression géométrique (rare).
- si distribution symétrique $\rightarrow$ Écart-type, intervalle égaux



## Autres classifications 

consultez la doc de la fonction `classInt` du package du même nom

## Transformations des données 


- $x \mapsto log(x)$ pour une distribution asymétrique à droite ou  $x \mapsto \sqrt x$ si moins asymétrique

- $x \mapsto x^2$ pour une distribution asymétrique à gauche ou $x \mapsto x^3$ si très asymétrique 

(<span style="color:red">&#9888;</span> toujours vérifier l'allure de la distribution transformée)

## Variables centrées-réduites 

<span style="color:red">&#9888; </span> En principe, uniquement lorsque la distribution d'une variable est proche d'une gaussienne <span style="color:red">&#9888;</span> 


Centrer : soustraire la moyenne

Réduire : diviser par l'écart-type


une variable **centrée réduite** est exprimée en «écarts-types à la moyenne»

$\rightarrow$ permet de repérer les valeurs extrèmes ($<2\sigma$ ou $>2\sigma$)

$\rightarrow$ utile pour comparer des individus selon un grand nombre de variables (tableaux de synthèse)


# Visualiser une distribution

- Histogramme 
- Distribution
- BoxPlot
- Violin plot
- Pyramides (histogrammes jusxtaposés)
- Polygones de fréquences
- Distribution cumulée , Fonction de répartition , CDF
- Dot strip plot


## Histogramme : Code R + ggplot

```{r histo_code_1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
histo_mass <- ggplot(mydata)+
  geom_histogram(aes(x=body_mass_g), fill="darkorchid4", color="darkgray", bins=50)+
  labs(title = "Penguins Body Mass", subtitle = "Histogram")+
  ylab("Count")+theme_light()
histo_mass
```


## Distribution : Code R + ggplot

<span style="color:red">&#9888;</span>  ce n'est pas exactement une probabilité, mais une **densité** de probabilité.
Pour obtenir la probabilité , il faut intégrer sur un petit $dx$.


```{r distrib_code_1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
distrib_mass <- ggplot(mydata)+
  geom_density(aes(x=body_mass_g), fill="darkorchid4", color="darkgray")+
  geom_vline(aes(xintercept=mean(body_mass_g, na.rm = T)), color="black", size=0.4, linetype="dashed" )+
  labs(title = "Penguins Body Mass", subtitle = "Probability density and mean")+
  ylab("Count")+theme_light()
distrib_mass
```



## BoxPlot : Code R + ggplot


```{r boxplot_code_1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
boxplot_mass <- ggplot(mydata)+
  geom_boxplot(aes(x=body_mass_g, y=species, color=species))+
  labs(title = "Penguins Body Mass", subtitle = "BoxPlot by Species")+
  ylab("Count")+theme_light()
boxplot_mass
```

## Violin plot

Dsitribution+miroir
Utile pour des distributions complexes, e.g.  mal résumées par la moyenne et la dispersion.

```{r violin_code_1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
violin_mass <- ggplot(mydata)+
  geom_violin(aes(y=body_mass_g, x=species, fill=species), color="gray", trim=F)+
  labs(title = "Penguins Body Mass", subtitle = "ViolinPlot by Species")+
  ylab("Count")+theme_light()
violin_mass
```


## Violin plot et Boxplot  : Code R + ggplot 2



```{r violin_code_2, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
violin_mass <- ggplot(mydata)+
  geom_violin(aes(y=body_mass_g, x=species, fill=species), color="lightgray", trim=F)+
  geom_boxplot(aes(y=body_mass_g, x=species, fill=species), color="black", fill="#eeeeee" ,width=0.1)+
  labs(title = "Penguins Body Mass", subtitle = "ViolinPlot and Boxplot by Species")+
  ylab("Count")+theme_light()
violin_mass
```


## Pyramides (histogrammes juxtaposés) 

lorsqu'une des variables est qualitatives à deux modalités :

```{r pyramide_code_1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3, message=F}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
pyramide_mass <-  ggplot(mydata, aes(fill = sex)) + 
  geom_bar(data = subset(mydata, sex == "female"), stat = "bin", aes(x=body_mass_g, y=..count..*(-1)), color="grey") +
  geom_bar(data = subset(mydata, sex == "male"), stat = "bin", aes(x=body_mass_g), color="grey") + 
  scale_y_continuous(labels = paste0(as.character(c(seq(20, 0, -10), seq(10, 20, 10))))) +
  ylab("count")+  coord_flip()+
  labs(title = "Penguins Body Mass", subtitle = "Pyramid Plot by sex")+
  theme_light()
  
pyramide_mass
```

## Polygones de fréquences

"Histogramme en courbe"
<br>
Utile pour comparer plusieurs distributions


```{r frequpoly_code1, cache=T, warning=F, echo=T,fig.width=8, fig.height=3}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
freqpoly_mass <- ggplot(mydata)+
  geom_freqpoly(aes(x=body_mass_g, color=species), bins=50)+
  labs(title = "Penguins Body Mass", subtitle = "Frequence Polygons")+
  ylab("Count")+theme_light()
freqpoly_mass
```




## Distribution cumulée , Fonction de répartition , CDF

Courbe $x,y$,
<br>
en $x$ la valeur de la variable $V$, en $y$ la probabilité empririque d'avoir dans la population, un individu pour lequel $V\leq x$

i.e. c'est la fonction  <br>
$F_{V}(x)=\mathbb {P} (V\leq x)$


```{r CDF1 , cache = TRUE, fig.width=8, fig.height=3, echo=F, warning=F}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
plot_mass <- ggplot(mydata, aes(x= body_mass_g))+
  stat_ecdf(color="darkorchid4")+
  labs(title = "Penguins Body Mass", subtitle = "Cumulative Distribution Function")+
  ylab("Probability")+theme_light()
plot_mass
```


## Distribution cumulée , Fonction de répartition , CDF
<br><br>
Permet de superposer les CDF de sous groupes de la population. 
ici : la race des penguins

```{r CDF_groupe , cache = TRUE, fig.width=8, fig.height=3, echo=F, warning=F}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
plot_mass <- ggplot(mydata)+
  stat_ecdf(aes(x= body_mass_g, color=species))+
  labs(title = "Penguins Body Mass by Species", subtitle = "Cumulative Distribution Function")+
  ylab("Probability")+theme_light()
plot_mass
```



## Distribution cumulée simple : Code R + ggplot

```{r CDF_code , cache = TRUE, fig.width=8, fig.height=3, echo=T, warning=F}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
plot_mass <- ggplot(mydata)+
  stat_ecdf(aes(x= body_mass_g),color="darkorchid4")+
  labs(title = "Penguins Body Mass", subtitle = "Cumulative Distribution Function")+
  ylab("Probability")+theme_light()
plot_mass
```


## Distribution cumulée par groupe : Code R + ggplot

```{r CDF_code_groupe , cache = TRUE, fig.width=8, fig.height=3, echo=T, warning=F}
library(palmerpenguins)
data(package = 'palmerpenguins')
mydata <-  penguins
plot_mass <- ggplot(mydata)+
  stat_ecdf(aes(x= body_mass_g,color=species))+    #on affecte la couleur à la variable modale  
  labs(title = "Penguins Body Mass", subtitle = "Cumulative Distribution Function")+
  ylab("Probability")+theme_light()
plot_mass
```


## Dot Strip Plot






# Bonus


## Fat-tail distributions


Les distributions très asymétriques et très étendues sont délicates à résumer.

Les indicateurs traditionnels sont plus efficaces lorsque la variabilité des valeurs est moindre, et leur distribution plus symétrique.

e.g. Considérer la population moyenne des villes de France a-t'elle du sens ? 
```{r histoVillesPop, cache=TRUE, echo=FALSE, fig.width=8, fig.height=2.5}
mydata <-  read.csv("data/pop_communes.csv")
plot_PopVilles <- ggplot(mydata)+
  geom_histogram(aes(x=Population.totale), bins=60 , color="#aaaaaa",fill="#44DD99" )+
  geom_vline(xintercept = mean(mydata$Population.totale), color = "red")+
  annotate("text", x=15000, y=400, colour=c("red"),label="moyennne = 7517.37 ")+
  theme_light()
plot_PopVilles
```


## Distribution rang-taille des villes de france 


Pour mieux voir la distribution et les écarts, on trace la **taille** des villes en fonction de leur **rang** 

```{r popVilles1 , cache = TRUE, fig.width=8, fig.height=4, echo=FALSE}
mydata <-  read.csv("data/pop_communes.csv")
plot_PopVilles <- ggplot(mydata)+
  geom_point(aes(x=rank(-Population.totale), y=Population.totale), color="#44DD99")+
  xlab(label = "rang")+ylab("Population")+ggtitle("Distribution rang-taille des villes de France")+
  theme_light()
plot_PopVilles
```

## Transformation logarithmique

Appliquer une transformation **monotone**, **bijective** et **inversible** qui "applatisse" la distribution.

  * réduit les écarts entre les valeurs
  * resserre  l'essentiel des valeurs 

$\implies$ mesure de façon plus robuste  tendance, dispersion et forme

Ici : le logarithme décimal


## Distribution rang-log(taille) 

```{r loglin1 , cache = TRUE, fig.width=8, fig.height=4, echo=FALSE}
mydata <-  read.csv("data/pop_communes.csv")
plot_PopVilles <- ggplot(mydata)+
  geom_point(aes(x=rank(-Population.totale), y=Population.totale), color="#44DD99")+
  xlab(label = "rang")+ylab("Population")+ggtitle("Distribution rang-taille des villes de France")+
  scale_y_log10()+
  theme_light()
plot_PopVilles
```













